---
date: 2015-01-25
layout: post
title: 移动时代互联网金融的架构趋势
permalink: '/2015/01-25-0.html'
categories:
- 服务器编程
tags:
- 架构
---

## 引子
有幸参加了[又拍网](https://www.upyun.com/index.html)组织的Open Talk No.2 -- 移动时代互联网金融的架构趋势。虽然没有接触过互联网金融这方面的内容，但是怀着成为一个合格程序员的人生梦想的人，怎能错过这样的聚会。

本次Talk请来了三位讲师分别讲述了其所在公司的相关后台技术架构，技术虽然各有千秋，但万变不离其中：**并发，缓存，异步是后台永恒的话题**。

下面主要回顾下挖财和同盾科技的两位讲师的Key Point，而51信用卡的分享以其原始PPT呈现。

## 挖财的互联网金融技术探索
讲师是挖财首席架构师王福强，原阿里资深架构师。他的主题分为以下：

+ **Separation Everywhere**，即组件分离，将服务分组，模块化，有点类似[SOA](http://en.wikipedia.org/wiki/Service-oriented_architecture)的味道（事实上就是SOA）。模块化架构不仅易于后期的代码重构，而且也方便后期的架构调整。而且，组件分离后，可以对各类服务进行分组，将耗时操作与非耗时操作分离，保证两者互不干涉，即使一方繁忙时也不影响另一方。

+ **Async Everywhere**，即异步化。服务器并发量达到一定数量级，必需经过调用的异步化。当相对耗时调用等待时，可以进行其他调用的处理，以此让服务器并发化处理相应业务。

+ **Message Passing Everywhere**，即消息化。服务器内部或者之间通信全部使用消息机制，统一调度。这里[消息中间件](http://baike.baidu.com/view/3118541.htm)就会大显身手。这里挖财就应用了[Kafka](http://kafka.apache.org/)。

+ **Immutability Everywhere**，即持久化。内存中的数据在断电后是无法恢复的，所以一些重要数据，特别是互联网金融领域的相关数据，是不能丢失的，所以及时对数据进行持久化是十分必要的。

+ **Security Everywhere**，即安全性。与持久化类似，互联网金融领域的一些数据是用户的敏感数据，所以对数据的安全必须要仔细考虑。如果数据被拖库的话，在业内声誉就基本毁于一旦了。

+ **Intercept Everywhere**，即拦截。与安全性一样，对敏感业务，数据必须要多长一个心眼。

+ **Auditing Everywhere**，即监控化。服务器硬件各项指标，如CPU负载，内存利用率，磁盘利用率，网络I/O状态等，服务器业务进程各项指标，如业务请求成功数，失败数等，都必须收集汇总，以显示服务器健康度。

+ **Bulkheads Everywhere**，即隔离化。同样这也是服务器架构方面的注意点，合理分层化，模块化，某一服务的异常确保不会影响到其他服务。

+ **Switches Everywhere**，即开关化。针对单独业务接口，或者单独用户，又或者单独IP进行服务开关化。在遇见异常情况下，如恶意用户进行的攻击，窃取私密数据时，及时关闭相应服务。

+ **Redundancy Everywhere**，即冗余化。特别是金融重要数据，如果其丢失将造成不可挽回的损失，所以对相应数据的冗余化，及时做备份也是必要的。

+ **Reactive Everywhere**，即事件驱动化（可能并不是很准确）。这里是指采用事件驱动，网络请求，信号发生等采用事件循环驱动，可以高性能进行并发服务处理。比如[libevent](http://libevent.org)、[libev](http://software.schmorp.de/pkg/libev.html)、[libuv](https://github.com/libuv/libuv)就是成熟的事件驱动框架。

## 从零打造千万级的实时风控云服务
讲师是来自同盾科技的联合创始人、技术总监张新波，原阿里集团安全部专家。

### 挑战
风控云服务如果要做好，就必需跨越以下几个挑战：
+ **性能**
+ **可用性**
+ **可扩展性**

事实上，所有后台服务器如果要支持大并发量都要考虑以上3点挑战。

具体到风控云服务上（具体点就是同盾科技内部），性能上的挑战有：
+ 实时性要求高，服务响应时间通常小于500ms（客户要求）
+ 计算结果无法缓存，全部需要实时动态计算（风控业务要求)
+ 参与计算数据量大，计算维度多且复杂（风控业务要求）
+ 无法像静态资源盘多机房缓存和加速（风控业务要求）

而可用性上有：
+ 保证服务的稳定性，消除单点故障（服务器基本要求）
+ 完备的灾备和紧急处理方案，以备不时之需（服务器基本要求）

在可扩展性上则为：
+ 应用服务器可线性扩展，支撑业务的快速发展（服务器基本要求）
+ 海量数据的存储和计算，支持线性扩展（服务器基本要求）

可见，在可用性和可扩展性上，同盾科技的实时风控云服务与一般高性能服务器挑战一致，但是在性能上却更具有挑战性，由于一些业务上的特殊情况，不能缓存计算结果将会对服务器的情况上造成巨大的伤害。

### 服务器架构演化
下图是同盾科技最早版本的服务器架构V0.1（切莫嘲笑其简单，创业初期先走业务实现是根本原则）：
![](/img/2015-01-25-0.jpg "")

我们可以看到，整套服务器采用[Apache](http://httpd.apache.org/)作为服务器的接入层，具体业务逻辑层分别用两台机器做为Admin控制和具体接口服务逻辑计算，而数据层则直接用[MySQL](http://www.mysql.com/)进行存储。特别注意，业务主要逻辑(用户校验，查找策略，保存数据)采用的是直接向数据库**同步**加载数据，而我们知道数据库操作的慢速操作，因此整个服务的并发上不去，明显这个操作将会成为巨大的瓶颈。

因此，在V0.2时，针对V0.1中的同步向数据库读取数据的操作进行缓存优化，使用[Guava Cache](https://code.google.com/p/guava-libraries/wiki/CachesExplained)定时预先加载，缓存全部用户及对应的策略数据。当然这里有些同学就有疑问了，缓存全部用户数据这是不是脑洞太大了。没错，就是全部用户数据，由于早期用户数据不多且业务类型特性（面向企业）决定全部数据也不是不可控。
在另一方面，数据库写入操作则采用异步写入，引入[Berkeley DB](http://en.wikipedia.org/wiki/Berkeley_DB)作为本地队列辅助进行异步写入。

在V0.2中，随着用户数据量的增多，原先使用Guava Cache进行缓存的方式已经力不从心，所以在V0.3中直接用[Memcached](http://memcached.org/)代替，而且对缓存数据进行了Base64+Gzip的压缩，减少缓存的数据大小。当然，有同学有疑问进行数据压缩转换是否增加了性能压力。事实上，这点性能的损失对服务整体的耗时来说可以忽略不计，所以引入压缩转换减少的缓存量和网络传输量在性价比上来说是值得的。

我们注意到，在上面提及的所有版本中都没有集群的概念，事实上，所有的服务都是单点。当然，这对于一个服务的可用性来说是不良信号，所以在V1.0版本时，不仅消除单点问题，而且新增监控系统([Zabbix](http://www.zabbix.com/))，同时，接入层由Apache替换成性能更强力的[Nginx](http://nginx.com/)，具体架构如下：
![](/img/2015-01-25-1.jpg "")

但是这样就够了吗？

业务数据增加过快，直接引入了新的问题：数据库分表已无法解决数据增加过快问题。所以在V2.x中引入[Cassandra](http://cassandra.apache.org/)数据库，其Wide column store的特点正好解决数据单表过大无法存储的问题。同时，为了解决根据任意维度进行数据查询和分析的性能问题，引入[ElasticSerch](http://www.elasticsearch.org/)进行全字段索引查询。另一方面，坐拥大数据却不知利用则会冠以暴殄天物之名。所以引入[Spark](https://spark.apache.org/)进行离线分析，[Spark streaming](https://spark.apache.org/streaming/)结合[Kafka](https://spark.apache.org/streaming/)则进行实时流计算，
所以现在的架构演化成如下：
![](/img/2015-01-25-2.jpg "")

### 架构演化带来的思考
+ **使用熟悉、成熟和社区活跃的开源技术**。
+ **先满足业务需求，再优化，逐步演进**。
+ **监控报警，应急预案必须成为系统的一部分**。
+ **纸上得来终觉浅，绝知此事要躬行**。

## 51信用卡的日志分析变迁史
参见文后Reference。

## [Reference]
+ [挖财的互联网金融技术探索](http://upyun-open-talk.b0.upaiyun.com/wacai.pdf)
+ [从零打造千万级的实时风控云服务](http://upyun-open-talk.b0.upaiyun.com/tongdun.pdf)
+ [51信用卡的日志分析变迁史](http://upyun-open-talk.b0.upaiyun.com/51xinyongka.pdf)