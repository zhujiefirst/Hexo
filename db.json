{"meta":{"version":1,"warehouse":"1.0.2"},"models":{"Asset":[{"_id":"themes/next/source/vendors/velocity/velocity.ui.min.js","path":"vendors/velocity/velocity.ui.min.js","modified":0},{"_id":"themes/next/source/vendors/velocity/velocity.ui.js","path":"vendors/velocity/velocity.ui.js","modified":0},{"_id":"themes/next/source/vendors/velocity/velocity.min.js","path":"vendors/velocity/velocity.min.js","modified":0},{"_id":"themes/next/source/vendors/velocity/velocity.js","path":"vendors/velocity/velocity.js","modified":0},{"_id":"themes/next/source/vendors/velocity/bower.json","path":"vendors/velocity/bower.json","modified":0},{"_id":"themes/next/source/vendors/jquery/index.js","path":"vendors/jquery/index.js","modified":0},{"_id":"themes/next/source/vendors/fancybox/source/jquery.fancybox.pack.js","path":"vendors/fancybox/source/jquery.fancybox.pack.js","modified":0},{"_id":"themes/next/source/vendors/fancybox/source/jquery.fancybox.js","path":"vendors/fancybox/source/jquery.fancybox.js","modified":0},{"_id":"themes/next/source/vendors/fancybox/source/jquery.fancybox.css","path":"vendors/fancybox/source/jquery.fancybox.css","modified":0},{"_id":"themes/next/source/vendors/fancybox/source/helpers/jquery.fancybox-thumbs.js","path":"vendors/fancybox/source/helpers/jquery.fancybox-thumbs.js","modified":0},{"_id":"themes/next/source/vendors/fancybox/source/helpers/jquery.fancybox-thumbs.css","path":"vendors/fancybox/source/helpers/jquery.fancybox-thumbs.css","modified":0},{"_id":"themes/next/source/vendors/fancybox/source/helpers/jquery.fancybox-media.js","path":"vendors/fancybox/source/helpers/jquery.fancybox-media.js","modified":0},{"_id":"themes/next/source/vendors/fancybox/source/helpers/jquery.fancybox-buttons.js","path":"vendors/fancybox/source/helpers/jquery.fancybox-buttons.js","modified":0},{"_id":"themes/next/source/vendors/fancybox/source/helpers/jquery.fancybox-buttons.css","path":"vendors/fancybox/source/helpers/jquery.fancybox-buttons.css","modified":0},{"_id":"themes/next/source/vendors/fancybox/source/helpers/fancybox_buttons.png","path":"vendors/fancybox/source/helpers/fancybox_buttons.png","modified":0},{"_id":"themes/next/source/vendors/fancybox/source/fancybox_sprite@2x.png","path":"vendors/fancybox/source/fancybox_sprite@2x.png","modified":0},{"_id":"themes/next/source/vendors/fancybox/source/fancybox_sprite.png","path":"vendors/fancybox/source/fancybox_sprite.png","modified":0},{"_id":"themes/next/source/vendors/fancybox/source/fancybox_overlay.png","path":"vendors/fancybox/source/fancybox_overlay.png","modified":0},{"_id":"themes/next/source/vendors/fancybox/source/fancybox_loading@2x.gif","path":"vendors/fancybox/source/fancybox_loading@2x.gif","modified":0},{"_id":"themes/next/source/vendors/fancybox/source/fancybox_loading.gif","path":"vendors/fancybox/source/fancybox_loading.gif","modified":0},{"_id":"themes/next/source/vendors/fancybox/source/blank.gif","path":"vendors/fancybox/source/blank.gif","modified":0},{"_id":"themes/next/source/js/ua-parser.min.js","path":"js/ua-parser.min.js","modified":0},{"_id":"themes/next/source/js/search-toggle.js","path":"js/search-toggle.js","modified":0},{"_id":"themes/next/source/js/motion_global.js","path":"js/motion_global.js","modified":0},{"_id":"themes/next/source/js/motion_fallback.js","path":"js/motion_fallback.js","modified":0},{"_id":"themes/next/source/js/lazyload.js","path":"js/lazyload.js","modified":0},{"_id":"themes/next/source/js/hook-duoshuo.js","path":"js/hook-duoshuo.js","modified":0},{"_id":"themes/next/source/js/helpers.js","path":"js/helpers.js","modified":0},{"_id":"themes/next/source/js/fancy-box.js","path":"js/fancy-box.js","modified":0},{"_id":"themes/next/source/js/bootstrap.scrollspy.js","path":"js/bootstrap.scrollspy.js","modified":0},{"_id":"themes/next/source/images/searchicon.png","path":"images/searchicon.png","modified":0},{"_id":"themes/next/source/images/placeholder.gif","path":"images/placeholder.gif","modified":0},{"_id":"themes/next/source/images/loading.gif","path":"images/loading.gif","modified":0},{"_id":"themes/next/source/images/cc-zero.svg","path":"images/cc-zero.svg","modified":0},{"_id":"themes/next/source/images/cc-by.svg","path":"images/cc-by.svg","modified":0},{"_id":"themes/next/source/images/cc-by-sa.svg","path":"images/cc-by-sa.svg","modified":0},{"_id":"themes/next/source/images/cc-by-nd.svg","path":"images/cc-by-nd.svg","modified":0},{"_id":"themes/next/source/images/cc-by-nc.svg","path":"images/cc-by-nc.svg","modified":0},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","path":"images/cc-by-nc-sa.svg","modified":0},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","path":"images/cc-by-nc-nd.svg","modified":0},{"_id":"themes/next/source/images/bkdefault_avatar.jpg","path":"images/bkdefault_avatar.jpg","modified":0},{"_id":"themes/next/source/images/avatar.jpg","path":"images/avatar.jpg","modified":0},{"_id":"themes/next/source/fonts/icon-linecons/icomoon.woff","path":"fonts/icon-linecons/icomoon.woff","modified":0},{"_id":"themes/next/source/fonts/icon-linecons/icomoon.ttf","path":"fonts/icon-linecons/icomoon.ttf","modified":0},{"_id":"themes/next/source/fonts/icon-linecons/icomoon.svg","path":"fonts/icon-linecons/icomoon.svg","modified":0},{"_id":"themes/next/source/fonts/icon-linecons/icomoon.eot","path":"fonts/icon-linecons/icomoon.eot","modified":0},{"_id":"themes/next/source/fonts/icon-icomoon/icomoon.woff","path":"fonts/icon-icomoon/icomoon.woff","modified":0},{"_id":"themes/next/source/fonts/icon-icomoon/icomoon.ttf","path":"fonts/icon-icomoon/icomoon.ttf","modified":0},{"_id":"themes/next/source/fonts/icon-icomoon/icomoon.svg","path":"fonts/icon-icomoon/icomoon.svg","modified":0},{"_id":"themes/next/source/fonts/icon-icomoon/icomoon.eot","path":"fonts/icon-icomoon/icomoon.eot","modified":0},{"_id":"themes/next/source/fonts/icon-fifty-shades/icomoon.woff","path":"fonts/icon-fifty-shades/icomoon.woff","modified":0},{"_id":"themes/next/source/fonts/icon-fifty-shades/icomoon.ttf","path":"fonts/icon-fifty-shades/icomoon.ttf","modified":0},{"_id":"themes/next/source/fonts/icon-fifty-shades/icomoon.svg","path":"fonts/icon-fifty-shades/icomoon.svg","modified":0},{"_id":"themes/next/source/fonts/icon-fifty-shades/icomoon.eot","path":"fonts/icon-fifty-shades/icomoon.eot","modified":0},{"_id":"themes/next/source/fonts/icon-feather/icomoon.woff","path":"fonts/icon-feather/icomoon.woff","modified":0},{"_id":"themes/next/source/fonts/icon-feather/icomoon.ttf","path":"fonts/icon-feather/icomoon.ttf","modified":0},{"_id":"themes/next/source/fonts/icon-feather/icomoon.svg","path":"fonts/icon-feather/icomoon.svg","modified":0},{"_id":"themes/next/source/fonts/icon-feather/icomoon.eot","path":"fonts/icon-feather/icomoon.eot","modified":0},{"_id":"themes/next/source/fonts/icon-default/icomoon.woff","path":"fonts/icon-default/icomoon.woff","modified":0},{"_id":"themes/next/source/fonts/icon-default/icomoon.ttf","path":"fonts/icon-default/icomoon.ttf","modified":0},{"_id":"themes/next/source/fonts/icon-default/icomoon.svg","path":"fonts/icon-default/icomoon.svg","modified":0},{"_id":"themes/next/source/fonts/icon-default/icomoon.eot","path":"fonts/icon-default/icomoon.eot","modified":0},{"_id":"themes/next/source/css/main.styl","path":"css/main.styl","modified":0},{"_id":"source/img/2015-02-14-1.png","path":"img/2015-02-14-1.png","modified":0},{"_id":"source/img/2015-02-14-1.dot","path":"img/2015-02-14-1.dot","modified":0},{"_id":"source/img/2015-02-14-0.png","path":"img/2015-02-14-0.png","modified":0},{"_id":"source/img/2015-02-14-0.dot","path":"img/2015-02-14-0.dot","modified":0},{"_id":"source/img/2015-01-30-1.jpg","path":"img/2015-01-30-1.jpg","modified":0},{"_id":"source/img/2015-01-30-0.jpg","path":"img/2015-01-30-0.jpg","modified":0},{"_id":"source/img/2015-01-25-2.jpg","path":"img/2015-01-25-2.jpg","modified":0},{"_id":"source/img/2015-01-25-1.jpg","path":"img/2015-01-25-1.jpg","modified":0},{"_id":"source/img/2015-01-25-0.jpg","path":"img/2015-01-25-0.jpg","modified":0},{"_id":"source/img/2014-12-28-0.png","path":"img/2014-12-28-0.png","modified":0},{"_id":"source/img/2013-06-29-0.png","path":"img/2013-06-29-0.png","modified":0},{"_id":"source/img/2012-09-09-0.png","path":"img/2012-09-09-0.png","modified":0},{"_id":"source/img/2012-09-02-5.png","path":"img/2012-09-02-5.png","modified":0},{"_id":"source/img/2012-09-02-4.png","path":"img/2012-09-02-4.png","modified":0},{"_id":"source/img/2012-09-02-3.png","path":"img/2012-09-02-3.png","modified":0},{"_id":"source/img/2012-09-02-2.png","path":"img/2012-09-02-2.png","modified":0},{"_id":"source/img/2012-09-02-1.png","path":"img/2012-09-02-1.png","modified":0},{"_id":"source/img/2012-09-02-0.png","path":"img/2012-09-02-0.png","modified":0},{"_id":"source/favicon.ico","path":"favicon.ico","modified":0}],"Cache":[{"_id":"source/_posts/2010-07-03-0.md","shasum":"ecf0a0af0eb4e4056cb395774ccb4bf9f60aac12","modified":1434730145000},{"_id":"source/_posts/2010-08-02-0.md","shasum":"800698feacd5b66de4335b4c9fcd1aa33386e984","modified":1434730145000},{"_id":"source/_posts/2010-09-03-0.md","shasum":"12ef484e427126e7b1a51e0ff79a3a82eed9e3d8","modified":1434730145000},{"_id":"source/_posts/2011-05-29-0.md","shasum":"61e753fabb31dcca438278774cd76cea534efc72","modified":1434730145000},{"_id":"source/_posts/2011-06-04-0.md","shasum":"5e4017868bd5fe9a0a1715871a6e326e10a8341b","modified":1434730145000},{"_id":"source/_posts/2011-10-06-0.md","shasum":"23be0ed06ebd2164c002b440c85d3cbe7a87c333","modified":1434730145000},{"_id":"source/_posts/2011-10-07-0.md","shasum":"a56a9c4adf23e33d444ef76fecbb8bd173732397","modified":1434730145000},{"_id":"source/_posts/2011-10-16-0.md","shasum":"9fa67404193f52db4a614fffc278e43925a16b27","modified":1434730145000},{"_id":"source/_posts/2011-12-15-0.md","shasum":"705d1bee5bdb0c735f9bd716fdbc0aa253a6746b","modified":1434730145000},{"_id":"source/_posts/2012-09-02-0.md","shasum":"75fa4b4da6450ad177b64ba11c496cb1025faa62","modified":1434730145000},{"_id":"source/_posts/2012-09-09-0.md","shasum":"10568f3e8c146d45e0a0f387e52f52717ca391e2","modified":1434730145000},{"_id":"source/_posts/2013-03-24-0.md","shasum":"c1ecd723fec8a04395e8b900ea8d4592daf1a919","modified":1434730145000},{"_id":"source/_posts/2013-03-25-0.md","shasum":"366be8e25462e55e386cff68823cd3b3ffad3d38","modified":1434730145000},{"_id":"source/_posts/2013-06-22-0.md","shasum":"4830ee785674d38995e4ffa1340b8e29f006bcc4","modified":1434730145000},{"_id":"source/_posts/2013-06-23-0.md","shasum":"c8ac9598502d1dde791e1b9cfa39af61b297f50c","modified":1434730145000},{"_id":"source/_posts/2013-06-29-0.md","shasum":"6988a9efbbe4fc995735cf9fdcddde4301a3c3f0","modified":1434730145000},{"_id":"source/_posts/2013-07-15-0.md","shasum":"3eea6d858993765f7b5be60e1d6f10e5955d0a16","modified":1434730145000},{"_id":"source/_posts/2013-07-28-0.md","shasum":"cf21d0911794eaa78eff8d1d9989977937256c36","modified":1434730145000},{"_id":"source/_posts/2013-07-17-0.md","shasum":"c44c1acebe3f251de3340527c67db379186d85b7","modified":1434730145000},{"_id":"source/_posts/2013-07-27-0.md","shasum":"7ff6ca51fca1cd2224b5c241ccad6306f380c686","modified":1434730145000},{"_id":"source/_posts/2014-07-03-0.md","shasum":"87151d091735146a9a4ce4a679f6981f672410c5","modified":1434730145000},{"_id":"source/_posts/2014-08-09-0.md","shasum":"ab8909c3516f6707d7db187a750205d5aca78f07","modified":1434730145000},{"_id":"source/_posts/2014-08-09-1.md","shasum":"95da580e3f61559f7249468137639316a72e4af7","modified":1434730145000},{"_id":"source/_posts/2014-08-09-2.md","shasum":"b4dedc0a14add10e2017b79fe52b13cd683d7411","modified":1434730145000},{"_id":"source/_posts/2014-11-14-0.md","shasum":"671c3a8e3428023b5b18177ce7c9a01b28df2d1c","modified":1434730145000},{"_id":"source/_posts/2014-11-16-0.md","shasum":"f32d7b97f7e69dbbde026782ec141f02f1eea23f","modified":1434730145000},{"_id":"source/_posts/2014-11-18-0.md","shasum":"d760a7df174dfe23f2c14107313f98f04ce25d46","modified":1434730145000},{"_id":"source/_posts/2014-11-20-0.md","shasum":"4d05187dc23a564df293b7331b50140aba61882c","modified":1434730145000},{"_id":"source/_posts/2014-12-01-0.md","shasum":"a2ca78c89515539ef509a2881160fa1268ecc24c","modified":1434730145000},{"_id":"source/_posts/2014-12-07-0.md","shasum":"7e00f14814e46c1d71663c8dd136d3a8670447da","modified":1434730145000},{"_id":"source/_posts/2014-12-08-0.md","shasum":"f7906f4ffe6c7ac569008de616ec69a2a5271bb4","modified":1434730145000},{"_id":"source/_posts/2014-12-12-0.md","shasum":"f8071616e08d4c05b08333b3a4e0e620b1c6915f","modified":1434730145000},{"_id":"source/_posts/2014-12-27-0.md","shasum":"685fab90b219ae4c7ce05183452c31328f126a74","modified":1434730145000},{"_id":"source/_posts/2014-12-27-1.md","shasum":"21750126bed2c510818fb0d65d3b7e65e38946b5","modified":1434730145000},{"_id":"source/_posts/2014-12-27-2.md","shasum":"5d995458ba5e97a463d19ecdb2a4c6c19ad9c276","modified":1434730145000},{"_id":"source/_posts/2014-12-27-3.md","shasum":"f4f399522fb8cef6f57502da41d06998a7021f12","modified":1434730145000},{"_id":"source/_posts/2014-12-28-0.md","shasum":"526ddf1015a08bce3d045b9626a1823d6c03ebe6","modified":1434730145000},{"_id":"source/_posts/2014-12-28-1.md","shasum":"bfa6ff2eeaf131120049823fb976099cb3f1568e","modified":1434730145000},{"_id":"source/_posts/2014-12-28-2.md","shasum":"bd8e00208bc3daf94a3f0972b3e3a1ad1a690bf2","modified":1434730145000},{"_id":"source/_posts/2015-01-22-0.md","shasum":"4506fdc4a90abec92d3405741358224c29f7fc0c","modified":1434730145000},{"_id":"source/_posts/2015-01-23-0.md","shasum":"2bf64e3fd51433364cf5aaac958b85dc5a1e743c","modified":1434730145000},{"_id":"source/_posts/2015-01-25-0.md","shasum":"0975a46b61024cd086301049109eed81557bdbe1","modified":1434730145000},{"_id":"source/_posts/2015-01-30-0.md","shasum":"005d97440ad349f59c3b0a1ad54d048b6d6dd78a","modified":1434730145000},{"_id":"source/_posts/2015-02-01-0.md","shasum":"52a48aabbd31d0a89d2a8a1b4decef96eebe94e4","modified":1434730145000},{"_id":"source/_posts/2015-02-14-0.md","shasum":"55317d484d986a42bda5b72abc2ebd11c4e36e0a","modified":1437808988000},{"_id":"source/_posts/2015-12-30-0.md","shasum":"8d547f634fff86571dba0854682fa4e9e5de230f","modified":1451482047000},{"_id":"source/_posts/2015-12-31-0.md","shasum":"c86bd487613fb6774374e0a6b5b74b85f49f1c14","modified":1451567301000},{"_id":"source/about/index.md","shasum":"7dbe059ddc6a0f788492c71522293c6223786de8","modified":1437808097000},{"_id":"source/categories/index.md","shasum":"78f722906143808cc435b19a060a511a6fdfa696","modified":1437813909000},{"_id":"source/img/2012-09-02-0.png","shasum":"0a18664b44b7ddc501c795c0d7c40e0bd2fd83cd","modified":1434730145000},{"_id":"source/img/2012-09-02-1.png","shasum":"8afb5dfc6871080c68da765dca199034ae1f1f60","modified":1434730145000},{"_id":"source/img/2012-09-02-2.png","shasum":"1a745b2042cffdffb3c3c639aaecce9994a70575","modified":1434730145000},{"_id":"source/img/2012-09-02-3.png","shasum":"6d39c219fa056f4bd831a1cfd228bb6136ddaef4","modified":1434730145000},{"_id":"source/img/2012-09-02-4.png","shasum":"89e3783d740c3b13d2643d1b4211565973e92292","modified":1434730145000},{"_id":"source/img/2012-09-02-5.png","shasum":"82fffe663e491fbb49b060c9767aab9b951899a6","modified":1434730145000},{"_id":"source/img/2012-09-09-0.png","shasum":"e75691d34f672d2ee9be89f8bb6e1e10217603f6","modified":1434730145000},{"_id":"source/img/2014-12-28-0.png","shasum":"5a8f344ecb8494905f4fd3fc3eee81eb35d90708","modified":1434730145000},{"_id":"source/img/2015-02-14-0.dot","shasum":"ed9a5e347a0283408d2c9abb14e105edc0ad2286","modified":1434730145000},{"_id":"source/img/2015-02-14-0.png","shasum":"694abc328b0e4e3d955dda15a32e98a07d034f2a","modified":1434730145000},{"_id":"source/img/2015-02-14-1.dot","shasum":"da82da63bfaaff004c3d741690509d48a3a5ecec","modified":1434730145000},{"_id":"source/img/2015-02-14-1.png","shasum":"d3eb99aecefdc2c8bee9c14de90994bab5ed2c0d","modified":1434730145000},{"_id":"source/tags/index.md","shasum":"5fe69de32eebc5c2feeecbbd8f1a82bb94f69371","modified":1437813959000},{"_id":"source/img/2015-01-30-0.jpg","shasum":"d76b63a8a15bdd5a1b2e012ee2e10bb1c13b461e","modified":1434730145000},{"_id":"source/img/2015-01-25-0.jpg","shasum":"627f105689f6a362275a41ec1ed6f24bd46fdbf2","modified":1434730145000},{"_id":"source/img/2015-01-30-1.jpg","shasum":"32912ad385a2263f99a84c63a0330c0b7093a566","modified":1434730145000},{"_id":"source/favicon.ico","shasum":"e5f4f4550b8c1c4e5d63dce25668da4823b1dd52","modified":1437816496000},{"_id":"source/img/2013-06-29-0.png","shasum":"830f2f885c8a9ee208e48254956b5971456b5ff7","modified":1434730145000},{"_id":"source/img/2015-01-25-1.jpg","shasum":"21b9ed0a8e2685331a565f20e7f554e6f6ee14d7","modified":1434730145000},{"_id":"source/img/2015-01-25-2.jpg","shasum":"1a42f75d4dfceab83969a0e7d7a3d67d938de2f9","modified":1434730145000},{"_id":"themes/next/source/css/_common/_page/home.styl","shasum":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1437813096000},{"_id":"themes/next/source/css/_mixins/Mist.styl","shasum":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1437813096000},{"_id":"themes/next/source/css/_mixins/custom.styl","shasum":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1437813096000},{"_id":"themes/next/source/css/_mixins/default.styl","shasum":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1437813096000},{"_id":"themes/next/source/css/_variables/custom.styl","shasum":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1437813096000},{"_id":"themes/next/source/css/_variables/default.styl","shasum":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1437813096000},{"_id":"themes/next/README.en.md","shasum":"565ba52b3825b85a9f05b41183caca7f18b741d4","modified":1437813096000},{"_id":"themes/next/README.md","shasum":"aa16555d1aa1d80666ab9085042e118cdb7f5ef2","modified":1437813096000},{"_id":"themes/next/_config.yml","shasum":"072bc6f8b34d1329412980a5a9d4a3777d6c4858","modified":1437814982000},{"_id":"themes/next/bower.json","shasum":"1a681eeb5bff68be34e4e5226678c6cd3a7a12cc","modified":1437813096000},{"_id":"themes/next/languages/de.yml","shasum":"784bea46de28a3113d7c91621740f521dae09dce","modified":1437813096000},{"_id":"themes/next/languages/default.yml","shasum":"d0cad2843283dd2a62cb8d1a2ed182a368210aca","modified":1437813096000},{"_id":"themes/next/languages/en.yml","shasum":"d0cad2843283dd2a62cb8d1a2ed182a368210aca","modified":1437813096000},{"_id":"themes/next/languages/fr-FR.yml","shasum":"9ee1011db6307df957684c83f39ac7499391924c","modified":1437813096000},{"_id":"themes/next/languages/ru.yml","shasum":"60cc1fb273adfd84137a207dd9d0d00f08605ccd","modified":1437813096000},{"_id":"themes/next/languages/zh-Hans.yml","shasum":"282620a222ea32c062610f4ed6af016f862ccdfa","modified":1437813096000},{"_id":"themes/next/languages/zh-hk.yml","shasum":"e58766e0af5abf0705ccca4a5fc86d1be03db198","modified":1437813096000},{"_id":"themes/next/languages/zh-tw.yml","shasum":"d34c5781a231978e66852784ad00c9895a7de022","modified":1437813096000},{"_id":"themes/next/layout/_layout.swig","shasum":"417cc254ba47a77b43f6f45e398756a0a9a424e9","modified":1437813096000},{"_id":"themes/next/layout/_macro/post-collapse.swig","shasum":"e0e16ca56917b51728a13453d0a2f932da7ecdcb","modified":1437813096000},{"_id":"themes/next/layout/_macro/post.swig","shasum":"9f3819f348a8a3af97c0fc520ea3944da5c3e4a9","modified":1437813096000},{"_id":"themes/next/layout/_macro/sidebar.swig","shasum":"939dbfc3de22706702da59e67293e1f243cbcf9f","modified":1437813096000},{"_id":"themes/next/layout/_partials/footer.swig","shasum":"b4b39dd010307ab61008a70a8ae9199ceeee89b5","modified":1437813096000},{"_id":"themes/next/layout/_partials/head.swig","shasum":"f2b7a6d43249622745a7d58daa11030f433d3c96","modified":1437813096000},{"_id":"themes/next/layout/_partials/header.swig","shasum":"c18888bd0a26f9bda3c6f7d17e22774a56f7378b","modified":1437813096000},{"_id":"themes/next/layout/_partials/old-browsers.swig","shasum":"dbbfea810bf3a2ed9c83b9a6683037175aacfc67","modified":1437813096000},{"_id":"themes/next/layout/_partials/pagination.swig","shasum":"d6c7f04eee4388d8f133eb5526b7c0875c321a30","modified":1437813096000},{"_id":"themes/next/layout/_partials/search/swiftype.swig","shasum":"ee0c2540e8178f390051af7d365a42ae68375afa","modified":1437813096000},{"_id":"themes/next/layout/_partials/search/tinysou.swig","shasum":"94beb0764ccbbba0c9f5c9886cc656bf879bcfd5","modified":1437813096000},{"_id":"themes/next/layout/_partials/search.swig","shasum":"8a18d32e2a257dafaaba75353692db901e1dddc5","modified":1437813096000},{"_id":"themes/next/layout/_partials/share/duoshuo_share.swig","shasum":"89c5a5240ecb223acfe1d12377df5562a943fd5d","modified":1437813096000},{"_id":"themes/next/layout/_partials/share/jiathis.swig","shasum":"63315fcf210799f894208c9f512737096df84962","modified":1437813096000},{"_id":"themes/next/layout/_scripts/analytics/baidu-analytics.swig","shasum":"7c43d66da93cde65b473a7d6db2a86f9a42647d6","modified":1437813096000},{"_id":"themes/next/layout/_scripts/analytics/google-analytics.swig","shasum":"30a23fa7e816496fdec0e932aa42e2d13098a9c2","modified":1437813096000},{"_id":"themes/next/layout/_scripts/analytics.swig","shasum":"0ebbf76c2317faa8ba31365adba59331c2e0262c","modified":1437813096000},{"_id":"themes/next/layout/_scripts/baidushare.swig","shasum":"d726361945437cf6e48067b3dd041b7e36e98d85","modified":1437813096000},{"_id":"themes/next/layout/_scripts/bootstrap.scrollspy.swig","shasum":"85295f126836b95f0837d03e58228bb3cf8c4490","modified":1437813096000},{"_id":"themes/next/layout/_scripts/comments/disqus.swig","shasum":"3491d3cebabc8a28857200db28a1be65aad6adc2","modified":1437813096000},{"_id":"themes/next/layout/_scripts/comments/duoshuo.swig","shasum":"3351ea62225933f8045d036a79654e19e84d19a7","modified":1437813096000},{"_id":"themes/next/layout/_scripts/fancy-box.swig","shasum":"41b4ff1446060c88c33bf666a32277dcf12129f0","modified":1437813096000},{"_id":"themes/next/layout/_scripts/helpers.swig","shasum":"4d2cbfca0aaf546a2b5813288073e824c1498fdf","modified":1437813096000},{"_id":"themes/next/layout/_scripts/mathjax.swig","shasum":"abc52fefb276c52cbb19de5c214521dfcf2a10fd","modified":1437813096000},{"_id":"themes/next/layout/_scripts/motion.swig","shasum":"817705bfd1a1282cb6bf59094afe507e11455aa0","modified":1437813096000},{"_id":"themes/next/layout/_scripts/pages/post-details.swig","shasum":"f0f34a08d99802c526486af58e11a6a9d1461fb1","modified":1437813096000},{"_id":"themes/next/layout/archive.swig","shasum":"ed242c832d27743375a5fb524dc5a116a6a723a7","modified":1437813096000},{"_id":"themes/next/layout/category.swig","shasum":"ca5b5b4c091e575487a398e5f1c0947fe3a13bfc","modified":1437813096000},{"_id":"themes/next/layout/index.swig","shasum":"9fcae9769998e5f4182b363ccf3ae5a026728d50","modified":1437813096000},{"_id":"themes/next/layout/page.swig","shasum":"0b0924774a562ff45ed98e40c4e913df9a77fe08","modified":1437813096000},{"_id":"themes/next/layout/post.swig","shasum":"3f3a183543cbb0d396484242952b02992366afef","modified":1437813096000},{"_id":"themes/next/layout/tag.swig","shasum":"f1dcfbc0eef76f1f6be29f31a343338d5bbfe814","modified":1437813096000},{"_id":"themes/next/source/css/_common/_component/back-to-top.styl","shasum":"88cd66910260006aa8e9e795df4948d4b67bfa11","modified":1437813096000},{"_id":"themes/next/source/css/_common/_component/buttons.styl","shasum":"81063e0979f04a0f9af37f321d7321dda9abf593","modified":1437813096000},{"_id":"themes/next/source/css/_common/_component/comments.styl","shasum":"54e73681ba6f57ef961138f94d2ee8ac845990c3","modified":1437813096000},{"_id":"themes/next/source/css/_common/_component/duoshuo.styl","shasum":"c307f1e4827d7cb82816a5f9de109ae14ed4199c","modified":1437813096000},{"_id":"themes/next/source/css/_common/_component/gallery.styl","shasum":"fa6e23ebddb6f235803b51974f36be2a43b2c9c4","modified":1437813096000},{"_id":"themes/next/source/css/_common/_component/jiathis.styl","shasum":"327b5f63d55ec26f7663185c1a778440588d9803","modified":1437813096000},{"_id":"themes/next/source/css/_common/_component/pagination.styl","shasum":"711c8830886619d4f4a0598b0cde5499dce50c62","modified":1437813096000},{"_id":"themes/next/source/css/_common/_component/posts-collapse.styl","shasum":"8f9e8f5f65956ccf1d52ff8526392803dff579d3","modified":1437813096000},{"_id":"themes/next/source/css/_common/_component/posts-expand.styl","shasum":"4b82dbbb6e536e6e8ee3cec6e62c2fd4bea60a09","modified":1437813096000},{"_id":"themes/next/source/css/_common/_component/posts-type.styl","shasum":"40b593134bf96d1d6095b3439d47820659d7f10b","modified":1437813096000},{"_id":"themes/next/source/css/_common/_component/tag-cloud.styl","shasum":"dd8a3b22fc2f222ac6e6c05bd8a773fb039169c0","modified":1437813096000},{"_id":"themes/next/source/css/_common/_core/base.styl","shasum":"e79a08484b191dca14ccfc005053eb95786dafae","modified":1437813096000},{"_id":"themes/next/source/css/_common/_core/helpers.styl","shasum":"41a31d651b60b4f458fc56a1d191dfbbdcb6d794","modified":1437813096000},{"_id":"themes/next/source/css/_common/_core/normalize.styl","shasum":"ece571f38180febaf02ace8187ead8318a300ea7","modified":1437813096000},{"_id":"themes/next/source/css/_common/_core/scaffolding.styl","shasum":"d776e241cf650b00ee1dd21b9ff377c250d9eeaa","modified":1437813096000},{"_id":"themes/next/source/css/_common/_core/tables.styl","shasum":"be6c1a04595cf38673511366a3d89fcdb046f533","modified":1437813096000},{"_id":"themes/next/source/css/_common/_fonts/icon-default.styl","shasum":"86bd4135afa2589ad074e0cf8ebb054ff3d10f24","modified":1437813096000},{"_id":"themes/next/source/css/_common/_fonts/icon-feather.styl","shasum":"f49f8966496166bd62f79f75a3277d4d5b1102e8","modified":1437813096000},{"_id":"themes/next/source/css/_common/_fonts/icon-fifty-shades.styl","shasum":"90e68936ea0f26af93c2c517fe1b891538f9c1b1","modified":1437813096000},{"_id":"themes/next/source/css/_common/_fonts/icon-font.styl","shasum":"6fd7caf8194656b90c3b7976295f157bce593b54","modified":1437813096000},{"_id":"themes/next/source/css/_common/_fonts/icon-linecons.styl","shasum":"3874252c8392b5a18e849ac69b6d66999ec1de16","modified":1437813096000},{"_id":"themes/next/source/css/_common/_page/archive.styl","shasum":"dff879f55ca65fa79c07e9098719e53eeea7ac88","modified":1437813096000},{"_id":"themes/next/source/css/_common/_page/categories.styl","shasum":"4f696a2eaeee2f214adcf273eab25c62a398077a","modified":1437813096000},{"_id":"themes/next/source/css/_common/_page/post-detail.styl","shasum":"73796f6f13caa7151a2ee8e55755627e0d189f55","modified":1437813096000},{"_id":"themes/next/source/css/_common/_section/body.styl","shasum":"ca1a4766cbe25baac757c6b47a4858d221afdc40","modified":1437813096000},{"_id":"themes/next/source/css/_common/_section/footer.styl","shasum":"8994ffcce84deac0471532f270f97c44fea54dc0","modified":1437813096000},{"_id":"themes/next/source/css/_common/_section/header.styl","shasum":"ba501332fb111bd72dc0777f2e1c8a29ad538ff9","modified":1437813096000},{"_id":"themes/next/source/css/_common/_section/layout.styl","shasum":"4daaadd156ece64ae05908ad6bb0159c8a27c071","modified":1437813096000},{"_id":"themes/next/source/css/_common/_section/media.styl","shasum":"fa9809d2ecc753cf32f70803c1d0821c405211f4","modified":1437813096000},{"_id":"themes/next/source/css/_common/_section/sidebar.styl","shasum":"d57e1769ebd2c472d2b27d17a706d3f564f94033","modified":1437813096000},{"_id":"themes/next/source/css/_common/_vendor/highlight/highlight.styl","shasum":"6259f4780f2aae1e6f85b892d8822c1c7ebc28bc","modified":1437813096000},{"_id":"themes/next/source/css/_common/_vendor/highlight/theme.styl","shasum":"ae19721ceee5ba460e131cb2427dae3c1ff39d6f","modified":1437813096000},{"_id":"themes/next/source/css/_custom/custom.styl","shasum":"68b6859fb48fe8358e567fc324f218cecfc3a533","modified":1437813096000},{"_id":"themes/next/source/css/_mixins/base.styl","shasum":"66985fe77bd323f7f8f634908e17166f51e96e95","modified":1437813096000},{"_id":"themes/next/source/css/_schemes/Mist/index.styl","shasum":"b0037a87ee1a613f315c331e8ecf1673c6d82211","modified":1437813096000},{"_id":"themes/next/source/css/_schemes/default/_menu.styl","shasum":"4bba29cece65ffc5122f4e052063dea4439fe4ae","modified":1437813096000},{"_id":"themes/next/source/css/_schemes/default/_search.styl","shasum":"05045d24850a982dc8069012c86c878b130b60eb","modified":1437813096000},{"_id":"themes/next/source/css/_schemes/default/index.styl","shasum":"2588e55132e10d82c0608f03c2c72a2bace8fa4e","modified":1437813096000},{"_id":"themes/next/source/css/_variables/Mist.styl","shasum":"f5dda1ca48c1b73a0bd34e08413de57699f24083","modified":1437813096000},{"_id":"themes/next/source/css/_variables/base.styl","shasum":"59acc8bf6e6b55f576b001e520e048cd0ca801fb","modified":1437813096000},{"_id":"themes/next/source/css/main.styl","shasum":"b05c342e94ded24a5f2b203cedf77d3faa817fd5","modified":1437813096000},{"_id":"themes/next/source/fonts/icon-default/icomoon.eot","shasum":"a58d5e893c6faefc90d5c2589cc314dff8ffca7a","modified":1437813096000},{"_id":"themes/next/source/fonts/icon-default/icomoon.svg","shasum":"4f18f0bb815b1aeba57739069c3416106240b7c1","modified":1437813096000},{"_id":"themes/next/source/fonts/icon-default/icomoon.ttf","shasum":"e6452f07b050ee0ff265b3b99a1e7ef82eb561b2","modified":1437813096000},{"_id":"themes/next/source/fonts/icon-default/icomoon.woff","shasum":"4d0adc55240f331c6de225e23afd76ea5318da9c","modified":1437813096000},{"_id":"themes/next/source/fonts/icon-feather/icomoon.eot","shasum":"6d0eb1a5bfef4f2bf77089bd090e88c5b2f7944d","modified":1437813096000},{"_id":"themes/next/source/fonts/icon-feather/icomoon.svg","shasum":"690836f81c0feb1a49e2253d4f984ad543414986","modified":1437813096000},{"_id":"themes/next/source/fonts/icon-feather/icomoon.ttf","shasum":"8c865cffa3845be32406737fcc0466cf9cd965b3","modified":1437813096000},{"_id":"themes/next/source/fonts/icon-feather/icomoon.woff","shasum":"9159eea8641b840e0f7aa6e087dae414044ecdd3","modified":1437813096000},{"_id":"themes/next/source/fonts/icon-fifty-shades/icomoon.eot","shasum":"f27c3643af6ed6f3d29a0be0c8dbea9b157857db","modified":1437813096000},{"_id":"themes/next/source/fonts/icon-fifty-shades/icomoon.svg","shasum":"f0790da03008b6cb3ae4215cbb656cb4b4599633","modified":1437813096000},{"_id":"themes/next/source/fonts/icon-fifty-shades/icomoon.ttf","shasum":"e0b5e4a23a949bac499908bcef2fae56430e230e","modified":1437813096000},{"_id":"themes/next/source/fonts/icon-fifty-shades/icomoon.woff","shasum":"088a16303b0700e1c9e2c6962240b4c2f0fc3aa4","modified":1437813096000},{"_id":"themes/next/source/fonts/icon-icomoon/icomoon.eot","shasum":"301fcf00c24750dddf1c529f944ca62c7f1a217d","modified":1437813096000},{"_id":"themes/next/source/fonts/icon-icomoon/icomoon.svg","shasum":"e316347805eb93425faa678611c5e42a7152da8f","modified":1437813096000},{"_id":"themes/next/source/fonts/icon-icomoon/icomoon.ttf","shasum":"f399713d1c9400d4d3373e38991a7e362a754a94","modified":1437813096000},{"_id":"themes/next/source/fonts/icon-icomoon/icomoon.woff","shasum":"05f1ec0bd307da5e731a86eb4961589a6042aebb","modified":1437813096000},{"_id":"themes/next/source/fonts/icon-linecons/icomoon.eot","shasum":"176695cc0dc12daba049b2bb889397a7bf2e553c","modified":1437813096000},{"_id":"themes/next/source/fonts/icon-linecons/icomoon.ttf","shasum":"c8ec218adabc788b17f976f60dd1c5fa872d9fc4","modified":1437813096000},{"_id":"themes/next/source/fonts/icon-linecons/icomoon.woff","shasum":"d1ed08a17670fa259df02c1d52dc9ce754343775","modified":1437813096000},{"_id":"themes/next/source/images/bkdefault_avatar.jpg","shasum":"b687bb4bfbe35a32b592c24d652ba80cfdc770fc","modified":1437813096000},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","shasum":"c6524ece3f8039a5f612feaf865d21ec8a794564","modified":1437813096000},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","shasum":"3031be41e8753c70508aa88e84ed8f4f653f157e","modified":1437813096000},{"_id":"themes/next/source/images/cc-by-nc.svg","shasum":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7","modified":1437813096000},{"_id":"themes/next/source/images/cc-by-nd.svg","shasum":"c563508ce9ced1e66948024ba1153400ac0e0621","modified":1437813096000},{"_id":"themes/next/source/images/cc-by-sa.svg","shasum":"aa4742d733c8af8d38d4c183b8adbdcab045872e","modified":1437813096000},{"_id":"themes/next/source/images/cc-by.svg","shasum":"28a0a4fe355a974a5e42f68031652b76798d4f7e","modified":1437813096000},{"_id":"themes/next/source/images/cc-zero.svg","shasum":"87669bf8ac268a91d027a0a4802c92a1473e9030","modified":1437813096000},{"_id":"themes/next/source/images/loading.gif","shasum":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1437813096000},{"_id":"themes/next/source/images/placeholder.gif","shasum":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1437813096000},{"_id":"themes/next/source/images/searchicon.png","shasum":"67727a6a969be0b2659b908518fa6706eed307b8","modified":1437813096000},{"_id":"themes/next/source/js/bootstrap.scrollspy.js","shasum":"ae7bdce88b515aade4eea8bf7407eec458bcd625","modified":1437813096000},{"_id":"themes/next/source/js/fancy-box.js","shasum":"116cafc741e048497287121a508d7a54c050c70c","modified":1437813096000},{"_id":"themes/next/source/js/helpers.js","shasum":"c2117b0ec653df4c45dd9d9575b190cbe1035335","modified":1437813096000},{"_id":"themes/next/source/js/lazyload.js","shasum":"b92e9acdc7afc15468314c03f4a643b0c93944cf","modified":1437813096000},{"_id":"themes/next/source/js/motion_fallback.js","shasum":"a767d522c65a8b2fbad49135c9332135c6785c3e","modified":1437813096000},{"_id":"themes/next/source/js/hook-duoshuo.js","shasum":"a7a618126d6853d52f4e32be116d3985325ad17d","modified":1437813096000},{"_id":"themes/next/source/js/motion_global.js","shasum":"e6df9e7e61109667df0e22c4f7cc25c85015440b","modified":1437813096000},{"_id":"themes/next/source/js/search-toggle.js","shasum":"0bf617514cd86307f0678a226761341100dd86d4","modified":1437813096000},{"_id":"themes/next/source/js/ua-parser.min.js","shasum":"acf0ee6a47ffb7231472b56e43996e3f947c258a","modified":1437813096000},{"_id":"themes/next/source/vendors/fancybox/source/blank.gif","shasum":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1437813096000},{"_id":"themes/next/source/vendors/fancybox/source/fancybox_loading.gif","shasum":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1437813096000},{"_id":"themes/next/source/vendors/fancybox/source/fancybox_loading@2x.gif","shasum":"273b123496a42ba45c3416adb027cd99745058b0","modified":1437813096000},{"_id":"themes/next/source/vendors/fancybox/source/fancybox_overlay.png","shasum":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1437813096000},{"_id":"themes/next/source/vendors/fancybox/source/fancybox_sprite.png","shasum":"17df19f97628e77be09c352bf27425faea248251","modified":1437813096000},{"_id":"themes/next/source/vendors/fancybox/source/fancybox_sprite@2x.png","shasum":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1437813096000},{"_id":"themes/next/source/vendors/fancybox/source/helpers/fancybox_buttons.png","shasum":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1437813096000},{"_id":"themes/next/source/vendors/fancybox/source/helpers/jquery.fancybox-buttons.css","shasum":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1437813096000},{"_id":"themes/next/source/vendors/fancybox/source/helpers/jquery.fancybox-buttons.js","shasum":"91e41741c2e93f732c82aaacec4cfc6e3f3ec876","modified":1437813096000},{"_id":"themes/next/source/vendors/fancybox/source/helpers/jquery.fancybox-media.js","shasum":"3bdf69ed2469e4fb57f5a95f17300eef891ff90d","modified":1437813096000},{"_id":"themes/next/source/vendors/fancybox/source/helpers/jquery.fancybox-thumbs.css","shasum":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1437813096000},{"_id":"themes/next/source/vendors/fancybox/source/helpers/jquery.fancybox-thumbs.js","shasum":"53e194f4a72e649c04fb586dd57762b8c022800b","modified":1437813096000},{"_id":"themes/next/source/vendors/fancybox/source/jquery.fancybox.css","shasum":"5f163444617b6cf267342f06ac166a237bb62df9","modified":1437813096000},{"_id":"themes/next/source/vendors/fancybox/source/jquery.fancybox.js","shasum":"1cf3d47b5ccb7cb6e9019c64f2a88d03a64853e4","modified":1437813096000},{"_id":"themes/next/source/vendors/fancybox/source/jquery.fancybox.pack.js","shasum":"53360764b429c212f424399384417ccc233bb3be","modified":1437813096000},{"_id":"themes/next/source/vendors/velocity/bower.json","shasum":"2ec99573e84c7117368beccb9e94b6bf35d2db03","modified":1437813096000},{"_id":"themes/next/source/vendors/velocity/velocity.min.js","shasum":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1437813096000},{"_id":"themes/next/source/vendors/velocity/velocity.ui.js","shasum":"6a1d101eab3de87527bb54fcc8c7b36b79d8f0df","modified":1437813096000},{"_id":"themes/next/source/vendors/velocity/velocity.ui.min.js","shasum":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1437813096000},{"_id":"themes/next/tests/helpers.js","shasum":"a1f5de25154c3724ffc24a91ddc576cdbd60864f","modified":1437813096000},{"_id":"themes/next/tests/intern.js","shasum":"11fa8a4f5c3b4119a179ae0a2584c8187f907a73","modified":1437813096000},{"_id":"themes/next/source/fonts/icon-linecons/icomoon.svg","shasum":"888a285a4a7329210b2210742c673611c27425eb","modified":1437813096000},{"_id":"themes/next/source/vendors/jquery/index.js","shasum":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1437813096000},{"_id":"themes/next/source/images/avatar.jpg","shasum":"e5f4f4550b8c1c4e5d63dce25668da4823b1dd52","modified":1437815845000},{"_id":"themes/next/source/vendors/velocity/velocity.js","shasum":"e63dc7cea055ca60a95d286f32349d88b10c5a4d","modified":1437813096000},{"_id":"public/vendors/velocity/velocity.ui.min.js","modified":1451705039321,"shasum":"ed5e534cd680a25d8d14429af824f38a2c7d9908"},{"_id":"public/vendors/velocity/velocity.ui.js","modified":1451705039325,"shasum":"6a1d101eab3de87527bb54fcc8c7b36b79d8f0df"},{"_id":"public/vendors/velocity/velocity.min.js","modified":1451705039328,"shasum":"2f1afadc12e4cf59ef3b405308d21baa97e739c6"},{"_id":"public/vendors/velocity/velocity.js","modified":1451705039330,"shasum":"9f08181baea0cc0e906703b7e5df9111b9ef3373"},{"_id":"public/vendors/velocity/bower.json","modified":1451705039332,"shasum":"0ef14e7ccdfba5db6eb3f8fc6aa3b47282c36409"},{"_id":"public/vendors/jquery/index.js","modified":1451705039333,"shasum":"41b4bfbaa96be6d1440db6e78004ade1c134e276"},{"_id":"public/vendors/fancybox/source/jquery.fancybox.pack.js","modified":1451705039334,"shasum":"53360764b429c212f424399384417ccc233bb3be"},{"_id":"public/vendors/fancybox/source/jquery.fancybox.js","modified":1451705039335,"shasum":"1cf3d47b5ccb7cb6e9019c64f2a88d03a64853e4"},{"_id":"public/vendors/fancybox/source/jquery.fancybox.css","modified":1451705039336,"shasum":"5f163444617b6cf267342f06ac166a237bb62df9"},{"_id":"public/vendors/fancybox/source/helpers/jquery.fancybox-thumbs.js","modified":1451705039337,"shasum":"53e194f4a72e649c04fb586dd57762b8c022800b"},{"_id":"public/vendors/fancybox/source/helpers/jquery.fancybox-thumbs.css","modified":1451705039339,"shasum":"4ac329c16a5277592fc12a37cca3d72ca4ec292f"},{"_id":"public/vendors/fancybox/source/helpers/jquery.fancybox-media.js","modified":1451705039340,"shasum":"3bdf69ed2469e4fb57f5a95f17300eef891ff90d"},{"_id":"public/vendors/fancybox/source/helpers/jquery.fancybox-buttons.js","modified":1451705039341,"shasum":"91e41741c2e93f732c82aaacec4cfc6e3f3ec876"},{"_id":"public/vendors/fancybox/source/helpers/jquery.fancybox-buttons.css","modified":1451705039342,"shasum":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8"},{"_id":"public/vendors/fancybox/source/helpers/fancybox_buttons.png","modified":1451705039346,"shasum":"e385b139516c6813dcd64b8fc431c364ceafe5f3"},{"_id":"public/vendors/fancybox/source/fancybox_sprite@2x.png","modified":1451705039349,"shasum":"30c58913f327e28f466a00f4c1ac8001b560aed8"},{"_id":"public/vendors/fancybox/source/fancybox_sprite.png","modified":1451705039351,"shasum":"17df19f97628e77be09c352bf27425faea248251"},{"_id":"public/vendors/fancybox/source/fancybox_overlay.png","modified":1451705039353,"shasum":"b3a4ee645ba494f52840ef8412015ba0f465dbe0"},{"_id":"public/vendors/fancybox/source/fancybox_loading@2x.gif","modified":1451705039354,"shasum":"273b123496a42ba45c3416adb027cd99745058b0"},{"_id":"public/vendors/fancybox/source/fancybox_loading.gif","modified":1451705039356,"shasum":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c"},{"_id":"public/vendors/fancybox/source/blank.gif","modified":1451705039358,"shasum":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a"},{"_id":"public/js/ua-parser.min.js","modified":1451705039360,"shasum":"acf0ee6a47ffb7231472b56e43996e3f947c258a"},{"_id":"public/js/search-toggle.js","modified":1451705039362,"shasum":"0bf617514cd86307f0678a226761341100dd86d4"},{"_id":"public/js/motion_global.js","modified":1451705039363,"shasum":"e6df9e7e61109667df0e22c4f7cc25c85015440b"},{"_id":"public/js/motion_fallback.js","modified":1451705039364,"shasum":"a767d522c65a8b2fbad49135c9332135c6785c3e"},{"_id":"public/js/lazyload.js","modified":1451705039366,"shasum":"b92e9acdc7afc15468314c03f4a643b0c93944cf"},{"_id":"public/js/hook-duoshuo.js","modified":1451705039367,"shasum":"e529f5d6dda3aee77fadfed879da9fe1fb570165"},{"_id":"public/js/helpers.js","modified":1451705039370,"shasum":"c2117b0ec653df4c45dd9d9575b190cbe1035335"},{"_id":"public/js/fancy-box.js","modified":1451705039375,"shasum":"116cafc741e048497287121a508d7a54c050c70c"},{"_id":"public/js/bootstrap.scrollspy.js","modified":1451705039379,"shasum":"ae7bdce88b515aade4eea8bf7407eec458bcd625"},{"_id":"public/images/searchicon.png","modified":1451705039381,"shasum":"67727a6a969be0b2659b908518fa6706eed307b8"},{"_id":"public/images/placeholder.gif","modified":1451705039383,"shasum":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b"},{"_id":"public/images/loading.gif","modified":1451705039386,"shasum":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b"},{"_id":"public/images/cc-zero.svg","modified":1451705039388,"shasum":"87669bf8ac268a91d027a0a4802c92a1473e9030"},{"_id":"public/images/cc-by.svg","modified":1451705039390,"shasum":"28a0a4fe355a974a5e42f68031652b76798d4f7e"},{"_id":"public/images/cc-by-sa.svg","modified":1451705039392,"shasum":"aa4742d733c8af8d38d4c183b8adbdcab045872e"},{"_id":"public/images/cc-by-nd.svg","modified":1451705039395,"shasum":"c563508ce9ced1e66948024ba1153400ac0e0621"},{"_id":"public/images/cc-by-nc.svg","modified":1451705039398,"shasum":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7"},{"_id":"public/images/cc-by-nc-sa.svg","modified":1451705039402,"shasum":"3031be41e8753c70508aa88e84ed8f4f653f157e"},{"_id":"public/images/cc-by-nc-nd.svg","modified":1451705039404,"shasum":"c6524ece3f8039a5f612feaf865d21ec8a794564"},{"_id":"public/images/bkdefault_avatar.jpg","modified":1451705039406,"shasum":"b687bb4bfbe35a32b592c24d652ba80cfdc770fc"},{"_id":"public/images/avatar.jpg","modified":1451705039408,"shasum":"e5f4f4550b8c1c4e5d63dce25668da4823b1dd52"},{"_id":"public/fonts/icon-linecons/icomoon.woff","modified":1451705039410,"shasum":"d1ed08a17670fa259df02c1d52dc9ce754343775"},{"_id":"public/fonts/icon-linecons/icomoon.ttf","modified":1451705039413,"shasum":"c8ec218adabc788b17f976f60dd1c5fa872d9fc4"},{"_id":"public/fonts/icon-linecons/icomoon.svg","modified":1451705039416,"shasum":"888a285a4a7329210b2210742c673611c27425eb"},{"_id":"public/fonts/icon-linecons/icomoon.eot","modified":1451705039418,"shasum":"176695cc0dc12daba049b2bb889397a7bf2e553c"},{"_id":"public/fonts/icon-icomoon/icomoon.woff","modified":1451705039420,"shasum":"05f1ec0bd307da5e731a86eb4961589a6042aebb"},{"_id":"public/fonts/icon-icomoon/icomoon.ttf","modified":1451705039424,"shasum":"f399713d1c9400d4d3373e38991a7e362a754a94"},{"_id":"public/fonts/icon-icomoon/icomoon.svg","modified":1451705039428,"shasum":"e316347805eb93425faa678611c5e42a7152da8f"},{"_id":"public/fonts/icon-icomoon/icomoon.eot","modified":1451705039430,"shasum":"301fcf00c24750dddf1c529f944ca62c7f1a217d"},{"_id":"public/fonts/icon-fifty-shades/icomoon.woff","modified":1451705039431,"shasum":"088a16303b0700e1c9e2c6962240b4c2f0fc3aa4"},{"_id":"public/fonts/icon-fifty-shades/icomoon.ttf","modified":1451705039433,"shasum":"e0b5e4a23a949bac499908bcef2fae56430e230e"},{"_id":"public/fonts/icon-fifty-shades/icomoon.svg","modified":1451705039434,"shasum":"f0790da03008b6cb3ae4215cbb656cb4b4599633"},{"_id":"public/fonts/icon-fifty-shades/icomoon.eot","modified":1451705039436,"shasum":"f27c3643af6ed6f3d29a0be0c8dbea9b157857db"},{"_id":"public/fonts/icon-feather/icomoon.woff","modified":1451705039438,"shasum":"9159eea8641b840e0f7aa6e087dae414044ecdd3"},{"_id":"public/fonts/icon-feather/icomoon.ttf","modified":1451705039440,"shasum":"8c865cffa3845be32406737fcc0466cf9cd965b3"},{"_id":"public/fonts/icon-feather/icomoon.svg","modified":1451705039442,"shasum":"690836f81c0feb1a49e2253d4f984ad543414986"},{"_id":"public/fonts/icon-feather/icomoon.eot","modified":1451705039445,"shasum":"6d0eb1a5bfef4f2bf77089bd090e88c5b2f7944d"},{"_id":"public/fonts/icon-default/icomoon.woff","modified":1451705039446,"shasum":"4d0adc55240f331c6de225e23afd76ea5318da9c"},{"_id":"public/fonts/icon-default/icomoon.ttf","modified":1451705039448,"shasum":"e6452f07b050ee0ff265b3b99a1e7ef82eb561b2"},{"_id":"public/fonts/icon-default/icomoon.svg","modified":1451705039450,"shasum":"4f18f0bb815b1aeba57739069c3416106240b7c1"},{"_id":"public/fonts/icon-default/icomoon.eot","modified":1451705039451,"shasum":"a58d5e893c6faefc90d5c2589cc314dff8ffca7a"},{"_id":"public/css/main.css","modified":1451705039886,"shasum":"9b08e245444bdd8050b75170d597826a657debed"},{"_id":"public/img/2015-02-14-1.png","modified":1451705039980,"shasum":"d3eb99aecefdc2c8bee9c14de90994bab5ed2c0d"},{"_id":"public/img/2015-02-14-1.dot","modified":1451705039984,"shasum":"da82da63bfaaff004c3d741690509d48a3a5ecec"},{"_id":"public/img/2015-02-14-0.png","modified":1451705039986,"shasum":"694abc328b0e4e3d955dda15a32e98a07d034f2a"},{"_id":"public/img/2015-02-14-0.dot","modified":1451705039988,"shasum":"ed9a5e347a0283408d2c9abb14e105edc0ad2286"},{"_id":"public/img/2015-01-30-1.jpg","modified":1451705039991,"shasum":"32912ad385a2263f99a84c63a0330c0b7093a566"},{"_id":"public/img/2015-01-30-0.jpg","modified":1451705039993,"shasum":"d76b63a8a15bdd5a1b2e012ee2e10bb1c13b461e"},{"_id":"public/img/2015-01-25-2.jpg","modified":1451705039996,"shasum":"1a42f75d4dfceab83969a0e7d7a3d67d938de2f9"},{"_id":"public/img/2015-01-25-1.jpg","modified":1451705040000,"shasum":"21b9ed0a8e2685331a565f20e7f554e6f6ee14d7"},{"_id":"public/img/2015-01-25-0.jpg","modified":1451705040003,"shasum":"627f105689f6a362275a41ec1ed6f24bd46fdbf2"},{"_id":"public/img/2014-12-28-0.png","modified":1451705040006,"shasum":"5a8f344ecb8494905f4fd3fc3eee81eb35d90708"},{"_id":"public/img/2013-06-29-0.png","modified":1451705040008,"shasum":"830f2f885c8a9ee208e48254956b5971456b5ff7"},{"_id":"public/img/2012-09-09-0.png","modified":1451705040010,"shasum":"e75691d34f672d2ee9be89f8bb6e1e10217603f6"},{"_id":"public/img/2012-09-02-5.png","modified":1451705040013,"shasum":"82fffe663e491fbb49b060c9767aab9b951899a6"},{"_id":"public/img/2012-09-02-4.png","modified":1451705040016,"shasum":"89e3783d740c3b13d2643d1b4211565973e92292"},{"_id":"public/img/2012-09-02-3.png","modified":1451705040018,"shasum":"6d39c219fa056f4bd831a1cfd228bb6136ddaef4"},{"_id":"public/img/2012-09-02-2.png","modified":1451705040021,"shasum":"1a745b2042cffdffb3c3c639aaecce9994a70575"},{"_id":"public/img/2012-09-02-1.png","modified":1451705040025,"shasum":"8afb5dfc6871080c68da765dca199034ae1f1f60"},{"_id":"public/img/2012-09-02-0.png","modified":1451705040027,"shasum":"0a18664b44b7ddc501c795c0d7c40e0bd2fd83cd"},{"_id":"public/favicon.ico","modified":1451705040031,"shasum":"e5f4f4550b8c1c4e5d63dce25668da4823b1dd52"},{"_id":"public/tags/index.html","modified":1451705040123,"shasum":"9505551c687e74a714811a68d088d64fbb1f8ec9"},{"_id":"public/categories/index.html","modified":1451705040167,"shasum":"35c4f5d077536636d834f2e39be5e83c867a9fe1"},{"_id":"public/about/index.html","modified":1451705040210,"shasum":"d5df83d0d617e37c82a27e7b7096327faa9a77f1"},{"_id":"public/2015/12/31//2015/12-31-0.html/index.html","modified":1451705040280,"shasum":"00fc71e84d145a5dbec18a1a23f0ce7287c7fc9f"},{"_id":"public/2015/12/30//2015/12-30-0.html/index.html","modified":1451705040339,"shasum":"a344571acbc908a5f2e5c92f765c176ef4096849"},{"_id":"public/2015/02/14//2015/02-14-0.html/index.html","modified":1451705040418,"shasum":"c722b5fb4bf3fd99ec73e4bed296e4b495be2093"},{"_id":"public/2015/02/01//2015/02-01-0.html/index.html","modified":1451705040500,"shasum":"264c2b5bc9a5ef8f42a055bc817149d6507dca1a"},{"_id":"public/2015/01/30//2015/01-30-0.html/index.html","modified":1451705040545,"shasum":"6fab4d8498a591833a3235aa295ccd91d7ee0af2"},{"_id":"public/2015/01/25//2015/01-25-0.html/index.html","modified":1451705040592,"shasum":"6649461142fd08da80f6d083eae132a734a28fcf"},{"_id":"public/2015/01/23//2015/01-23-0.html/index.html","modified":1451705040629,"shasum":"195a46c040bd16f11485fdd30eb12935081931ef"},{"_id":"public/2015/01/22//2015/01-22-0.html/index.html","modified":1451705040675,"shasum":"5aef37d64905a7833fca47e97cdfbcd5d02e4f9d"},{"_id":"public/2014/12/28//2014/12-28-2.html/index.html","modified":1451705040709,"shasum":"d934fe281c573250b42e59a9207eac0f0b7adf0b"},{"_id":"public/2014/12/28//2014/12-28-1.html/index.html","modified":1451705040751,"shasum":"bcffb5fcd2eee2ac1e839eda108d36147564fa75"},{"_id":"public/2014/12/28//2014/12-28-0.html/index.html","modified":1451705040784,"shasum":"900fd362059ca40f56ede4f23b15c671a324f042"},{"_id":"public/2014/12/27//2014/12-27-2.html/index.html","modified":1451705040823,"shasum":"a5c8c9d2bf5ee4aaae54f7fb908ecf870524a18f"},{"_id":"public/2014/12/27//2014/12-27-3.html/index.html","modified":1451705040864,"shasum":"c57f736f462274825a878567d4c39c1805e7ffea"},{"_id":"public/2014/12/27//2014/12-27-0.html/index.html","modified":1451705040895,"shasum":"d71f97cf3b35b13fae02a6dd3140ed932fde8c70"},{"_id":"public/2014/12/27//2014/12-27-1.html/index.html","modified":1451705040934,"shasum":"277447d2cb1052eb81d961cadaefedbd6b4f7f37"},{"_id":"public/2014/12/12//2014/12-12-0.html/index.html","modified":1451705040966,"shasum":"226403dea9fdad0fdf70726dcfc5779a449aa086"},{"_id":"public/2014/12/08//2014/12-08-0.html/index.html","modified":1451705041008,"shasum":"8bc5ff912174259933ee45dc8e741e7e90a747f5"},{"_id":"public/2014/12/07//2014/12-07-0.html/index.html","modified":1451705041040,"shasum":"f8383bca0b7bd6fd965dcaa0a2ac7eea7ddf762b"},{"_id":"public/2014/12/01//2014/12-01-0.html/index.html","modified":1451705041081,"shasum":"0fc51ba33f1fcaa0e6baf27facf01930199b99c3"},{"_id":"public/2014/11/20//2014/11-20-0.html/index.html","modified":1451705041124,"shasum":"97ac7510f8172dc89326eb3be4f1e4cad4e7e715"},{"_id":"public/2014/11/18//2014/11-18-0.html/index.html","modified":1451705041157,"shasum":"522d827114b3bdcc7796f5e1d129f78fce9342fb"},{"_id":"public/2014/11/16//2014/11-16-0.html/index.html","modified":1451705041198,"shasum":"1c1c72cc43d21e1d5e0a935e1558cf867cb5f5cc"},{"_id":"public/2014/11/14//2014/11-14-0.html/index.html","modified":1451705041230,"shasum":"de2d1e7b24d831dfdf8b4327fbc46f0484e5f8e5"},{"_id":"public/2014/08/09//2014/08-09-2.html/index.html","modified":1451705041272,"shasum":"15ba7b18a2e1a1229c2cbe33e21009a3013758e2"},{"_id":"public/2014/08/09//2014/08-09-1.html/index.html","modified":1451705041304,"shasum":"ff8f2f88848c5479873d09884b9446752e1edc7c"},{"_id":"public/2014/08/09//2014/08-09-0.html/index.html","modified":1451705041344,"shasum":"b940ca254946ea1af062785992635ccc4929878e"},{"_id":"public/2014/07/03//2014/07-03-0.html/index.html","modified":1451705041381,"shasum":"43a0851964dea7b18de4dca4f3f33b593d6323d0"},{"_id":"public/2013/07/28//2013/07-28-0.html/index.html","modified":1451705041417,"shasum":"691ff25cd74924d761c7f3f29df90e453fd90a20"},{"_id":"public/2013/07/27//2013/07-27-0.html/index.html","modified":1451705041458,"shasum":"40069e96d4ef67db72ee4bea187f7167619cb6ef"},{"_id":"public/2013/07/17//2013/07-17-0.html/index.html","modified":1451705041491,"shasum":"ebf0c25dc99b5b2873ca7f658c04e6b8bf94ba3a"},{"_id":"public/2013/07/15//2013/07-15-0.html/index.html","modified":1451705041532,"shasum":"08d4d79da353ebbf8ca6a10b31d991c3b63611a1"},{"_id":"public/2013/06/29//2013/06-29-0.html/index.html","modified":1451705041564,"shasum":"653ce2e4ca2bd3b2e54e04523e22e2fccc277bc3"},{"_id":"public/2013/06/23//2013/06-23-0.html/index.html","modified":1451705041601,"shasum":"2b56bc993c255a562b96c742fbd35336669061f5"},{"_id":"public/2013/06/22//2013/06-22-0.html/index.html","modified":1451705041641,"shasum":"c11efc7904a50c66c7d6b3cea3b0f92f38b27758"},{"_id":"public/2013/03/25//2013/03-25-0.html/index.html","modified":1451705041675,"shasum":"9118ad99876c70689a4f1efae64708bab5b3ca4e"},{"_id":"public/2013/03/24//2013/03-24-0.html/index.html","modified":1451705041720,"shasum":"5b064da18e3451cd1489653fc68405ca828de5bd"},{"_id":"public/2012/09/09//2012/09-09-0.html/index.html","modified":1451705041755,"shasum":"669960726a4ca8bfc08e0196de3d2aa47807e92e"},{"_id":"public/2012/09/02//2012/09-02-0.html/index.html","modified":1451705041800,"shasum":"6e06af5cea8c55bb2be5d4e416a9402b55e526fb"},{"_id":"public/2011/12/15//2011/12-15-0.html/index.html","modified":1451705041837,"shasum":"f641e10fc3de6230e3a1e605ae593d30b6766d25"},{"_id":"public/2011/10/16//2011/10-16-0.html/index.html","modified":1451705041877,"shasum":"dedd50718cdef595a7dee603dfaa42ac23deeaf6"},{"_id":"public/2011/10/07//2011/10-07-0.html/index.html","modified":1451705041918,"shasum":"ce7e1e711783c8896e6fa0a44cc706dfb43d2ee2"},{"_id":"public/2011/06/04//2011/06-04-0.html/index.html","modified":1451705041956,"shasum":"b0ddb958516a50517ae8bf49850d2571ef7b3d86"},{"_id":"public/2011/05/29//2011/05-29-0.html/index.html","modified":1451705041995,"shasum":"fdaa0cd63a7bb90bae7263ac41e608b48aa736e6"},{"_id":"public/2010/09/03//2010/09-03-0.html/index.html","modified":1451705042030,"shasum":"f74df4eed7e635b0bcdbe6df61469bfe6a7ceb1d"},{"_id":"public/2010/08/02//2010/08-02-0.html/index.html","modified":1451705042070,"shasum":"38d124c4af191fab397b6c4f2160d3818b2cca90"},{"_id":"public/2010/07/03//2010/07-03-0.html/index.html","modified":1451705042107,"shasum":"7c3e66296e25768c97f7fef99e1a0ec29f81fd23"},{"_id":"public/archives/index.html","modified":1451705042139,"shasum":"85c95b43e7ef8e1bd7f734fc06be384fc0a6ea0f"},{"_id":"public/archives/page/2/index.html","modified":1451705042174,"shasum":"6e4a7ff3f87c242ac914b2b2e378d3ea0c40bda6"},{"_id":"public/archives/page/3/index.html","modified":1451705042202,"shasum":"5b6261cae22bc2eaf12565156d3f57279caf749a"},{"_id":"public/archives/page/4/index.html","modified":1451705042236,"shasum":"cff01778e3f4c6ae48cf599f4fbbcaf7ab6ef5ab"},{"_id":"public/archives/page/5/index.html","modified":1451705042261,"shasum":"ad8126db3e4abe0b7213ecc70da03d59664c20db"},{"_id":"public/archives/page/6/index.html","modified":1451705042290,"shasum":"11866f748b17aa3c2e49c175b1d404d6e4491eb7"},{"_id":"public/archives/page/7/index.html","modified":1451705042325,"shasum":"0e9db4185a2b4cdf6cdb9aa2b267634e47ae0656"},{"_id":"public/archives/page/8/index.html","modified":1451705042354,"shasum":"b1cd9f9b1aa379877d92fe627003b515b9cac8a4"},{"_id":"public/archives/page/9/index.html","modified":1451705042379,"shasum":"275d633979a3a0a2138764748545d3e9172c0809"},{"_id":"public/archives/page/10/index.html","modified":1451705042413,"shasum":"2b64c01e2cbd2cfad911f32d64a2e4ad7f3608ff"},{"_id":"public/archives/2010/index.html","modified":1451705042436,"shasum":"1e2a865307094f2412030894ccb03f83ea95d356"},{"_id":"public/archives/2010/07/index.html","modified":1451705042462,"shasum":"162a2d9453b204c137414d0469608766624ee6fb"},{"_id":"public/archives/2010/08/index.html","modified":1451705042494,"shasum":"c8892dd3955172058b43c3fd2a6009d367a69db1"},{"_id":"public/archives/2010/09/index.html","modified":1451705042521,"shasum":"da50704e2b82a05f2ce0a17cb0a93ff5004a1117"},{"_id":"public/archives/2011/index.html","modified":1451705042548,"shasum":"b9e2649a4f6d8c8e6d939ecbb978f158c4c6762c"},{"_id":"public/archives/2011/page/2/index.html","modified":1451705042581,"shasum":"9361e75f3285b20daa75b40758d3e2d025eb3c3f"},{"_id":"public/archives/2011/05/index.html","modified":1451705042604,"shasum":"23bd9ab617b2039cd988a9e8245a3bda39ab72cf"},{"_id":"public/archives/2011/06/index.html","modified":1451705042630,"shasum":"fcb0b46c9fd8bfe41cb698c75f272f3e9f3ed481"},{"_id":"public/archives/2011/10/index.html","modified":1451705042665,"shasum":"3b675039d8192721bc27ea8f93ca7c2d38beddf0"},{"_id":"public/archives/2011/12/index.html","modified":1451705042691,"shasum":"d696468304bb7e0de827976dadea8283142b8efa"},{"_id":"public/archives/2012/index.html","modified":1451705042716,"shasum":"78866cba45a5d9d683db6a35a776d9cccd9ab4d0"},{"_id":"public/archives/2012/09/index.html","modified":1451705042749,"shasum":"a1f3c916e046588acdaa4cc26493d62b8668c97c"},{"_id":"public/archives/2013/index.html","modified":1451705042775,"shasum":"74bd5545b692cf5b5690d2c414d28f5f66f2031b"},{"_id":"public/archives/2013/page/2/index.html","modified":1451705042804,"shasum":"22b216d192d74af56c2e0c310f280acbf52d7d43"},{"_id":"public/archives/2013/03/index.html","modified":1451705042834,"shasum":"2905d814cabe9b85f88450f01ae790256e4fc588"},{"_id":"public/archives/2013/06/index.html","modified":1451705042862,"shasum":"44f4a8182e625c3c344f9af855e6f999619efb61"},{"_id":"public/archives/2013/07/index.html","modified":1451705042889,"shasum":"99a8c0117090494932efda535aaa12a6858b84c7"},{"_id":"public/archives/2014/index.html","modified":1451705042925,"shasum":"4e5782bd1fabf426c1ac22b43ea903ebc1d3a376"},{"_id":"public/archives/2014/page/2/index.html","modified":1451705042955,"shasum":"13c431aa2425158995defa619a49c89f95939c64"},{"_id":"public/archives/2014/page/3/index.html","modified":1451705042985,"shasum":"a74b57a9092eaf016cba252f30868f2e4c0f2f5c"},{"_id":"public/archives/2014/page/4/index.html","modified":1451705043017,"shasum":"8a58bcadb424cb7914e76506191d79ed98033842"},{"_id":"public/archives/2014/07/index.html","modified":1451705043042,"shasum":"043dad813bc9b2c8eaf8aa1423be45b90f713a4c"},{"_id":"public/archives/2014/08/index.html","modified":1451705043068,"shasum":"5ede50c6368a947469a553d1d813fd433c7bf16c"},{"_id":"public/archives/2014/11/index.html","modified":1451705043101,"shasum":"d048a5ee9e64ef462b7c603955727e3d9315a200"},{"_id":"public/archives/2014/12/index.html","modified":1451705043128,"shasum":"a56687072e06f34036b1453ad507a997e48a7033"},{"_id":"public/archives/2014/12/page/2/index.html","modified":1451705043157,"shasum":"b6bd86c983c9e1497be3d4d25cce245799387631"},{"_id":"public/archives/2014/12/page/3/index.html","modified":1451705043187,"shasum":"2ca289909b8263729d8eb5f3dc80f26d523f134f"},{"_id":"public/archives/2015/index.html","modified":1451705043213,"shasum":"4a7523e41850b5cb03bc1bf3d5145d0df1065ae5"},{"_id":"public/archives/2015/page/2/index.html","modified":1451705043243,"shasum":"ae1333cbfd6c7f999faa626d7adeebb01b15723c"},{"_id":"public/archives/2015/01/index.html","modified":1451705043278,"shasum":"2b2565e79a2d0d2ab767cca1acb58eaa5a32e922"},{"_id":"public/archives/2015/02/index.html","modified":1451705043302,"shasum":"ed615a62166a8b8e7c298e7015289ea8ced856a4"},{"_id":"public/archives/2015/12/index.html","modified":1451705043331,"shasum":"c27c1402af0f833a0a5a02fceb23600314d18145"},{"_id":"public/index.html","modified":1451705043379,"shasum":"4aa31a7ca6b0b64bb52f17b7eae91d1429c6097d"},{"_id":"public/page/2/index.html","modified":1451705043419,"shasum":"175377de5945cc89e3e3e76a15232e1b3b132a35"},{"_id":"public/page/3/index.html","modified":1451705043463,"shasum":"7062487c1e54759a15fc7fdfe0932035c1da0e66"},{"_id":"public/page/4/index.html","modified":1451705043504,"shasum":"401ac62e41310d31a11682e97353040383769461"},{"_id":"public/page/5/index.html","modified":1451705043550,"shasum":"b9f04334e7f733448b14126d6f6ef1003e59ad17"},{"_id":"public/page/6/index.html","modified":1451705043587,"shasum":"555f3680b556a3c045438b48d6cbf064df162c0a"},{"_id":"public/page/7/index.html","modified":1451705043626,"shasum":"e6a11ef33d34cd37f7c302c728f12a07a166fe81"},{"_id":"public/page/8/index.html","modified":1451705043671,"shasum":"3bf95e0ef39c4c094dab738d9b20c7faf8c452da"},{"_id":"public/page/9/index.html","modified":1451705043708,"shasum":"07dd09c277ef72ff30fcc0d89ea66916f941d10e"},{"_id":"public/page/10/index.html","modified":1451705043757,"shasum":"158969ce492c0220047f03290c5aa773ebc48c65"},{"_id":"public/categories/c-c/index.html","modified":1451705043782,"shasum":"2384384b77fe68b4dee77067e7ad17db43c9e115"},{"_id":"public/categories/我的计划/index.html","modified":1451705043806,"shasum":"7209eb7f5379467904b35fef5299212fc6ba73a6"},{"_id":"public/categories/iOS/index.html","modified":1451705043838,"shasum":"a9c1b45a6aeb189a4193f1837e42453cba611d1a"},{"_id":"public/categories/算法/index.html","modified":1451705043867,"shasum":"a49545956643a4af0c4be2544abd33a12b05bb0c"},{"_id":"public/categories/算法/page/2/index.html","modified":1451705043892,"shasum":"e4d5f12cb9a232451ea36669b8c83fbdd0e0db5c"},{"_id":"public/categories/算法/page/3/index.html","modified":1451705043929,"shasum":"f95228f10405ed36366552f4865496c019590437"},{"_id":"public/categories/算法/page/4/index.html","modified":1451705043952,"shasum":"4960d3b083539779f57a2a7516362923520bcb15"},{"_id":"public/categories/服务器编程/index.html","modified":1451705043980,"shasum":"e4448645c8f3d3f731e5228d57d623dfd402ad52"},{"_id":"public/categories/服务器编程/page/2/index.html","modified":1451705044013,"shasum":"c3ce17c56303dfde21b148cc8ac12eacc6675079"},{"_id":"public/categories/golang/index.html","modified":1451705044044,"shasum":"4e83d48d305d11c5c7f7a46a1c6cbb39f968f64c"},{"_id":"public/categories/编程思维/index.html","modified":1451705044068,"shasum":"aa10a6fbb295e34a5aa524115f486bd1c08b158c"},{"_id":"public/categories/lua/index.html","modified":1451705044091,"shasum":"8bbd78a9533187b7fb9feaf03026fa137f8df1f7"},{"_id":"public/categories/杂感/index.html","modified":1451705044125,"shasum":"22d6f57132ee6c1262b4c51b793b8397d895ae6b"},{"_id":"public/categories/游戏开发/index.html","modified":1451705044153,"shasum":"dffb55d2feb1d8947070e5348ccc87eb7ae131f2"},{"_id":"public/categories/设计模式/index.html","modified":1451705044181,"shasum":"3e082a43afecd760e764f41e24f36ffc6d3a668e"},{"_id":"public/categories/lisp/index.html","modified":1451705044213,"shasum":"66395dc322b057bc5a2a9a2452fd72f159994cad"},{"_id":"public/tags/设计/index.html","modified":1451705044240,"shasum":"d3a7365f7ed31395f39c1badeb4e6e9f229e97d6"},{"_id":"public/tags/设计/page/2/index.html","modified":1451705044267,"shasum":"ee8d0db469974ff814efdf82f8b174e8b5ebaf63"},{"_id":"public/tags/代码质量/index.html","modified":1451705044301,"shasum":"9b236efa913990e884c985e4483200fb5d4c14fa"},{"_id":"public/tags/性能/index.html","modified":1451705044337,"shasum":"3da1a8d82fdd6540b025bbfb9d53bf7dbd3f8303"},{"_id":"public/tags/性能/page/2/index.html","modified":1451705044365,"shasum":"33aeae6be3cdce6857e5278e32fbed9c4e1b5f6d"},{"_id":"public/tags/计划/index.html","modified":1451705044392,"shasum":"1b12c3ed13b227be9206caeb5dd80251352cde96"},{"_id":"public/tags/iOS入门/index.html","modified":1451705044431,"shasum":"806a45581351ab595e1fb4efb9b9f368e998376b"},{"_id":"public/tags/查找/index.html","modified":1451705044464,"shasum":"4aec3198ddb683676950adb2b2b396623d5ed487"},{"_id":"public/tags/架构/index.html","modified":1451705044494,"shasum":"b065aa506d439dd4e81c8ec58cd14f0fa7834ab1"},{"_id":"public/tags/排序/index.html","modified":1451705044540,"shasum":"e85ab356af48bde0159af05dfa9cc97879b5e198"},{"_id":"public/tags/排序/page/2/index.html","modified":1451705044572,"shasum":"8efec1a72bbac60c156732cfc51cafc245c62709"},{"_id":"public/tags/union-find/index.html","modified":1451705044609,"shasum":"e0b6c5ee7f03ca76525f9201bad1c9a9472280d4"},{"_id":"public/tags/pprof/index.html","modified":1451705044649,"shasum":"fd1d064629295f6bceb97308a3b0540dbb5d3de0"},{"_id":"public/tags/面试题/index.html","modified":1451705044684,"shasum":"e22fd99395653ce664186a7d261080c04c86a2ff"},{"_id":"public/tags/小技巧/index.html","modified":1451705044724,"shasum":"4507c975f81e9f9cfe69ebe5216d1e4dbd53dc9f"},{"_id":"public/tags/元编程/index.html","modified":1451705044756,"shasum":"e559ab9b29654adec04b10f83181d2415d341c17"},{"_id":"public/tags/内存管理/index.html","modified":1451705044797,"shasum":"a4c18948f5d5fabb512c40753ee907b735ed95e0"},{"_id":"public/tags/面向对象/index.html","modified":1451705044828,"shasum":"7a1df4a6b100e7ce4f0afc13118298dbb71bbf26"},{"_id":"public/tags/网络I-O/index.html","modified":1451705044897,"shasum":"99fcf5445503a7b38f70854eb5b31873c6d7bab6"},{"_id":"public/tags/openGL/index.html","modified":1451705044928,"shasum":"181ea952af0ed97dadc634de02658c996880aff0"},{"_id":"public/tags/高阶函数/index.html","modified":1451705044962,"shasum":"d8963730e75099f5de0affe86cacc84e440fe7ac"},{"_id":"public/tags/基础/index.html","modified":1451705044988,"shasum":"714a496dbb8edfe0b28f312da4f8a588d012017e"},{"_id":"public/sitemap.xml","modified":1451800025478,"shasum":"32c564c1ece00c42fdfaa8de471611da498766fe"},{"_id":"public/baidusitemap.xml","modified":1451800515285,"shasum":"fd8248221a15604e03a0b404248e1f5c8561a1c6"}],"Category":[{"name":"c/c++","_id":"ciiwjp2y40001of6g1j0xtk6a"},{"name":"我的计划","_id":"ciiwjp2yv000dof6gfnf95ypv"},{"name":"iOS","_id":"ciiwjp2yy000iof6ge41e7ll0"},{"name":"算法","_id":"ciiwjp2z1000nof6gk2xv516u"},{"name":"服务器编程","_id":"ciiwjp2z3000sof6gr0zjg7xx"},{"name":"golang","_id":"ciiwjp3070028of6g0lmx51jb"},{"name":"编程思维","_id":"ciiwjp30i002pof6gd9xgesb3"},{"name":"lua","_id":"ciiwjp30l002wof6gztk38zpp"},{"name":"杂感","_id":"ciiwjp30p0035of6gcezpbnpf"},{"name":"游戏开发","_id":"ciiwjp30r0038of6gcul9a1kg"},{"name":"设计模式","_id":"ciiwjp31m0042of6glg0ia1ue"},{"name":"lisp","_id":"ciiwjp31s0049of6gefjc1nwo"}],"Data":[],"Page":[{"title":"tags","date":"2015-01-24T03:10:55.000Z","type":"tags","_content":"","source":"tags/index.md","raw":"title: tags\ndate: 2015-01-24 11:10:55\ntype: tags\n---\n","updated":"2015-07-25T08:45:59.000Z","path":"tags/index.html","comments":1,"layout":"page","_id":"ciiwjp2ym0009of6gp1eylwcc"},{"title":"categories","date":"2015-01-24T03:12:50.000Z","type":"categories","_content":"","source":"categories/index.md","raw":"title: categories\ndate: 2015-01-24 11:12:50\ntype: categories\n---\n","updated":"2015-07-25T08:45:09.000Z","path":"categories/index.html","comments":1,"layout":"page","_id":"ciiwjp2yq000aof6g87hb2rig"},{"title":"About Me","description":null,"_content":"\n这家伙很懒，什么也没有留下。\n-------------------------\n\n似乎不写点东西，对不起这2块钱的特效。所以就胡乱扯点吧。\n\n1. **波大**       \n小Coder毕业于[波大](http://www.nbu.edu.cn)，没错，你没有看错，就是远近文明的[波大](http://www.nbu.edu.cn)。那么，问题来了，波大的妹子真的波大么？这个，请各位看官自行移步到[波大妹子](https://www.google.com/search?q=%E5%AE%81%E6%B3%A2%E5%A4%A7%E5%AD%A6%E5%A6%B9%E5%AD%90&biw=1366&bih=643&source=lnms&tbm=isch&sa=X&ei=kyiVVLyuPImsoQTjoYDoDA&ved=0CAcQ_AUoAg)。\n2. **sky-mobi**  \n毕业后辗转来到天堂之一的杭州，就职于“中国移动互联网纳斯达克第一股“的[sky-mobi](http://www.mopo.com/)，先后参加自研游戏引擎，2款手游研发。说实话，无论是引擎还是手游，都算是失败的，说得心塞呐。\n3. **tencent--MIG**  \n人生第一次跳槽，进入[腾讯](http://www.tencent.com)，担任后台开发，请关注我们的产品--[应用宝](sj.qq.com)。\n4. **tencent--SNG**\n加入[QQ物联](http://iot.open.qq.com/)，进入物联网大军，成为杂兵一枚，iOS/Android移动终端开发。\n5. **人生之路漫漫**  \nMove on...\n\n\n联系我\n----------\n\n+ [GitHub](https://github.com/zhujiefirst)\n+ [豆瓣](http://www.douban.com/people/44265520/)\n+ [Weibo](http://weibo.com/u/2421642590)\n+ [Twitter](https://twitter.com/Jay1002008)\n+ <a href=\"mailto:zhujiefirst@gmail.com\">Mail</a>\n","source":"about/index.md","raw":"---\ntitle : About Me\ndescription:\n---\n\n这家伙很懒，什么也没有留下。\n-------------------------\n\n似乎不写点东西，对不起这2块钱的特效。所以就胡乱扯点吧。\n\n1. **波大**       \n小Coder毕业于[波大](http://www.nbu.edu.cn)，没错，你没有看错，就是远近文明的[波大](http://www.nbu.edu.cn)。那么，问题来了，波大的妹子真的波大么？这个，请各位看官自行移步到[波大妹子](https://www.google.com/search?q=%E5%AE%81%E6%B3%A2%E5%A4%A7%E5%AD%A6%E5%A6%B9%E5%AD%90&biw=1366&bih=643&source=lnms&tbm=isch&sa=X&ei=kyiVVLyuPImsoQTjoYDoDA&ved=0CAcQ_AUoAg)。\n2. **sky-mobi**  \n毕业后辗转来到天堂之一的杭州，就职于“中国移动互联网纳斯达克第一股“的[sky-mobi](http://www.mopo.com/)，先后参加自研游戏引擎，2款手游研发。说实话，无论是引擎还是手游，都算是失败的，说得心塞呐。\n3. **tencent--MIG**  \n人生第一次跳槽，进入[腾讯](http://www.tencent.com)，担任后台开发，请关注我们的产品--[应用宝](sj.qq.com)。\n4. **tencent--SNG**\n加入[QQ物联](http://iot.open.qq.com/)，进入物联网大军，成为杂兵一枚，iOS/Android移动终端开发。\n5. **人生之路漫漫**  \nMove on...\n\n\n联系我\n----------\n\n+ [GitHub](https://github.com/zhujiefirst)\n+ [豆瓣](http://www.douban.com/people/44265520/)\n+ [Weibo](http://weibo.com/u/2421642590)\n+ [Twitter](https://twitter.com/Jay1002008)\n+ <a href=\"mailto:zhujiefirst@gmail.com\">Mail</a>\n","date":"2015-07-25T07:08:17.000Z","updated":"2015-07-25T07:08:17.000Z","path":"about/index.html","comments":1,"layout":"page","_id":"ciiwjp2yr000bof6g3sck8e1e"}],"Post":[{"date":"2010-07-02T16:00:00.000Z","layout":"post","title":"优化程序性能","_content":"\n\n编写高效程序需要两个活动：第一，我们必须选择一组最好的算法和数据结构；第二，我们必须编写出编译器能够有效优化以转换成高效可执行代码的源 代码。这里，我们主要讲述后者。\n\n首先，我们討論一下为什么要编写高效程序。不难想象，如果本来要用１０天运行完的程序，经过优化只需要１天就可运行完，这是一件多么令人振奋的 事啊。时间就是金钱呐。那么，什么时候才有必要优化。什么？优化不是无论什么时候都有必要的吗？太不可思议了！当然，作为一个程序员，我们必做在实现与维 护程序的简单性与它的运行速度之间做出权衡折衷。对于一个只会运行一次以产生一组数据点的程序，以一种尽量减少编程工作量并保证正确性来编写程序就更为重 要了。考虑一下，比如一个只用一次的算法，编写时间加上运行时间不超过一天，然而我们花上三天来优化这个算法让它只要一个小时就能出結果。乍一看多好的优 化啊，三天变成一小时！等等，让我们来算一算。不优化编写加运行时候只要一天，而优化后呢？三天加一小时！当然，如果这个算法反复执行的话，我们对它的优 化就值得肯定了。\n\n好了，说了这么多，切入正题，怎样才能在优码级别上进行优化呢？做那些编译器不能帮你做的优化。这里，我们先讲个例子。考虑一个简单向量数据结构。向量由两个存储器块表示。头部是一个声明如下的结构：\n\n```c++\n\ttypedef struct{\n\t    int len;\n\t    data_t* data;\n\t}vec_rec, *vec_ptr;\n```\n\n这个声明用数据类型data_t作为基本元素的数据类型。可以用int,float,double类型来评价我们代码的性能，这里我们使用float。代码如下：\n\n\ttypedef float data_t;\n\n除了头以外，我们还分配一个len长度的data_t类型对象的数组，以存放实际的向量元素。代码如下：\n\n\tvec_ptr new_vec(int len)\n\t{\n\t    vec_ptr result = (vec_ptr)malloc(sizeof(vec_rec));\n\t    if(!result)\n\t        return NULL;\n\t    result->len = len;\n\t    if(len > 0){\n\t        data_t* data = (data_t*)calloc(len, sizeof(data_t));\n\t        if(!data){\n\t            free((void*)result);\n\t            return NULL;\n\t        }\n\t        result->data = data;\n\t    }\n\t    else\n\t        result->data = NULL;\n\t    return result;\n\t}\n\n当然，还有另外的操作，如取data_t类型对象数组中的元素，得数组的长度等。\n\n\tint get_vec_elment(vec_ptr v, int index, data_t* dest)\n\t{\n\t    if(index < 0 || index > 0)\n\t        return 0;\n\t    *dest = v->data[index];\n\t    return 1;\n\t}\n\t \n\tint vec_length(vec_ptr v)\n\t{\n\t    return v->len;\n\t}\n\n作为一个优化示例，必须有操作。这里我们将操作定义为把data_t类型对象数组中的元素根据某种运算合并成一个值。通过使用编译时常数IDENT和OPER定义：\n\n\t#define INENT 1\n\t#define OPER *\n\n最后，我们进行操作，函数如下：\n\n\tvoid combine1(vec_ptr v, data_t* dest)\n\t{\n\t    int i;\n\t \n\t    *dest = INENT;\n\t    for(i = 0; i < vec_length(v); i++){\n\t        data_t val;\n\t        get_vec_elment(v, i, &val);\n\t        *dest = *dest OPER val;\n\t    }\n\t}\n\n这里就是将所有的元素通过乘法合并成一个元素。假设元素数组有１０亿个。默认地，编译器产生的代码没有经过任何的优化，所以，我们这个程序的运 行时间是相当的长。还是先说明下我的实验环境吧。我是在eclipse+Mingw下运行的，CPU为T5670　1.8GHz。那么这样的代码花了我多长时间呢？答案是12.680秒!天呐，那不是很慢嘛！这个嘛，要得益于我们高速发展的硬件设备了。但是，现在只是１０亿个，要是更多呢？操作只是简单的相乘，要是更复杂呢？不敢想象。。。\n\n至此，我们先来讨论第一个优化：消除循环的低效率 。观察combine1函数，我们发现，在for(i = 0; i < vec_length(v); i++)中，我们调用函数vec_length()作为测试条件。想象一下上C语言课程时候对循环的讨论，每次循环迭代时都必须对测试条件进行求值。哇， 那我们运行１０亿次乘法不是要调用１０亿次vec_length()函数，但是，vec_length()的返回值在这１０亿次中根本不会变化!没错，我 们对一个不会变的结果运行计算了１０亿次！事实上１０亿减１次是根本不需要的！你想到了什么？没错，我们可以优化。正如在前面所说，我们要消除循环的低效率。\n\n我们编写combie2版本，它在开始时调用vec_length()函数，并将结果赋值给局部变量length,然后在for循环中使用这个变量。果不其然，我们提高了程序的性能，运行完只花了10.012秒。这里列出combine2的代码：\n\n\tvoid combine2(vec_ptr v, data_t* dest)\n\t{\n\t    int i;\n\t    int len = vec_length(v);\n\t \n\t    *dest = INENT;\n\t    for(i = 0; i < len; i++){\n\t        data_t val;\n\t        get_vec_elment(v, i, &val);\n\t        *dest = *dest OPER val;\n\t    }\n\t}\n \n这个优化是一类常见的、称为代码移动的优化实例。这类优化包括识别出在循环里执行多次，但结果不会变化的计算，因而我们可以将计算移动到循环体外，这样这个计算就不会被执行多次。\n \n下面，我们对第二个优化进行讨论：减少过程调用 。过程调用可能会带来相当大的开销。如combine2中的get_vec_elment()函数。每次迭代循环，我们都要调用 get_vec_elment()函数以获得下一个元素。仔细观察代码，我们发现完全可以避免这个过程调用，因而也不需要进行边界检查，对程序来说是一个 良好的优化。我们可以进行如下 的改变：\n\n\tdata_t* get_vec_start(vec_ptr v)\n\t{\n\t    return v->data;\n\t}\n\t \n\tvoid combine3(vec_ptr v, data_t* dest)\n\t{\n\t    int i;\n\t    int len = vec_length(v);\n\t    data_t* data = get_vec_start(v);\n\t \n\t    *dest = INENT;\n\t    for(i = 0; i < len; i++){\n\t        *dest = *dest OPER data[i];\n\t    }\n\t}\n\n相比之前，我们在进行循环体之前先取得元素数组的起始位置，然后我们每次循环时用数组得到元素，而省去了对get+vec_elment的过程调用，减少了一些运行时间。改善后的时间是6.36秒。\n\n下面，我们再次进入下一个优化阶段：消除不必要的存储器引用 。我们知道，操作系统中对数据的读取与存储，寄存器快于存储器。然而，我们发现combine3中，每次循环中， *dest = *dest OPER data[i]语句先是对*dest进行读取，然后进行计算，再存到*dest中，这些是在存储器上进行的。但是，我们这一次存的数据就是我们下一次循环 读的数据，这样在存储器上操作不是很费时间？没错，所以，我们要消除不必要的存储器引用，将这个数据存到寄存器中。我们引入一个临时变量：\n\n\tvoid combine4(vec_ptr v, data_t* dest)\n\t{\n\t    int i;\n\t    int len = vec_length(v);\n\t    data_t* data = get_vec_start(v);\n\t    data_t tmp = INENT;\n\t \n\t    for(i = 0; i < len; i++){\n\t        tmp = tmp OPER data[i];\n\t    }\n\t    *dest = tmp;\n\t}\n\t\n经过如此改变之后，我们程序的性能又有所提高，只需要6.227秒。\n\n最后，我们再一次来回顾一下我们如何提高程序的性能。一、消除循环的低效率。二、减少过程调用。三、消除不必要的存储器引用。这里，有人会问，编译器不是 自己有优化的嘛。没错，现代的各种编译器都有能力不等的优化。但是，作为一个合格的程序员，把程序优化的工作交给编译器固然有益处，可编译器也不是万能的 啊。一部分的优化能是做不到的，而且，作为优化，最重要的是不能改变程序原来的执行结果。编译器当碰到能决定是否会改变你的程序结果的时候，他往往选择不 优化以保证结果的正确性，这个时候就需要我们手动来进行程序的优化了。所以，掌握这个技能还是很有必要的。\n\n另外，这是我第一次写Blog，当然文笔很生疏啦，请读者见谅！不管怎么样，这是我学习过程的一个总结，请批评指正。","source":"_posts/2010-07-03-0.md","raw":"---\ndate: 2010-07-03\nlayout: post\ntitle: 优化程序性能\npermalink: '/2010/07-03-0.html'\ncategories:\n- c/c++\ntags:\n- 设计\n- 代码质量\n- 性能\n---\n\n\n编写高效程序需要两个活动：第一，我们必须选择一组最好的算法和数据结构；第二，我们必须编写出编译器能够有效优化以转换成高效可执行代码的源 代码。这里，我们主要讲述后者。\n\n首先，我们討論一下为什么要编写高效程序。不难想象，如果本来要用１０天运行完的程序，经过优化只需要１天就可运行完，这是一件多么令人振奋的 事啊。时间就是金钱呐。那么，什么时候才有必要优化。什么？优化不是无论什么时候都有必要的吗？太不可思议了！当然，作为一个程序员，我们必做在实现与维 护程序的简单性与它的运行速度之间做出权衡折衷。对于一个只会运行一次以产生一组数据点的程序，以一种尽量减少编程工作量并保证正确性来编写程序就更为重 要了。考虑一下，比如一个只用一次的算法，编写时间加上运行时间不超过一天，然而我们花上三天来优化这个算法让它只要一个小时就能出結果。乍一看多好的优 化啊，三天变成一小时！等等，让我们来算一算。不优化编写加运行时候只要一天，而优化后呢？三天加一小时！当然，如果这个算法反复执行的话，我们对它的优 化就值得肯定了。\n\n好了，说了这么多，切入正题，怎样才能在优码级别上进行优化呢？做那些编译器不能帮你做的优化。这里，我们先讲个例子。考虑一个简单向量数据结构。向量由两个存储器块表示。头部是一个声明如下的结构：\n\n```c++\n\ttypedef struct{\n\t    int len;\n\t    data_t* data;\n\t}vec_rec, *vec_ptr;\n```\n\n这个声明用数据类型data_t作为基本元素的数据类型。可以用int,float,double类型来评价我们代码的性能，这里我们使用float。代码如下：\n\n\ttypedef float data_t;\n\n除了头以外，我们还分配一个len长度的data_t类型对象的数组，以存放实际的向量元素。代码如下：\n\n\tvec_ptr new_vec(int len)\n\t{\n\t    vec_ptr result = (vec_ptr)malloc(sizeof(vec_rec));\n\t    if(!result)\n\t        return NULL;\n\t    result->len = len;\n\t    if(len > 0){\n\t        data_t* data = (data_t*)calloc(len, sizeof(data_t));\n\t        if(!data){\n\t            free((void*)result);\n\t            return NULL;\n\t        }\n\t        result->data = data;\n\t    }\n\t    else\n\t        result->data = NULL;\n\t    return result;\n\t}\n\n当然，还有另外的操作，如取data_t类型对象数组中的元素，得数组的长度等。\n\n\tint get_vec_elment(vec_ptr v, int index, data_t* dest)\n\t{\n\t    if(index < 0 || index > 0)\n\t        return 0;\n\t    *dest = v->data[index];\n\t    return 1;\n\t}\n\t \n\tint vec_length(vec_ptr v)\n\t{\n\t    return v->len;\n\t}\n\n作为一个优化示例，必须有操作。这里我们将操作定义为把data_t类型对象数组中的元素根据某种运算合并成一个值。通过使用编译时常数IDENT和OPER定义：\n\n\t#define INENT 1\n\t#define OPER *\n\n最后，我们进行操作，函数如下：\n\n\tvoid combine1(vec_ptr v, data_t* dest)\n\t{\n\t    int i;\n\t \n\t    *dest = INENT;\n\t    for(i = 0; i < vec_length(v); i++){\n\t        data_t val;\n\t        get_vec_elment(v, i, &val);\n\t        *dest = *dest OPER val;\n\t    }\n\t}\n\n这里就是将所有的元素通过乘法合并成一个元素。假设元素数组有１０亿个。默认地，编译器产生的代码没有经过任何的优化，所以，我们这个程序的运 行时间是相当的长。还是先说明下我的实验环境吧。我是在eclipse+Mingw下运行的，CPU为T5670　1.8GHz。那么这样的代码花了我多长时间呢？答案是12.680秒!天呐，那不是很慢嘛！这个嘛，要得益于我们高速发展的硬件设备了。但是，现在只是１０亿个，要是更多呢？操作只是简单的相乘，要是更复杂呢？不敢想象。。。\n\n至此，我们先来讨论第一个优化：消除循环的低效率 。观察combine1函数，我们发现，在for(i = 0; i < vec_length(v); i++)中，我们调用函数vec_length()作为测试条件。想象一下上C语言课程时候对循环的讨论，每次循环迭代时都必须对测试条件进行求值。哇， 那我们运行１０亿次乘法不是要调用１０亿次vec_length()函数，但是，vec_length()的返回值在这１０亿次中根本不会变化!没错，我 们对一个不会变的结果运行计算了１０亿次！事实上１０亿减１次是根本不需要的！你想到了什么？没错，我们可以优化。正如在前面所说，我们要消除循环的低效率。\n\n我们编写combie2版本，它在开始时调用vec_length()函数，并将结果赋值给局部变量length,然后在for循环中使用这个变量。果不其然，我们提高了程序的性能，运行完只花了10.012秒。这里列出combine2的代码：\n\n\tvoid combine2(vec_ptr v, data_t* dest)\n\t{\n\t    int i;\n\t    int len = vec_length(v);\n\t \n\t    *dest = INENT;\n\t    for(i = 0; i < len; i++){\n\t        data_t val;\n\t        get_vec_elment(v, i, &val);\n\t        *dest = *dest OPER val;\n\t    }\n\t}\n \n这个优化是一类常见的、称为代码移动的优化实例。这类优化包括识别出在循环里执行多次，但结果不会变化的计算，因而我们可以将计算移动到循环体外，这样这个计算就不会被执行多次。\n \n下面，我们对第二个优化进行讨论：减少过程调用 。过程调用可能会带来相当大的开销。如combine2中的get_vec_elment()函数。每次迭代循环，我们都要调用 get_vec_elment()函数以获得下一个元素。仔细观察代码，我们发现完全可以避免这个过程调用，因而也不需要进行边界检查，对程序来说是一个 良好的优化。我们可以进行如下 的改变：\n\n\tdata_t* get_vec_start(vec_ptr v)\n\t{\n\t    return v->data;\n\t}\n\t \n\tvoid combine3(vec_ptr v, data_t* dest)\n\t{\n\t    int i;\n\t    int len = vec_length(v);\n\t    data_t* data = get_vec_start(v);\n\t \n\t    *dest = INENT;\n\t    for(i = 0; i < len; i++){\n\t        *dest = *dest OPER data[i];\n\t    }\n\t}\n\n相比之前，我们在进行循环体之前先取得元素数组的起始位置，然后我们每次循环时用数组得到元素，而省去了对get+vec_elment的过程调用，减少了一些运行时间。改善后的时间是6.36秒。\n\n下面，我们再次进入下一个优化阶段：消除不必要的存储器引用 。我们知道，操作系统中对数据的读取与存储，寄存器快于存储器。然而，我们发现combine3中，每次循环中， *dest = *dest OPER data[i]语句先是对*dest进行读取，然后进行计算，再存到*dest中，这些是在存储器上进行的。但是，我们这一次存的数据就是我们下一次循环 读的数据，这样在存储器上操作不是很费时间？没错，所以，我们要消除不必要的存储器引用，将这个数据存到寄存器中。我们引入一个临时变量：\n\n\tvoid combine4(vec_ptr v, data_t* dest)\n\t{\n\t    int i;\n\t    int len = vec_length(v);\n\t    data_t* data = get_vec_start(v);\n\t    data_t tmp = INENT;\n\t \n\t    for(i = 0; i < len; i++){\n\t        tmp = tmp OPER data[i];\n\t    }\n\t    *dest = tmp;\n\t}\n\t\n经过如此改变之后，我们程序的性能又有所提高，只需要6.227秒。\n\n最后，我们再一次来回顾一下我们如何提高程序的性能。一、消除循环的低效率。二、减少过程调用。三、消除不必要的存储器引用。这里，有人会问，编译器不是 自己有优化的嘛。没错，现代的各种编译器都有能力不等的优化。但是，作为一个合格的程序员，把程序优化的工作交给编译器固然有益处，可编译器也不是万能的 啊。一部分的优化能是做不到的，而且，作为优化，最重要的是不能改变程序原来的执行结果。编译器当碰到能决定是否会改变你的程序结果的时候，他往往选择不 优化以保证结果的正确性，这个时候就需要我们手动来进行程序的优化了。所以，掌握这个技能还是很有必要的。\n\n另外，这是我第一次写Blog，当然文笔很生疏啦，请读者见谅！不管怎么样，这是我学习过程的一个总结，请批评指正。","slug":"/2010/07-03-0.html","published":1,"updated":"2015-06-19T16:09:05.000Z","comments":1,"photos":[],"link":"","_id":"ciiwjp2xz0000of6ghe2ih6yq"},{"date":"2015-12-30T16:00:00.000Z","layout":"post","title":"2016年计划","_content":"\n*One of my goals for 2016 is to achieve the goal of 2015 which I should have done in 2014 because I promised a promise in 2013 & planned a plan in 2012 according to the situation of 2011 caused by a cause in 2010...but still hv a long way to run...*\n\n*Just kidding.*\n\n#Goal\n1. 阅读**10**本书，其中**3**技术性，**7**本非技术性。\n2. 撰写**12**篇Blog。\n3. 掌握**1**门语言，初步**Swift**。\n4. 学习**1**个开源项目，初步定[**TeamTalk**](https://github.com/mogujie/TeamTalk)。\n\n#Schedule\n空白\n","source":"_posts/2015-12-31-0.md","raw":"---\ndate: 2015-12-31\nlayout: post\ntitle: 2016年计划\npermalink: '/2015/12-31-0.html'\ncategories:\n- 我的计划\ntags:\n- 计划\n---\n\n*One of my goals for 2016 is to achieve the goal of 2015 which I should have done in 2014 because I promised a promise in 2013 & planned a plan in 2012 according to the situation of 2011 caused by a cause in 2010...but still hv a long way to run...*\n\n*Just kidding.*\n\n#Goal\n1. 阅读**10**本书，其中**3**技术性，**7**本非技术性。\n2. 撰写**12**篇Blog。\n3. 掌握**1**门语言，初步**Swift**。\n4. 学习**1**个开源项目，初步定[**TeamTalk**](https://github.com/mogujie/TeamTalk)。\n\n#Schedule\n空白\n","slug":"/2015/12-31-0.html","published":1,"updated":"2015-12-31T13:08:21.000Z","comments":1,"photos":[],"link":"","_id":"ciiwjp2yu000cof6gi7tep7pm"},{"date":"2015-12-29T16:00:00.000Z","layout":"post","title":"UIView入门","_content":"\n##初识*UIView*\n*UIView*是*UIKit*中重要的一个类，*iOS*开发者几乎无法绕过它，因为我们的*App*中，看得见摸得着的*UI*都是*UIView*以及它的子类，比如*UIWindow，UILabel，UIPickerView，UIProgressView，UIActivityIndicatorView，UIImageView，UITabBar，UIToolbar，UINavigationBar，UITableViewCell，UIActionSheet，UIAlertView，UIScrollView，UISearchBar，UIWebView，UIControl*。既然我们绕不过去，就必须了解它。\n\n##浏览*UIView*\n打开*UIView.h*文件(*iOS9.1*)，近600行的代码，似乎彰示着这并不是个小类。当然*UIView*包含的功能确实不少，因为它既要负责你看得见的，又要负责你摸的着的。之前我们了解到*iOS*中存在着大量的*UIView*的子类，那岂不是个个类都是庞然大物？没错，但今天我们只看*UIView*。\n\n浏览*UIView.h*文件，里面包含了几部分声明:\n\n> + UIView : UIResponder ...\n> + UIView(UIViewGeometry)\n> + UIView(UIViewHierarchy)\n> + UIView(UIViewRendering)\n> + UIView(UIViewAnimation)\n> + UIView(UIViewAnimationWithBlocks)\n> + UIView (UIViewGestureRecognizers)\n> + ...\n\n下面具体了解下各部分声明。\n\n##*UIView(UIViewGeometry)*\n从*Strategy*名称中我们可以看出些端倪，这部分基本都是与*Geometry*相关的。\n\n比如，包括指示*View*位置的*property*:\n> @property(nonatomic) CGRect frame;\n\n指示*View*渲染区域的*property*:\n> @property(nonatomic) CGRect bounds;\n\n指示*View*中心位置的*property*:\n> @property(nonatomic) CGPoint center; \n\n指示*View*内容刻度因子的*property*:\n> @property(nonatomic) CGFloat contentScaleFactor;\n\n指示*View*变换矩阵的*property*:\n> @property(nonatomic) CGAffineTransform transform; \n\n等等。\n\n几个*property*中其他似乎都比较好理解，但是*transform* *property*有点晦涩。事实上，*transform* *perperty* 表示一个*3乘3*的矩阵，\n\n\ta   b   0 \n\tc   d   0\n\ttx  ty  1\t\n\t\n而经过这个变换矩阵后，结果如下:\n\n\t\t\t\t\t\t\t\t\t        a   b   0\n\t[x'  y'  1]\t=\t[x   y   1]\t* \tc   d   0\n\t\t\t\t\t\t\t\t\t        tx  ty  1\n\n*CGAffineTransform*的定义也说明了这点：\n\n\tstruct CGAffineTransform {\n\t  CGFloat a, b, c, d;\n\t  CGFloat tx, ty;\n\t};\n\t\n当然，我们真正使用的时候，极少直接定义*CGAffineTransform*里面的字段，而是直接使用*Apple*提供的宏：\n\n> - CGAffineTransformIdentity \n> - CGAffineTransformMake\n> - CGAffineTransformMakeTranslation \n> - CGAffineTransformMakeScale\n> - ...\n\n## *UIView(UIViewHierarchy)*\n同样我们从*stratege*的名称中，我们可以猜想到这部分与*UIView*的层级有关。看一下此部分包含的*property*:\n\n> @property(nullable, nonatomic,readonly) UIView       *superview;\n> @property(nonatomic,readonly,copy) NSArray<__kindof UIView *> *subviews;\n> @property(nullable, nonatomic,readonly) UIWindow     *window;\n\n既然是层级关系，这里包含了指向父*UIView*的*property -- superview*, 以及指向子*UIView*的*property -- subviews*。这里可以确定一点，每个*UIView*如果在层级关系中，一定存在其父*UIView*，而且最多只有一个父*UIView*，而子*UIView*，可能存在多个，也可能不存在。\n\n最后，*UIWindow*类型的*property*指向整个*UIView*层次结构的顶层。\n\n## *UIView(UIViewRendering)*\n这部分中，我们重点关注下包含的方法：\n\n>\n- \\- (void)drawRect:(CGRect)rect;\n- \\- (void)setNeedsDisplay;\n- \\- (void)setNeedsDisplayInRect:(CGRect)rect;\n\n之前我们提过，*UIView*负责我们看到的，既然如此，视图就会在一定周期内绘制可见部分于屏幕上。当视图改变时，我们需要重绘视图以显示视图的改变。方法*setNeedsDisplay*以及方法*setNeedsDisplayInRect:*就是通知程序视图失效，需要重绘。\n\n而*drawRect:*方法则是用于自定义*UIView*子类时，覆盖该方法以绘制自定义的内容。\n\n## *Other*\n\n我们并没有分析完整的*UIView*，**\"纸上得来终觉浅，觉知此事要躬行\"**，学习*UIView*最好的方法，还是使用它。当然，开头的时候我们就提到，进行*iOS*开发，几乎不可能不使用*UIView*及其子类，那么，*coding*吧。\n\n\n\n\n\n","source":"_posts/2015-12-30-0.md","raw":"---\ndate: 2015-12-30\nlayout: post\ntitle: UIView入门\npermalink: '/2015/12-30-0.html'\ncategories:\n- iOS\ntags:\n- iOS入门\n---\n\n##初识*UIView*\n*UIView*是*UIKit*中重要的一个类，*iOS*开发者几乎无法绕过它，因为我们的*App*中，看得见摸得着的*UI*都是*UIView*以及它的子类，比如*UIWindow，UILabel，UIPickerView，UIProgressView，UIActivityIndicatorView，UIImageView，UITabBar，UIToolbar，UINavigationBar，UITableViewCell，UIActionSheet，UIAlertView，UIScrollView，UISearchBar，UIWebView，UIControl*。既然我们绕不过去，就必须了解它。\n\n##浏览*UIView*\n打开*UIView.h*文件(*iOS9.1*)，近600行的代码，似乎彰示着这并不是个小类。当然*UIView*包含的功能确实不少，因为它既要负责你看得见的，又要负责你摸的着的。之前我们了解到*iOS*中存在着大量的*UIView*的子类，那岂不是个个类都是庞然大物？没错，但今天我们只看*UIView*。\n\n浏览*UIView.h*文件，里面包含了几部分声明:\n\n> + UIView : UIResponder ...\n> + UIView(UIViewGeometry)\n> + UIView(UIViewHierarchy)\n> + UIView(UIViewRendering)\n> + UIView(UIViewAnimation)\n> + UIView(UIViewAnimationWithBlocks)\n> + UIView (UIViewGestureRecognizers)\n> + ...\n\n下面具体了解下各部分声明。\n\n##*UIView(UIViewGeometry)*\n从*Strategy*名称中我们可以看出些端倪，这部分基本都是与*Geometry*相关的。\n\n比如，包括指示*View*位置的*property*:\n> @property(nonatomic) CGRect frame;\n\n指示*View*渲染区域的*property*:\n> @property(nonatomic) CGRect bounds;\n\n指示*View*中心位置的*property*:\n> @property(nonatomic) CGPoint center; \n\n指示*View*内容刻度因子的*property*:\n> @property(nonatomic) CGFloat contentScaleFactor;\n\n指示*View*变换矩阵的*property*:\n> @property(nonatomic) CGAffineTransform transform; \n\n等等。\n\n几个*property*中其他似乎都比较好理解，但是*transform* *property*有点晦涩。事实上，*transform* *perperty* 表示一个*3乘3*的矩阵，\n\n\ta   b   0 \n\tc   d   0\n\ttx  ty  1\t\n\t\n而经过这个变换矩阵后，结果如下:\n\n\t\t\t\t\t\t\t\t\t        a   b   0\n\t[x'  y'  1]\t=\t[x   y   1]\t* \tc   d   0\n\t\t\t\t\t\t\t\t\t        tx  ty  1\n\n*CGAffineTransform*的定义也说明了这点：\n\n\tstruct CGAffineTransform {\n\t  CGFloat a, b, c, d;\n\t  CGFloat tx, ty;\n\t};\n\t\n当然，我们真正使用的时候，极少直接定义*CGAffineTransform*里面的字段，而是直接使用*Apple*提供的宏：\n\n> - CGAffineTransformIdentity \n> - CGAffineTransformMake\n> - CGAffineTransformMakeTranslation \n> - CGAffineTransformMakeScale\n> - ...\n\n## *UIView(UIViewHierarchy)*\n同样我们从*stratege*的名称中，我们可以猜想到这部分与*UIView*的层级有关。看一下此部分包含的*property*:\n\n> @property(nullable, nonatomic,readonly) UIView       *superview;\n> @property(nonatomic,readonly,copy) NSArray<__kindof UIView *> *subviews;\n> @property(nullable, nonatomic,readonly) UIWindow     *window;\n\n既然是层级关系，这里包含了指向父*UIView*的*property -- superview*, 以及指向子*UIView*的*property -- subviews*。这里可以确定一点，每个*UIView*如果在层级关系中，一定存在其父*UIView*，而且最多只有一个父*UIView*，而子*UIView*，可能存在多个，也可能不存在。\n\n最后，*UIWindow*类型的*property*指向整个*UIView*层次结构的顶层。\n\n## *UIView(UIViewRendering)*\n这部分中，我们重点关注下包含的方法：\n\n>\n- \\- (void)drawRect:(CGRect)rect;\n- \\- (void)setNeedsDisplay;\n- \\- (void)setNeedsDisplayInRect:(CGRect)rect;\n\n之前我们提过，*UIView*负责我们看到的，既然如此，视图就会在一定周期内绘制可见部分于屏幕上。当视图改变时，我们需要重绘视图以显示视图的改变。方法*setNeedsDisplay*以及方法*setNeedsDisplayInRect:*就是通知程序视图失效，需要重绘。\n\n而*drawRect:*方法则是用于自定义*UIView*子类时，覆盖该方法以绘制自定义的内容。\n\n## *Other*\n\n我们并没有分析完整的*UIView*，**\"纸上得来终觉浅，觉知此事要躬行\"**，学习*UIView*最好的方法，还是使用它。当然，开头的时候我们就提到，进行*iOS*开发，几乎不可能不使用*UIView*及其子类，那么，*coding*吧。\n\n\n\n\n\n","slug":"/2015/12-30-0.html","published":1,"updated":"2015-12-30T13:27:27.000Z","comments":1,"photos":[],"link":"","_id":"ciiwjp2yx000hof6ga461t7z0"},{"date":"2015-02-13T16:00:00.000Z","layout":"post","title":"经典算法巡礼(八) -- 查找之二叉查找树","_content":"\n## 理论说\n### 概念\n[二叉查找树](http://zh.wikipedia.org/zh/%E4%BA%8C%E5%85%83%E6%90%9C%E5%B0%8B%E6%A8%B9)是计算机科学中最重要的算法之一，它将[链表](http://zh.wikipedia.org/zh/%E9%93%BE%E8%A1%A8)插入的灵活性和[有序数组](http://baike.baidu.com/view/3792536.htm)查找的高效性结合在一起，即同时拥有插入灵活性和查找高效性的一种符号表实现。\n\n### 性能\n我们知道，链表以插入灵活性闻名，但是它的实现直接导致在查找效率上不是如此优美，**平均情况下的成本数量级为O(N/2)，最坏情况下为O(N)**。而有序数组查找时利用二分法直接将查找效率提高至**平均情况和最坏情况均为对数级别O(lgN)**，而查找情况下却也丑陋不堪，**平均情况下增长数量级为O(N/2)，最坏情况下为O(N)**。二叉查找树结合两者的优势，**在平均情况下查找和插入均提高至O(lgN)，最坏情况下为O(N)**。\n\n### 数据结构\n二叉查找树所使用的数组结构由结点组成，每个结点均包含指向其他指点的指针(可以为空)。在二叉树中，每个结点有且只能有一个父结点，即只能有一个另外的结点包含指向该结点的指针(树的根结点除外)，而每个结点都有左右两个分别指向不同结点的指针，称之为左子指针和右子指针，被指向的两个结点分别为该结点的左子结点和右子结点(可以为nil，即没有相应的子结点)。同时，二叉查找树有一个重要的性质，即结点的左子结点及其左子结点的所有递归子结点的值均小于该结点，而右子结点及其右子结点的所有递归所有子结点的值均大于该结点。这个特性使得该树成为一个按一定方式有序的树，从而支持高效查询。\n\n一棵典型的二叉查找树如下图所示：\n\n![](/img/2015-02-14-0.png \"\")\n\n如图中所示，结点S为二叉查找树的根结点，它是没有父结点的，但是拥有两个子结点，左子结点为E，父子结点为X。同时，结点E又拥有两个子结点，而结点X没有子结点。另外，由于二叉查找树的性质，结点S,E,X的大小 为E<S<X。\n\n## 实践说\n我们实现二叉查找树中几个常用的接口，均以golang实现。\n\n### 结点定义\n我们首先定义结点的数据结构，根据**\"理论说\"**中表述，结点必须包含指向左子结点和右子结点的两个指针。另外，结点是数据承载的容器，所以还必须包括与数据相关的字段。我们将结点定义如下：\n\n```go\ntype Key string\ntype Value string\ntype Node struct {\n\tkey         Key\n\tvalue       Value\n\tleft, right *Node\n\tN           int\n}\n```\n\n上述结构中，我们包含了指向子结点的两个指针，而且具有一对Key-Value对，这表明我们结点中所存储数据为Key-Value对，另外N为结点计数器，值为以该结点为根结点的子树的结点总数，如**\"基础说\"**中E结点的N值为5。\n\n### 二叉查找树定义\n定义二叉查找树，有了**\"结点定义\"**后，该定义非常方便，如下所示：\n\n```go\ntype BST struct {\n\troot *Node\n}\n```\n\n由代码段明显可知，二叉查找树的定义，只要直接保存其根结点即可。\n\n\n### 二叉查找树一般性接口定义\n一般来说，二叉查找树具有以下几个类型的接口：\n\n+ Size：二叉查找树结点数\n+ Get：从二叉查找树中获取相应的值\n+ Put：将相应的值插入到二叉查找树中\n+ Min：从二叉查找树中获取最小值\n+ Max：从二叉查找树中获取最大值\n+ Floor：从二叉查找树中获取比给定值小的且是最大的值，即向下取整\n+ Ceiling：从二叉查找树中获比给定值大的且是最小的值，即向上取整\n+ Select：从二叉查找树中获取第k个结点的值（从0开始）\n+ Rank: Select接口的反操作，即从二叉查找树中获取给定值的结点的排序值\n+ DeleteMin：删除二叉查找树中最小值\n+ DeleteMax：删除二叉查找树中最大值\n+ Delete：删除指定结点\n+ Travel: 遍历二叉查找树\n\n### 接口实现：Size\n```go\nfunc (this *BST) Size() int {\n\treturn this.size(this.root)\n}\nfunc (this *BST) size(n *Node) int {\n\tif n != nil {\n\t\treturn n.N\n\t} else {\n\t\treturn 0\n\t}\n}\n```\n由于我们在定义结点结构体的时候，特别增加字段N表示以该结点为根结点的子树的结点数，所以Size()接口的实现非常方便，直接返回N字段的值即可。\n\n### 接口实现：Get\n```go\nfunc (this *BST) Get(key Key) *Node {\n\treturn this.get(this.root, key)\n}\nfunc (this *BST) get(n *Node, key Key) *Node {\n\tif n == nil {\n\t\treturn nil\n\t}\n\tif n.key == key {\n\t\treturn n\n\t}\n\tif n.key > key {\n\t\treturn this.get(n.left, key)\n\t}\n\tif n.key < key {\n\t\treturn this.get(n.right, key)\n\t}\n\treturn nil\n}\n```\n\nGet()接口的实现思路比较简单，递归遍历所有结点，若寻找Key的值等于结点的值，则找到相应结点；若小于结点的值，则在该结点的左子结点上再次进行相同的操作；若大于结点的值，则相应查看右子结点。\n\n### 接口实现：Put\n```go\nfunc (this *BST) Put(key Key, value Value) {\n\tthis.root = this.put(this.root, key, value)\n}\nfunc (this *BST) put(n *Node, key Key, value Value) *Node {\n\tif n == nil {\n\t\treturn &Node{key: key, value: value, N: 1}\n\t}\n\tif n.key == key {\n\t\tn.value = value\n\t} else if n.key < key {\n\t\tn.right = this.put(n.right, key, value)\n\t} else {\n\t\tn.left = this.put(n.left, key, value)\n\t}\n\tn.N = this.size(n.left) + this.size(n.right) + 1\n\treturn n\n}\n```\n\nPut()接口的实现思路可以归纳为两种情况：一种是找到相应结点并修改值，另一种是未找到相应结点，在合适的位置增加结点。具体实现时，递归比较结点值，若值相等，则为情况一。若值大于，则对结点左子树进行相同操作，若值小于，则对结点右子树进行相同操作，直到子结点为nil为止，即未找到相应结点，对应于情况二，则主动在该位置增加新结点。\n\n### 接口实现：Min\n```go\nfunc (this *BST) Min() Key {\n\treturn this.min(this.root).key\n}\nfunc (this *BST) min(n *Node) *Node {\n\tif n.left != nil {\n\t\treturn this.min(n.left)\n\t}\n\treturn n\n}\n```\nMin()接口实现比较简单，由于二叉查找树本身的特点是有序的，所以直接一直找到最深左子结点即可。\n\n### 接口实现：Max\n```go\nfunc (this *BST) Max() Key {\n\treturn this.max(this.root).key\n}\nfunc (this *BST) max(n *Node) *Node {\n\tif n.right != nil {\n\t\treturn this.max(n.right)\n\t}\n\treturn n\n}\n```\nMax()接口与Min()接口类似，这里不再赘述。\n\n### 接口实现：Floor\n```go\nfunc (this *BST) Floor(key Key) Key {\n\tif n := this.floor(this.root, key); n != nil {\n\t\treturn n.key\n\t}\n\treturn \"\"\n}\nfunc (this *BST) floor(n *Node, key Key) *Node {\n\tif n == nil {\n\t\treturn nil\n\t}\n\tif key == n.key {\n\t\treturn n\n\t}\n\tif key < n.key {\n\t\treturn this.floor(n.left, key)\n\t}\n\tnode := this.floor(n.right, key)\n\tif node == nil {\n\t\treturn n\n\t} else {\n\t\treturn node\n\t}\n\treturn nil\n}\n```\n\nFloor()接口实现思路如下：如果给定Key等于结点的Key，则该结点为向下取整后结点，这种情况是最简单的；如果给定Key小于结点的Key，则向下取整后结点一定存在于以结点左子结点为根结点的子树中，递归调用即可；剩下的情况就是大于结点Key的情况，在此种情况下，向下取整后结点可能在右子树中，若不在，则该结点即为所需要结点。\n\n### 接口实现：Ceiling\n```go\nfunc (this *BST) Ceiling(key Key) Key {\n\tif n := this.ceiling(this.root, key); n != nil {\n\t\treturn n.key\n\t}\n\treturn \"\"\n}\nfunc (this *BST) ceiling(n *Node, key Key) *Node {\n\tif n == nil {\n\t\treturn nil\n\t}\n\tif key == n.key {\n\t\treturn n\n\t}\n\tif key > n.key {\n\t\treturn this.ceiling(n.right, key)\n\t}\n\tnode := this.ceiling(n.left, key)\n\tif node == nil {\n\t\treturn n\n\t} else {\n\t\treturn node\n\t}\n\treturn nil\n}\n```\nCeiling()接口与Floor()接口类似，也不再赘述。\n\n### 接口实现：Select\n```go\nfunc (this *BST) Select(k int) Key {\n\tif n := this.innerSelect(this.root, k); n != nil {\n\t\treturn n.key\n\t}\n\treturn \"\"\n}\n// 在go中select为关键字，所以以innerSelect代替\nfunc (this *BST) innerSelect(n *Node, k int) *Node {\n\tif n == nil {\n\t\treturn nil\n\t}\n\tif k <= 0 {\n\t\treturn n\n\t}\n\tif n.left == nil {\n\t\treturn this.innerSelect(n.right, k-1)\n\t}\n\tif n.left.N == k {\n\t\treturn n\n\t}\n\tif n.left.N > k {\n\t\treturn this.innerSelect(n.left, k)\n\t}\n\tif n.left.N < k {\n\t\treturn this.innerSelect(n.right, k-n.left.N-1)\n\t}\n\treturn nil\n}\n```\n\nSelect()接口实现的是给定一个k值，找到这样一个结点，小于这个结点的所有结点数正好为k。由于我们定义结点数据结构时，字段N的值代码以该结点为根结点形成的树的结点数。因此，Select()接口的实现只有找到这样一个结点，该结点的左子结点的N值为k即可。\n\n### 接口实现：Rank\n```go\nfunc (this *BST) Rank(key Key) int {\n\treturn this.rank(this.root, key)\n}\nfunc (this *BST) rank(n *Node, key Key) int {\n\tif n == nil {\n\t\treturn 0\n\t}\n\tif n.key == key {\n\t\tif n.left != nil {\n\t\t\treturn n.left.N\n\t\t} else {\n\t\t\treturn 0\n\t\t}\n\t}\n\tif n.key > key {\n\t\treturn this.rank(n.left, key)\n\t}\n\tif n.key < key {\n\t\tif n.left != nil {\n\t\t\treturn n.left.N + 1 + this.rank(n.right, key)\n\t\t} else {\n\t\t\treturn 1 + this.rank(n.right, key)\n\t\t}\n\t}\n\treturn 0\n}\n```\n\nRank()接口即Select()接口的反操作，即找到给比定结点小的结点数。实现过程中可以分为三种情况：结点值与Key相等时，结果为结点左子结点的N值；大于Key时，保存结果的结点在该结点的左子树中；小于Key时，情况略微复杂，由三部分组成，分别为左子树的结点数，该结点和右子树中比Key小的结点数。\n\n### 接口实现：DeleteMin\n```go\nfunc (this *BST) DeleteMin() {\n\tthis.root = this.deleteMin(this.root)\n}\nfunc (this *BST) deleteMin(n *Node) *Node {\n\tif n.left == nil {\n\t\treturn n.right\n\t} else {\n\t\tn.left = this.deleteMin(n.left)\n\t\tn.N = this.size(n.left) + this.size(n.right) + 1\n\t\treturn n\n\t}\n}\n```\nDeleteMin()接口实现思路就是找到最小结点，并且删除它即可。根据二叉查找树的特点，最小结点只要沿着树的左子结点走，直到发现一个结点，其左子结点为nil，那么该结点就是最小结点。\n\n### 接口实现：DeleteMax\n```go\nfunc (this *BST) DeleteMax() {\n\tthis.root = this.deleteMax(this.root)\n}\nfunc (this *BST) deleteMax(n *Node) *Node {\n\tif n.right == nil {\n\t\treturn n.left\n\t} else {\n\t\tn.right = this.deleteMax(n.right)\n\t\tn.N = this.size(n.left) + this.size(n.right) + 1\n\t\treturn n\n\t}\n}\n```\nDeleteMax()接口与DeleteMin()接口类似，这里不再赘述。\n\n### 接口实现：Delete\n```go\nfunc (this *BST) Delete(key Key) {\n\tthis.root = this.delete(this.root, key)\n}\nfunc (this *BST) delete(n *Node, key Key) *Node {\n\tif n == nil {\n\t\treturn nil\n\t}\n\tif n.key > key {\n\t\tn.left = this.delete(n.left, key)\n\t} else if n.key < key {\n\t\tn.right = this.delete(n.right, key)\n\t} else {\n\t\tif n.left == nil {\n\t\t\treturn n.right\n\t\t}\n\t\tif n.right == nil {\n\t\t\treturn n.left\n\t\t}\n\t\tnode := n\n\t\tn = this.min(n.right)\n\t\tn.right = this.deleteMin(n)\n\t\tn.left = node.left\n\t}\n\tn.N = this.size(n.left) + this.size(n.right) + 1\n\treturn n\n}\n```\nDelete()接口实现与查找类似，若结点值大于Key，则对结点左子数据进行递归操作，若结点值小于Key，则对结点右子数进行递归操作，当结点值等于Key时，则将该结点删除即可。在删除过程中，思路也很简单，即将删除结点的右子树中的最小结点代替该结点即可。\n\n### 接口实现：Travel\n```go\ntype oper func(*Node)\nfunc (this *BST) Travel(f oper, sort string) {\n\tthis.travel(this.root, f, sort)\n}\nfunc (this *BST) travel(n *Node, f oper, sort string) {\n\tif n == nil {\n\t\treturn\n\t}\n\tswitch sort {\n\tcase \"in-order\":\n\t\tthis.travel(n.left, f, sort)\n\t\tf(n)\n\t\tthis.travel(n.right, f, sort)\n\tcase \"pre-order\":\n\t\tf(n)\n\t\tthis.travel(n.left, f, sort)\n\t\tthis.travel(n.right, f, sort)\n\tcase \"post-order\":\n\t\tthis.travel(n.left, f, sort)\n\t\tthis.travel(n.right, f, sort)\n\t\tf(n)\n\t}\n}\n```\nTravel接口实现考虑了三种情况，即[中序遍历，先序遍历和后序遍历](http://zh.wikipedia.org/zh/%E6%A0%91%E7%9A%84%E9%81%8D%E5%8E%86)。\n\n## 分析说\n使用二叉查找树的算法的**运行时间取决于树的形状，而树的形状又取决于键被插入的先后顺序**。在最好的情况下，二叉查找树是完全平衡的，每条空链接和根结点的距离都为~lgN，但是在最坏的情况下，二叉查找树与链表无异，具体参见下图：\n\n![](/img/2015-02-14-1.png \"\")\n\n但是，二叉查找树的形状由于取决于键被插入的先后顺序，所以我们无法控制其一直保持基本平衡状态。那么，**我们是否可以如同[快速排序](http://codingforever.com/2014/12/28/-2014-12-28-1-html/)一般事先进行随机打乱呢？事实上这是不行的，因为二叉查找树本身是有序的，而且它携带着键值的插入顺序**。\n\n为了方便我们分析，我们假设二叉查找树的键的分布是随机的，即它们插入的顺序是随机的。这里，我们直接引入两个命题：\n\n\t命题一：在由N个随机键构造的二叉查找树中，查找命中平均所需的比较次数为~2lnN(约1.39lgN)。\n\n\t命题二：在由N个随机键构造的二叉查找树中插入操作和查找未命中平均所需的比较次数为~2lnN(约1.39lgN)。\n\n命题一说明，**二叉查找树在查找随机键的成本方面比二分查找大约高出39%(二分查找为lnN)**，但是这高出的成本是值得的。因为命题二说明，**二叉查找树在插入新键方面也是~2lnN，与二分查找的~N相比，对数级别的成本相对来说是高效很多**。\n\n以上分析均是基于二叉查找树的正常情况，而实际上，最坏情况也是可能发生的。**在最坏情况下，二叉查找树的性能完全取决于树的高度**，具体如命题三所描述。\n\n\t命题三：在一棵二叉查找树中，所有操作在最坏情况下所需要的时间都和树的高度成正比。\n\n很明显，最坏情况下成本（即树的高度）一定会大于平均情况下的成本。但是具体是多少呢？事实上，**随机键构造的二叉查找树的平均高度为树中结点数的对数级别，具体值趋近于2.99lgN**。因此，**二叉查找树的所有操作，在最坏情况下所需成本也是对数级别的**，这不得不说是一个可喜的结果。\n\n但是，请注意，我们之前有个假设：**二叉查找树的键是随机插入的**，但是实际应用中，这通常是理想情况下才会发生的事。而且，这种非随机插入，我们并不能如快速排序一般事先进行随机打乱操作。那么，真的无能为力了吗？当然不是！[平衡查找树]()就是为这个而生的！\n\n\n\n\n","source":"_posts/2015-02-14-0.md","raw":"---\ndate: 2015-02-14\nlayout: post\ntitle: 经典算法巡礼(八) -- 查找之二叉查找树 \npermalink: '/2015/02-14-0.html'\ncategories:\n- 算法\ntags:\n- 查找\n---\n\n## 理论说\n### 概念\n[二叉查找树](http://zh.wikipedia.org/zh/%E4%BA%8C%E5%85%83%E6%90%9C%E5%B0%8B%E6%A8%B9)是计算机科学中最重要的算法之一，它将[链表](http://zh.wikipedia.org/zh/%E9%93%BE%E8%A1%A8)插入的灵活性和[有序数组](http://baike.baidu.com/view/3792536.htm)查找的高效性结合在一起，即同时拥有插入灵活性和查找高效性的一种符号表实现。\n\n### 性能\n我们知道，链表以插入灵活性闻名，但是它的实现直接导致在查找效率上不是如此优美，**平均情况下的成本数量级为O(N/2)，最坏情况下为O(N)**。而有序数组查找时利用二分法直接将查找效率提高至**平均情况和最坏情况均为对数级别O(lgN)**，而查找情况下却也丑陋不堪，**平均情况下增长数量级为O(N/2)，最坏情况下为O(N)**。二叉查找树结合两者的优势，**在平均情况下查找和插入均提高至O(lgN)，最坏情况下为O(N)**。\n\n### 数据结构\n二叉查找树所使用的数组结构由结点组成，每个结点均包含指向其他指点的指针(可以为空)。在二叉树中，每个结点有且只能有一个父结点，即只能有一个另外的结点包含指向该结点的指针(树的根结点除外)，而每个结点都有左右两个分别指向不同结点的指针，称之为左子指针和右子指针，被指向的两个结点分别为该结点的左子结点和右子结点(可以为nil，即没有相应的子结点)。同时，二叉查找树有一个重要的性质，即结点的左子结点及其左子结点的所有递归子结点的值均小于该结点，而右子结点及其右子结点的所有递归所有子结点的值均大于该结点。这个特性使得该树成为一个按一定方式有序的树，从而支持高效查询。\n\n一棵典型的二叉查找树如下图所示：\n\n![](/img/2015-02-14-0.png \"\")\n\n如图中所示，结点S为二叉查找树的根结点，它是没有父结点的，但是拥有两个子结点，左子结点为E，父子结点为X。同时，结点E又拥有两个子结点，而结点X没有子结点。另外，由于二叉查找树的性质，结点S,E,X的大小 为E<S<X。\n\n## 实践说\n我们实现二叉查找树中几个常用的接口，均以golang实现。\n\n### 结点定义\n我们首先定义结点的数据结构，根据**\"理论说\"**中表述，结点必须包含指向左子结点和右子结点的两个指针。另外，结点是数据承载的容器，所以还必须包括与数据相关的字段。我们将结点定义如下：\n\n```go\ntype Key string\ntype Value string\ntype Node struct {\n\tkey         Key\n\tvalue       Value\n\tleft, right *Node\n\tN           int\n}\n```\n\n上述结构中，我们包含了指向子结点的两个指针，而且具有一对Key-Value对，这表明我们结点中所存储数据为Key-Value对，另外N为结点计数器，值为以该结点为根结点的子树的结点总数，如**\"基础说\"**中E结点的N值为5。\n\n### 二叉查找树定义\n定义二叉查找树，有了**\"结点定义\"**后，该定义非常方便，如下所示：\n\n```go\ntype BST struct {\n\troot *Node\n}\n```\n\n由代码段明显可知，二叉查找树的定义，只要直接保存其根结点即可。\n\n\n### 二叉查找树一般性接口定义\n一般来说，二叉查找树具有以下几个类型的接口：\n\n+ Size：二叉查找树结点数\n+ Get：从二叉查找树中获取相应的值\n+ Put：将相应的值插入到二叉查找树中\n+ Min：从二叉查找树中获取最小值\n+ Max：从二叉查找树中获取最大值\n+ Floor：从二叉查找树中获取比给定值小的且是最大的值，即向下取整\n+ Ceiling：从二叉查找树中获比给定值大的且是最小的值，即向上取整\n+ Select：从二叉查找树中获取第k个结点的值（从0开始）\n+ Rank: Select接口的反操作，即从二叉查找树中获取给定值的结点的排序值\n+ DeleteMin：删除二叉查找树中最小值\n+ DeleteMax：删除二叉查找树中最大值\n+ Delete：删除指定结点\n+ Travel: 遍历二叉查找树\n\n### 接口实现：Size\n```go\nfunc (this *BST) Size() int {\n\treturn this.size(this.root)\n}\nfunc (this *BST) size(n *Node) int {\n\tif n != nil {\n\t\treturn n.N\n\t} else {\n\t\treturn 0\n\t}\n}\n```\n由于我们在定义结点结构体的时候，特别增加字段N表示以该结点为根结点的子树的结点数，所以Size()接口的实现非常方便，直接返回N字段的值即可。\n\n### 接口实现：Get\n```go\nfunc (this *BST) Get(key Key) *Node {\n\treturn this.get(this.root, key)\n}\nfunc (this *BST) get(n *Node, key Key) *Node {\n\tif n == nil {\n\t\treturn nil\n\t}\n\tif n.key == key {\n\t\treturn n\n\t}\n\tif n.key > key {\n\t\treturn this.get(n.left, key)\n\t}\n\tif n.key < key {\n\t\treturn this.get(n.right, key)\n\t}\n\treturn nil\n}\n```\n\nGet()接口的实现思路比较简单，递归遍历所有结点，若寻找Key的值等于结点的值，则找到相应结点；若小于结点的值，则在该结点的左子结点上再次进行相同的操作；若大于结点的值，则相应查看右子结点。\n\n### 接口实现：Put\n```go\nfunc (this *BST) Put(key Key, value Value) {\n\tthis.root = this.put(this.root, key, value)\n}\nfunc (this *BST) put(n *Node, key Key, value Value) *Node {\n\tif n == nil {\n\t\treturn &Node{key: key, value: value, N: 1}\n\t}\n\tif n.key == key {\n\t\tn.value = value\n\t} else if n.key < key {\n\t\tn.right = this.put(n.right, key, value)\n\t} else {\n\t\tn.left = this.put(n.left, key, value)\n\t}\n\tn.N = this.size(n.left) + this.size(n.right) + 1\n\treturn n\n}\n```\n\nPut()接口的实现思路可以归纳为两种情况：一种是找到相应结点并修改值，另一种是未找到相应结点，在合适的位置增加结点。具体实现时，递归比较结点值，若值相等，则为情况一。若值大于，则对结点左子树进行相同操作，若值小于，则对结点右子树进行相同操作，直到子结点为nil为止，即未找到相应结点，对应于情况二，则主动在该位置增加新结点。\n\n### 接口实现：Min\n```go\nfunc (this *BST) Min() Key {\n\treturn this.min(this.root).key\n}\nfunc (this *BST) min(n *Node) *Node {\n\tif n.left != nil {\n\t\treturn this.min(n.left)\n\t}\n\treturn n\n}\n```\nMin()接口实现比较简单，由于二叉查找树本身的特点是有序的，所以直接一直找到最深左子结点即可。\n\n### 接口实现：Max\n```go\nfunc (this *BST) Max() Key {\n\treturn this.max(this.root).key\n}\nfunc (this *BST) max(n *Node) *Node {\n\tif n.right != nil {\n\t\treturn this.max(n.right)\n\t}\n\treturn n\n}\n```\nMax()接口与Min()接口类似，这里不再赘述。\n\n### 接口实现：Floor\n```go\nfunc (this *BST) Floor(key Key) Key {\n\tif n := this.floor(this.root, key); n != nil {\n\t\treturn n.key\n\t}\n\treturn \"\"\n}\nfunc (this *BST) floor(n *Node, key Key) *Node {\n\tif n == nil {\n\t\treturn nil\n\t}\n\tif key == n.key {\n\t\treturn n\n\t}\n\tif key < n.key {\n\t\treturn this.floor(n.left, key)\n\t}\n\tnode := this.floor(n.right, key)\n\tif node == nil {\n\t\treturn n\n\t} else {\n\t\treturn node\n\t}\n\treturn nil\n}\n```\n\nFloor()接口实现思路如下：如果给定Key等于结点的Key，则该结点为向下取整后结点，这种情况是最简单的；如果给定Key小于结点的Key，则向下取整后结点一定存在于以结点左子结点为根结点的子树中，递归调用即可；剩下的情况就是大于结点Key的情况，在此种情况下，向下取整后结点可能在右子树中，若不在，则该结点即为所需要结点。\n\n### 接口实现：Ceiling\n```go\nfunc (this *BST) Ceiling(key Key) Key {\n\tif n := this.ceiling(this.root, key); n != nil {\n\t\treturn n.key\n\t}\n\treturn \"\"\n}\nfunc (this *BST) ceiling(n *Node, key Key) *Node {\n\tif n == nil {\n\t\treturn nil\n\t}\n\tif key == n.key {\n\t\treturn n\n\t}\n\tif key > n.key {\n\t\treturn this.ceiling(n.right, key)\n\t}\n\tnode := this.ceiling(n.left, key)\n\tif node == nil {\n\t\treturn n\n\t} else {\n\t\treturn node\n\t}\n\treturn nil\n}\n```\nCeiling()接口与Floor()接口类似，也不再赘述。\n\n### 接口实现：Select\n```go\nfunc (this *BST) Select(k int) Key {\n\tif n := this.innerSelect(this.root, k); n != nil {\n\t\treturn n.key\n\t}\n\treturn \"\"\n}\n// 在go中select为关键字，所以以innerSelect代替\nfunc (this *BST) innerSelect(n *Node, k int) *Node {\n\tif n == nil {\n\t\treturn nil\n\t}\n\tif k <= 0 {\n\t\treturn n\n\t}\n\tif n.left == nil {\n\t\treturn this.innerSelect(n.right, k-1)\n\t}\n\tif n.left.N == k {\n\t\treturn n\n\t}\n\tif n.left.N > k {\n\t\treturn this.innerSelect(n.left, k)\n\t}\n\tif n.left.N < k {\n\t\treturn this.innerSelect(n.right, k-n.left.N-1)\n\t}\n\treturn nil\n}\n```\n\nSelect()接口实现的是给定一个k值，找到这样一个结点，小于这个结点的所有结点数正好为k。由于我们定义结点数据结构时，字段N的值代码以该结点为根结点形成的树的结点数。因此，Select()接口的实现只有找到这样一个结点，该结点的左子结点的N值为k即可。\n\n### 接口实现：Rank\n```go\nfunc (this *BST) Rank(key Key) int {\n\treturn this.rank(this.root, key)\n}\nfunc (this *BST) rank(n *Node, key Key) int {\n\tif n == nil {\n\t\treturn 0\n\t}\n\tif n.key == key {\n\t\tif n.left != nil {\n\t\t\treturn n.left.N\n\t\t} else {\n\t\t\treturn 0\n\t\t}\n\t}\n\tif n.key > key {\n\t\treturn this.rank(n.left, key)\n\t}\n\tif n.key < key {\n\t\tif n.left != nil {\n\t\t\treturn n.left.N + 1 + this.rank(n.right, key)\n\t\t} else {\n\t\t\treturn 1 + this.rank(n.right, key)\n\t\t}\n\t}\n\treturn 0\n}\n```\n\nRank()接口即Select()接口的反操作，即找到给比定结点小的结点数。实现过程中可以分为三种情况：结点值与Key相等时，结果为结点左子结点的N值；大于Key时，保存结果的结点在该结点的左子树中；小于Key时，情况略微复杂，由三部分组成，分别为左子树的结点数，该结点和右子树中比Key小的结点数。\n\n### 接口实现：DeleteMin\n```go\nfunc (this *BST) DeleteMin() {\n\tthis.root = this.deleteMin(this.root)\n}\nfunc (this *BST) deleteMin(n *Node) *Node {\n\tif n.left == nil {\n\t\treturn n.right\n\t} else {\n\t\tn.left = this.deleteMin(n.left)\n\t\tn.N = this.size(n.left) + this.size(n.right) + 1\n\t\treturn n\n\t}\n}\n```\nDeleteMin()接口实现思路就是找到最小结点，并且删除它即可。根据二叉查找树的特点，最小结点只要沿着树的左子结点走，直到发现一个结点，其左子结点为nil，那么该结点就是最小结点。\n\n### 接口实现：DeleteMax\n```go\nfunc (this *BST) DeleteMax() {\n\tthis.root = this.deleteMax(this.root)\n}\nfunc (this *BST) deleteMax(n *Node) *Node {\n\tif n.right == nil {\n\t\treturn n.left\n\t} else {\n\t\tn.right = this.deleteMax(n.right)\n\t\tn.N = this.size(n.left) + this.size(n.right) + 1\n\t\treturn n\n\t}\n}\n```\nDeleteMax()接口与DeleteMin()接口类似，这里不再赘述。\n\n### 接口实现：Delete\n```go\nfunc (this *BST) Delete(key Key) {\n\tthis.root = this.delete(this.root, key)\n}\nfunc (this *BST) delete(n *Node, key Key) *Node {\n\tif n == nil {\n\t\treturn nil\n\t}\n\tif n.key > key {\n\t\tn.left = this.delete(n.left, key)\n\t} else if n.key < key {\n\t\tn.right = this.delete(n.right, key)\n\t} else {\n\t\tif n.left == nil {\n\t\t\treturn n.right\n\t\t}\n\t\tif n.right == nil {\n\t\t\treturn n.left\n\t\t}\n\t\tnode := n\n\t\tn = this.min(n.right)\n\t\tn.right = this.deleteMin(n)\n\t\tn.left = node.left\n\t}\n\tn.N = this.size(n.left) + this.size(n.right) + 1\n\treturn n\n}\n```\nDelete()接口实现与查找类似，若结点值大于Key，则对结点左子数据进行递归操作，若结点值小于Key，则对结点右子数进行递归操作，当结点值等于Key时，则将该结点删除即可。在删除过程中，思路也很简单，即将删除结点的右子树中的最小结点代替该结点即可。\n\n### 接口实现：Travel\n```go\ntype oper func(*Node)\nfunc (this *BST) Travel(f oper, sort string) {\n\tthis.travel(this.root, f, sort)\n}\nfunc (this *BST) travel(n *Node, f oper, sort string) {\n\tif n == nil {\n\t\treturn\n\t}\n\tswitch sort {\n\tcase \"in-order\":\n\t\tthis.travel(n.left, f, sort)\n\t\tf(n)\n\t\tthis.travel(n.right, f, sort)\n\tcase \"pre-order\":\n\t\tf(n)\n\t\tthis.travel(n.left, f, sort)\n\t\tthis.travel(n.right, f, sort)\n\tcase \"post-order\":\n\t\tthis.travel(n.left, f, sort)\n\t\tthis.travel(n.right, f, sort)\n\t\tf(n)\n\t}\n}\n```\nTravel接口实现考虑了三种情况，即[中序遍历，先序遍历和后序遍历](http://zh.wikipedia.org/zh/%E6%A0%91%E7%9A%84%E9%81%8D%E5%8E%86)。\n\n## 分析说\n使用二叉查找树的算法的**运行时间取决于树的形状，而树的形状又取决于键被插入的先后顺序**。在最好的情况下，二叉查找树是完全平衡的，每条空链接和根结点的距离都为~lgN，但是在最坏的情况下，二叉查找树与链表无异，具体参见下图：\n\n![](/img/2015-02-14-1.png \"\")\n\n但是，二叉查找树的形状由于取决于键被插入的先后顺序，所以我们无法控制其一直保持基本平衡状态。那么，**我们是否可以如同[快速排序](http://codingforever.com/2014/12/28/-2014-12-28-1-html/)一般事先进行随机打乱呢？事实上这是不行的，因为二叉查找树本身是有序的，而且它携带着键值的插入顺序**。\n\n为了方便我们分析，我们假设二叉查找树的键的分布是随机的，即它们插入的顺序是随机的。这里，我们直接引入两个命题：\n\n\t命题一：在由N个随机键构造的二叉查找树中，查找命中平均所需的比较次数为~2lnN(约1.39lgN)。\n\n\t命题二：在由N个随机键构造的二叉查找树中插入操作和查找未命中平均所需的比较次数为~2lnN(约1.39lgN)。\n\n命题一说明，**二叉查找树在查找随机键的成本方面比二分查找大约高出39%(二分查找为lnN)**，但是这高出的成本是值得的。因为命题二说明，**二叉查找树在插入新键方面也是~2lnN，与二分查找的~N相比，对数级别的成本相对来说是高效很多**。\n\n以上分析均是基于二叉查找树的正常情况，而实际上，最坏情况也是可能发生的。**在最坏情况下，二叉查找树的性能完全取决于树的高度**，具体如命题三所描述。\n\n\t命题三：在一棵二叉查找树中，所有操作在最坏情况下所需要的时间都和树的高度成正比。\n\n很明显，最坏情况下成本（即树的高度）一定会大于平均情况下的成本。但是具体是多少呢？事实上，**随机键构造的二叉查找树的平均高度为树中结点数的对数级别，具体值趋近于2.99lgN**。因此，**二叉查找树的所有操作，在最坏情况下所需成本也是对数级别的**，这不得不说是一个可喜的结果。\n\n但是，请注意，我们之前有个假设：**二叉查找树的键是随机插入的**，但是实际应用中，这通常是理想情况下才会发生的事。而且，这种非随机插入，我们并不能如快速排序一般事先进行随机打乱操作。那么，真的无能为力了吗？当然不是！[平衡查找树]()就是为这个而生的！\n\n\n\n\n","slug":"/2015/02-14-0.html","published":1,"updated":"2015-07-25T07:23:08.000Z","comments":1,"photos":[],"link":"","_id":"ciiwjp2z0000mof6gf056mr5i"},{"date":"2015-01-31T16:00:00.000Z","layout":"post","title":"构建高性能服务器 -- 数据库篇","_content":"\n## 写在前面\n服务器数据，如用户相关数据，都需要保存起来，随时取出再次使用。当然，现在的[内存数据库](http://zh.wikipedia.org/zh/%E5%86%85%E5%AD%98%E6%95%B0%E6%8D%AE%E5%BA%93)也已经发展到相对可靠的阶段了，但是，我们这里还是讨论一个传统关系型数据库在构建高性能服务器方面的使用，如MySQL。\n\n## 利其器\n### 友好的MySQL状态报告\n俗话说，工欲善其事，必先利其器。所以，在服务器端数据库性能优化方面，我们先介绍下一个利器 -- [mysqlreport](http://www.tin.org/bin/man.cgi?section=1&topic=mysqlreport)。\n\n当然，在MySQL命令行中，我们可获取当前数据库的状态：\n\n```bash\nmysql> show status;\nmysql> show innodb status;\n```\n\n那么还需要mysqlreport干什么呢？当然，身为资深码农，我们一直以高标准要求，所以**mysqlreport是一款友好方式的数据库状态检测工具**，各方面甩直白的MySQL命令行好几条街。\n\n我们利用mysqlreport获取下当前状态：\n\n```bash\nmysql> mysqlreport --user USER_NAME --password PASSWORD\n```\n\n具体状态结果很长，就不放了，有兴趣的同学可以自己去试下。\n\n### 解释查询\nSQL语句的性能如何该如何知晓呢？**解释查询explain**横空出世。\n\nexplain的使用方式非常简单，举个简单例子，我们用以下语句创建数据表：\n\n```bash\ncreate table test (\n\tid int(11) not null auto_increment,\n\tname varchar(255) not null,\n\tprimary key (id)\n);\n```\n\n然后我们用存储过程向test数据表中增加一些数据。首先创建function:\n\n```base\ndelimiter //\ncreate function rs(n int)\nreturns varchar(255)\nbegin\n\tdeclare chars char(26) default 'abcdefghijklmnopqrstuvwxyz';\n\tdeclare res varchar(1024) default '';\n\tdeclare i int default 0;\n\trepeat\n\tset i = i + 1;\n\tset res = concat(res, substring(chars, floor(1 + rand() * 26), 1));\n\tuntil i = n end repeat;\n\treturn res;\nend\n//\n```\n然后创建存储过程：\n\n```bash\ndelimiter //\ncreate procedure inst(n int)\nbegin\n\tdeclare i int default 0;\n\tset autocommit = 0;\n\trepeat\n\tset i = i + 1;\n\tinsert into test set name=rs(16);\n\tuntil i = n end repeat;\n\tcommit;\n\tset autocommit = 1;\nend\n//\n```\n\n最后调用新创建的存储过程inst：\n\n```bash\ncall inst(100000);\n```\n这时，我们已向数据表中插入了10W条数据。这时，我们对该数据表中数据进行查询，看下效率如何该怎么办呢？我们利用**explain**语句进行查看：\n\n```bash\nexplain select * from test where id = 999;\n```\n\n得到结果如下：\n\n\t+----+-------------+-------+-------+---------------+---------+---------+-------+------+-------+\n\t| id | select_type | table | type  | possible_keys | key     | key_len | ref   | rows | extra |\n\t+----+-------------+-------+-------+---------------+---------+---------+-------+------+-------+\n\t|  1 | simple      | test  | const | primary       | primary | 4       | const |    1 |       |\n\t+----+-------------+-------+-------+---------------+---------+---------+-------+------+-------+\n\n我们可以看到，结果中type为const，这表示这次查询通过索引直接找到一个匹配行，优化器认为它的时间复杂度为常量。而根据key的值primary，意味着这次查询使用了主键索引。\n\n然后我们利用**explain**语句查看另外的查询语句：\n\n```base\nexplain select * from test where name = 'yoxxwmxbpvhyxtyo';'\n```\n\n得到结果为：\n\n\t+----+-------------+-------+------+---------------+------+---------+------+--------+-------------+\n\t| id | select_type | table | type | possible_keys | key  | key_len | ref  | rows   | Extra       |\n\t+----+-------------+-------+------+---------------+------+---------+------+--------+-------------+\n\t|  1 | SIMPLE      | test  | ALL  | NULL          | NULL | NULL    | NULL | 100260 | Using where |\n\t+----+-------------+-------+------+---------------+------+---------+------+--------+-------------+\n\n与之前不同的是，这里type值为all，即本次查询采用了全表扫描，而key的值为null，这也理所当然，因为我们并没有将name增加索引。\n\n经过上述简要讲述，大家应该了解到，**explain**语句在数据库优化过程中的确是一把利刃。\n\n### 慢查询分析\n在开发环境中，我们可以对所有查询语句进行explain分析，并建立适当的索引，把数据库性能调至最优。但是，在正式环境中，随着实际数据的积累，查询计算和开销有可能会增加，甚至我们发现有些索引设计并不理想。令人头疼的是，线上环境根本不可能用explain去分析查询语句。这个时候，我们需要一个自动记录下运行环境中每次查询执行时间的工具 —— **MySQL慢查询日志**。\n\n在MySQL中开启这项功能并不复杂，在my.cnf中增加下列配置选项：\n\n\tlong_query_time = 1\n\tlog-slow-queries = /data/var/mysql_slow.log\n\n这意味着，MySQL对执行时间超过1秒的查询请求将记录在log-slow-queries路径的文件中，我们可以用MySQL提供的mysqldumpslow查看日志，也可以通过第三方工具 —— [mysqlsla](http://www.pythian.com/blog/query-profiling-tools-part-1-mysqlsla/)。\n\n当然，我们还可以在mysqlreport的友好报告中发现以下列：\n\n\tSlow 1 s   \t\t722\t\t0.2/s \t\t0.01 \t%MDS: 0.08 \tLog:ON\n\n这其实告诉我们，超过1秒的慢查询每秒有0.2次，占总请求数的0.08%。\n\n## 善其事\n### 正确使用索引\n在影响数据库查询性能的诸多因素中，索引绝对是一个重量级的因素。\n\n#### 什么是索引\n索引说白了，就相当于一本书的目录。很容易理解，如果我们需要寻找一本书中的某一章节，我们会先去查找目录，如此做来可以大大提高查找的效率。但是如果没有索引，即书本目录，我们寻找过程就会变成全书遍历查找。\n\n事实上数据库索引也是一样，可以分为**全表扫描（Full Table Scan）和索引扫描（Index Scan）**两种。在大多数情况下，索引搜索当然要比全表扫描性能高很多，但这也不是绝对的。比如**需要查找的记录占据了整个数据表的大部分，那么使用索引扫描反而比全表扫描更差**。很容易想象，对于一本书，如果需要阅读绝大部分内容，那么按顺序全局阅读比按目录查找再阅读效率更高，因为查找目录也是需要开销的。\n\n另外，为数据库数据建立索引也不是一件简单的事，索引必须对应到数据库的每一行记录，这样一来，**引入数据库索引将会带来一个巨大的目录**，这点存储开销也是不得不重视的。而且，**除了普通索引之外，还有唯一索引，主键，全文索引等，各种索引类型都有可能带来更多额外的开销，如唯一索引插入时必须保证其唯一性，而唯一性检查也是不笔不小的开销**。\n\n这么说来，全表扫描和索引扫描孰优孰劣真心不好说，说句真心话，这是你自己的事情。记住：**为数据表建立索引是你自己的事情，永远不要期待有什么工具会自动帮你建立索引，没有工具会知道你未来会频繁地在哪个字段上进行条件查询，为哪个字段建立索引最优**。\n\n#### 初识索引\n在**利其器**一节中，我们讨论到，可以利用**explain**来进行SQL语句的性能分析。我们还是接着那时的例子，利用主键id进行查询与利用普通字段name进行查询，在查询效率上确有不同，而且一般情况下(查询绝大多数条数情况除外)前者优于后者。\n\n那么我们现在把name字段也修改为索引呢？利用以下语句进行修改：\n\n```bash\nalter table test add key name(name);\n```\n\n然后，我们再用**explain**进行查看：\n\n```bash\nexplain select * from test where name = 'yoxxwmxbpvhyxtyo';\n```\n\n结果稍微有点变化：\n\n\t+----+-------------+-------+------+---------------+------+---------+-------+------+--------------------------+\n\t| id | select_type | table | type | possible_keys | key  | key_len | ref   | rows | Extra                    |\n\t+----+-------------+-------+------+---------------+------+---------+-------+------+--------------------------+\n\t|  1 | SIMPLE      | test  | ref  | name          | name | 257     | const |    1 | Using where; Using index |\n\t+----+-------------+-------+------+---------------+------+---------+-------+------+--------------------------+\n\n现在是什么情况呢？我们可以看到，这时key字段的值为name，即本次查询采用了name字段的索引。另外，**对于没有使用主键索引或者唯一索引的条件查询，查询结果可能有多个匹配行，所以MySQL为这种情况定义的type为ref**，如本次结果中所示。\n\n那么，如果我们进行模糊查询呢？试下吧。\n\n```bash\nexplain select * from test where name like '%mxbpvhy';\n```\n\n看下结果：\n\n\t+----+-------------+-------+-------+---------------+------+---------+------+--------+--------------------------+\n\t| id | select_type | table | type  | possible_keys | key  | key_len | ref  | rows   | Extra                    |\n\t+----+-------------+-------+-------+---------------+------+---------+------+--------+--------------------------+\n\t|  1 | SIMPLE      | test  | index | NULL          | name | 257     | NULL | 100489 | Using where; Using index |\n\t+----+-------------+-------+-------+---------------+------+---------+------+--------+--------------------------+\n\n哇，还是很强力的，连模糊查询都能够利用name索引，可以看到type字段中明确写着index值。\n\n#### 使用组合索引\n实际项目过程中，查询中包含组合条件是不可避免的，如：\n\n\t... where a = 1 and b = 2\n\t... where a = 1 order by b\n\t... where a = 1 group by b\n\n这个时候，如果a和b字段都分别建立了索引，它们仍然不能同时发挥作用。因为**一次查询只能利用一个索引**。如何破？组合索引大叫：我来！\n\n还是基于先前的数据表，我们用以下命令删除先前增加的name索引，增加name_1和name_2两个字段，同时增加name，name_1和name_2的联合索引normal_key：\n\n```bash\nalter table test drop index name;\nalter table test add name_1 not null;\nalter table test add name_2 not null;\nalter table test add index normal_key(name, name_1, name_2);\n```\n\n至此，数据表table中，包含4个字段，具体情况如下：\n\n\t+--------+--------------+------+-----+---------+----------------+\n\t| Field  | Type         | Null | Key | Default | Extra          |\n\t+--------+--------------+------+-----+---------+----------------+\n\t| id     | int(11)      | NO   | PRI | NULL    | auto_increment |\n\t| name   | varchar(255) | NO   | MUL | NULL    |                |\n\t| name_1 | varchar(255) | NO   |     | NULL    |                |\n\t| name_2 | varchar(255) | NO   |     | NULL    |                |\n\t+--------+--------------+------+-----+---------+----------------+\n\n而查看数据表中index得：\n\n\t+-------+------------+------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+\n\t| Table | Non_unique | Key_name   | Seq_in_index | Column_name | Collation | Cardinality | Sub_part | Packed | Null | Index_type | Comment | Index_comment |\n\t+-------+------------+------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+\n\t| test  |          0 | PRIMARY    |            1 | id          | A         |      100288 |     NULL | NULL   |      | BTREE      |         |               |\n\t| test  |          1 | normal_key |            1 | name        | A         |         200 |     NULL | NULL   |      | BTREE      |         |               |\n\t| test  |          1 | normal_key |            2 | name_1      | A         |         200 |     NULL | NULL   |      | BTREE      |         |               |\n\t| test  |          1 | normal_key |            3 | name_2      | A         |         200 |     NULL | NULL   |      | BTREE      |         |               |\n\t+-------+------------+------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+\n\n可看，当前数据表的除了主键索引以外，还有我们刚设置的联合索引normal_key。\n\n这个时候，我们利用**explain**命令看下相关查询语句：\n\n```bash\nexplain select * from test where name = 'abc';\nexplain select * from test where name = 'abc' and name_1 = \"def\";\nexplain select * from test where name = 'abc' and name_1 = 'def' and name_2 = 'ghi';\n```\n\n这些查询语句的结果都是使用索引，具体结果大家可以自行尝试。\n\n这里我们要引入一个**“最左前缀”这个组合索引的基本原则**。这个概念可以如此解释：**如果查询条件检索时，只需要匹配联合索引中的最左顺序一个或多个字段，称为最左索引原则，或者叫最左前缀**。所以，我们查看如下SQL语句时，得到的结果应该是不使用索引。\n\n```bash\nexplain select * from test where name_2 = 'ghi' and name = 'abc';\n```\n\n**然而实际上，还是使用索引的，不得不佩服MySQL强大的SQL优化器**！\n\n#### 索引的正确使用姿势\n当然，事实上，**在整个数据库优化过程中，索引的利用永远是难点，所以，利用好你的explain工具，千万不要想当然**！\n\n凡是都有两面性，所以索引的使用也会有代价产生，具体可以归纳为以下几点：\n+ **索引会占据更多的磁盘空间，很多时候索引甚至比数据本身还要大**。不这现在磁盘的空间很容易达到TB级别，所以通常磁盘空间还未写满时，计算能力的瓶颈已经显现出来的。\n+ **当建立索引的字段发生更新时，会引发索引本身的更新，这将产生不小的计算开销**。这直接决定使用索引的数据表必须是读多写少。\n+ **索引需要我们花费一些额外的时候来维护**。MyISAM和Innodb类型的数据表存储结构会有不同，所以具体维护时也有些不同，比如MyISAM的索引写缓存由于断电可能造成索引的损坏，需要我们及时地手动修复。\n\n### 锁写与等待\n当有多个用户并发访问数据库中某一资源的时候，为了保证并发访问的一致性，数据库必须通过锁机制来协调这些访问。而**锁机制也是影响数据库性能的一个重要点**。\n\n**MySQL为MyISAM类型表提供了表级别的锁定，即当有请求对数据表有更新操作（如update)时，数据表就会被锁定，其他任何对当前表的操作将被排斥，甚至包括select查询**。另外需要注意的是，**更新操作有着默认高优先级，即当表锁释放后，更新操作将先获得锁定，然后才能轮到读取操作**。此机制将可能引发以下情况：频繁更新操作将会使得读取操作长时间等待。\n\n**MySQL为Innodb类型表提供了行锁，即当有请求对数据表有更新操作时，数据表不是全表被锁定，而是更新的特定行，其他任何对当前行的操作将被排斥，但是对其他行的操作将不被限制**。\n\n从概念上对比，似乎行锁要比表锁好。但这并不是绝对的，**理论上就锁定本身而言，行锁定的开销并不比表锁小**。比如对于update密集型的场景，行锁定并不是救世主，因为行锁单位锁定开销比表锁大，所以具体性能只能实测。\n\n### 事务性表的性能\n**MySQL中Innodb类型表不仅支持行锁定，还支持事务**。有时候，我们选择Innodb类型的数据表就是因为其支持事务。当然，如果我们没有在应用程序中使用事务操作的打算，而只是看中了其他特性，如行锁定，外键以及易于修复等，我们仍然可以使用它。\n\nInnodb实现事务是采用**预写日志方式（WAL）**完成的。当有事务提交时，Innodb首先将它写到内存中的事务日志缓冲区中，随后当事务日志写入磁盘时，Innodb才更新实际数据和索引。这里，事务日志写入磁盘的时机可以分为3种：\n+ innodb_flush_log_at_trx_commit=1。这个设置表示事务提交时立即将事务写入磁盘，同时实际数据和索引也更新。\n+ innodb_flush_log_at_trx_commit=0。这个设置表示事务提交时不立即将事务写入磁盘，而是每隔1秒写入磁盘文件一次，并且刷新到磁盘中，同时更新实际数据和索引。这种方式如果在事务提交和事务写入磁盘之间发生mysqld崩溃的话，那么在内存中的最近1秒的数据将会丢失，注意，是永久性丢失。\n+ innodb_flush_log_at_trx_commit=2。这个设置表示事务提交时立即写入磁盘，但没有刷新到磁盘，而是存放在磁盘缓冲区，每隔1秒刷新磁盘一次，同时更新数据和索引。这种方式如果发生mysqld崩溃的话，数据并不会丢失，因为存放在磁盘缓冲区的数据还是会刷新到磁盘中。但是如果操作系统崩溃的话，那就永久丢失了。\n\n显然，第2种方式性能最高，但是丢失数据的可能性也最大。\n\n另外，MySQL有一个选项会影响到上述3种方式的实现，它就是innodb_flush_method选项。我们可以将该选项设置为O_DIRECT，如下\n\n\tinnodb_flush_method = O_DIRECT\n\n如此一来，Innodb可以直接I/O，所有的读写操作将会跳过文件系统的系统缓冲区，提高I/O性能，当然，预写日志方式也就会随之改变。\n\n### 使用查询缓存\n**使用查询缓存的目的很简单，那就是提高数据库查询数据的性能**。\n\n**在默认情况下，MySQL是没有开启查询缓存功能**的，我们可以进行以下配置进行开启（开启256MB的内存空间来缓存查询结果）：\n\n\tquery_cache_size = 268435446\n\tquery_cache_type = 1\n\tquery_cache_limit = 1048576\n\n查询缓存功能，不论是MyISAM还是Innodb类型，对于以select为主的应用显然性能会大增。但是令人遗憾的是，MySQL的缓存过期策略并不是十分令人满意。**当一个数据表有更新操作后，那么涉及这个表的所有查询缓存均失效**。话虽如此，但是对于select操作占绝大部分的应用，还是极大的福音。我们只要注意不要将其使用在select和update交叉混合的应用就可以了。\n\n另外，我们可以利用mysqlreport查看查询缓存的状态，如下所示：\n\n\t__ Query Cache ______________________________________________________\n\tMemory usage   17.11k of  16.00M  %Used:   0.10\n\tBlock Fragmnt 100.00%\n\tHits                2     0.0/s\n\tInserts            13     0.0/s\n\tInsrt:Prune      13:1     0.0/s\n\tHit:Insert     0.15:1\n\n很显示，当前缓存区大小为16M，而现在使用了17K，另外，Insrt:Prume代表查询结果进入缓存的次数和过期被删除的次数的比例，当然，这个比例越大，表示查询操作与更新操作相比更频繁，也就更适合使用查询缓存。\n\n### 临时表\n我们利用mysqlreport时，可以发现有Using temporary的状态，如下：\n\n\t__ Created Temp ________________________________________________________\n\tDisk table         75     0.0/s\n\tTable             296     0.0/s    Size:  16.0M\n\tFile               10     0.0/s\n\n当然，我们这里的要求就是**尽量避免使用临时表，因为无论是在磁盘（Disk table），内存(Table)，还是在文件（File）中创建临时表，这都会是不小的开销**。\n\n### 线程池\n与临时表类似，我们可以从mysqlreport中看到线程的使用情况：\n\n\t__ Threads _________________________________________________________\n\tRunning             1 of    1\n\tCached              1 of    8      %Hit:  97.44\n\tCreated             2     0.0/s\n\tSlow                0       0/s\n\n这里我们看到，线程池的命中情况为97.44%，当然，命中率100%当然是最好的。一个比较好的以夷伐夷是在应用中，**尽量使用持久连接，这将在一定程度上减少线程的重复创建**。\n\n### 反范式化设计\n在学校的时候，数据库老师都会教我们，设计数据库的时候，要遵守一定的范式。比如说**第三范式**。简单的说，**第三范式要求在一个数据表中，非主键字段这之间不能存在依赖关系，这样可以避免更新异常、插入异常和删除异常，保证关系的一致性，并且减少数据冗余**。\n\n比如以下表的设计就是遵循范式：\n\n\t（用户ID，好友ID）\n\t（用户ID，用户昵称，用户邮箱，注册时间，联系电话）\n\n如果这是学校考试，那绝对是满分呐。我们对这两表中的数据进行查询，比如查询某用户的其好友的昵称。这里，我们可以有两种查询方式：\n+ 将两个表进行一次联合查询；\n+ 先在第一个表中查询出所有好友的ID，然后在第二个表中查询这些ID对应的昵称。\n\n显然，不论是采用哪一种方式，都需要打开两张数据表。那么，如果我们这么设计呢：\n\n\t（用户ID，好友ID，用户昵称）\n\t（用户ID，用户昵称，用户邮箱，注册时间，联系电话）\n\n这样一来，刚刚查询好友昵称的需求只需要打开第一张表就可以完成，当然付出的代价就是数据有冗余，而且进行数据更新时，可能会对数据造成不一致。但是实际中，有多少用户会一直修改它的昵称呢？所以，**实际中，引入一些反范式的设计也是可行的，当然前提是，它的性能将会提高**。\n\n### 放弃关系型数据库\n有些时候，相较于传统关系型数据库，我们采用Key-Value形式的数据库更加简单有效。具体可以阅读下相关资料 —— [NoSQL](http://en.wikipedia.org/wiki/NoSQL)。","source":"_posts/2015-02-01-0.md","raw":"---\ndate: 2015-02-01\nlayout: post\ntitle: 构建高性能服务器 -- 数据库篇\npermalink: '/2015/02-01-0.html'\ncategories:\n- 服务器编程\ntags:\n- 性能\n---\n\n## 写在前面\n服务器数据，如用户相关数据，都需要保存起来，随时取出再次使用。当然，现在的[内存数据库](http://zh.wikipedia.org/zh/%E5%86%85%E5%AD%98%E6%95%B0%E6%8D%AE%E5%BA%93)也已经发展到相对可靠的阶段了，但是，我们这里还是讨论一个传统关系型数据库在构建高性能服务器方面的使用，如MySQL。\n\n## 利其器\n### 友好的MySQL状态报告\n俗话说，工欲善其事，必先利其器。所以，在服务器端数据库性能优化方面，我们先介绍下一个利器 -- [mysqlreport](http://www.tin.org/bin/man.cgi?section=1&topic=mysqlreport)。\n\n当然，在MySQL命令行中，我们可获取当前数据库的状态：\n\n```bash\nmysql> show status;\nmysql> show innodb status;\n```\n\n那么还需要mysqlreport干什么呢？当然，身为资深码农，我们一直以高标准要求，所以**mysqlreport是一款友好方式的数据库状态检测工具**，各方面甩直白的MySQL命令行好几条街。\n\n我们利用mysqlreport获取下当前状态：\n\n```bash\nmysql> mysqlreport --user USER_NAME --password PASSWORD\n```\n\n具体状态结果很长，就不放了，有兴趣的同学可以自己去试下。\n\n### 解释查询\nSQL语句的性能如何该如何知晓呢？**解释查询explain**横空出世。\n\nexplain的使用方式非常简单，举个简单例子，我们用以下语句创建数据表：\n\n```bash\ncreate table test (\n\tid int(11) not null auto_increment,\n\tname varchar(255) not null,\n\tprimary key (id)\n);\n```\n\n然后我们用存储过程向test数据表中增加一些数据。首先创建function:\n\n```base\ndelimiter //\ncreate function rs(n int)\nreturns varchar(255)\nbegin\n\tdeclare chars char(26) default 'abcdefghijklmnopqrstuvwxyz';\n\tdeclare res varchar(1024) default '';\n\tdeclare i int default 0;\n\trepeat\n\tset i = i + 1;\n\tset res = concat(res, substring(chars, floor(1 + rand() * 26), 1));\n\tuntil i = n end repeat;\n\treturn res;\nend\n//\n```\n然后创建存储过程：\n\n```bash\ndelimiter //\ncreate procedure inst(n int)\nbegin\n\tdeclare i int default 0;\n\tset autocommit = 0;\n\trepeat\n\tset i = i + 1;\n\tinsert into test set name=rs(16);\n\tuntil i = n end repeat;\n\tcommit;\n\tset autocommit = 1;\nend\n//\n```\n\n最后调用新创建的存储过程inst：\n\n```bash\ncall inst(100000);\n```\n这时，我们已向数据表中插入了10W条数据。这时，我们对该数据表中数据进行查询，看下效率如何该怎么办呢？我们利用**explain**语句进行查看：\n\n```bash\nexplain select * from test where id = 999;\n```\n\n得到结果如下：\n\n\t+----+-------------+-------+-------+---------------+---------+---------+-------+------+-------+\n\t| id | select_type | table | type  | possible_keys | key     | key_len | ref   | rows | extra |\n\t+----+-------------+-------+-------+---------------+---------+---------+-------+------+-------+\n\t|  1 | simple      | test  | const | primary       | primary | 4       | const |    1 |       |\n\t+----+-------------+-------+-------+---------------+---------+---------+-------+------+-------+\n\n我们可以看到，结果中type为const，这表示这次查询通过索引直接找到一个匹配行，优化器认为它的时间复杂度为常量。而根据key的值primary，意味着这次查询使用了主键索引。\n\n然后我们利用**explain**语句查看另外的查询语句：\n\n```base\nexplain select * from test where name = 'yoxxwmxbpvhyxtyo';'\n```\n\n得到结果为：\n\n\t+----+-------------+-------+------+---------------+------+---------+------+--------+-------------+\n\t| id | select_type | table | type | possible_keys | key  | key_len | ref  | rows   | Extra       |\n\t+----+-------------+-------+------+---------------+------+---------+------+--------+-------------+\n\t|  1 | SIMPLE      | test  | ALL  | NULL          | NULL | NULL    | NULL | 100260 | Using where |\n\t+----+-------------+-------+------+---------------+------+---------+------+--------+-------------+\n\n与之前不同的是，这里type值为all，即本次查询采用了全表扫描，而key的值为null，这也理所当然，因为我们并没有将name增加索引。\n\n经过上述简要讲述，大家应该了解到，**explain**语句在数据库优化过程中的确是一把利刃。\n\n### 慢查询分析\n在开发环境中，我们可以对所有查询语句进行explain分析，并建立适当的索引，把数据库性能调至最优。但是，在正式环境中，随着实际数据的积累，查询计算和开销有可能会增加，甚至我们发现有些索引设计并不理想。令人头疼的是，线上环境根本不可能用explain去分析查询语句。这个时候，我们需要一个自动记录下运行环境中每次查询执行时间的工具 —— **MySQL慢查询日志**。\n\n在MySQL中开启这项功能并不复杂，在my.cnf中增加下列配置选项：\n\n\tlong_query_time = 1\n\tlog-slow-queries = /data/var/mysql_slow.log\n\n这意味着，MySQL对执行时间超过1秒的查询请求将记录在log-slow-queries路径的文件中，我们可以用MySQL提供的mysqldumpslow查看日志，也可以通过第三方工具 —— [mysqlsla](http://www.pythian.com/blog/query-profiling-tools-part-1-mysqlsla/)。\n\n当然，我们还可以在mysqlreport的友好报告中发现以下列：\n\n\tSlow 1 s   \t\t722\t\t0.2/s \t\t0.01 \t%MDS: 0.08 \tLog:ON\n\n这其实告诉我们，超过1秒的慢查询每秒有0.2次，占总请求数的0.08%。\n\n## 善其事\n### 正确使用索引\n在影响数据库查询性能的诸多因素中，索引绝对是一个重量级的因素。\n\n#### 什么是索引\n索引说白了，就相当于一本书的目录。很容易理解，如果我们需要寻找一本书中的某一章节，我们会先去查找目录，如此做来可以大大提高查找的效率。但是如果没有索引，即书本目录，我们寻找过程就会变成全书遍历查找。\n\n事实上数据库索引也是一样，可以分为**全表扫描（Full Table Scan）和索引扫描（Index Scan）**两种。在大多数情况下，索引搜索当然要比全表扫描性能高很多，但这也不是绝对的。比如**需要查找的记录占据了整个数据表的大部分，那么使用索引扫描反而比全表扫描更差**。很容易想象，对于一本书，如果需要阅读绝大部分内容，那么按顺序全局阅读比按目录查找再阅读效率更高，因为查找目录也是需要开销的。\n\n另外，为数据库数据建立索引也不是一件简单的事，索引必须对应到数据库的每一行记录，这样一来，**引入数据库索引将会带来一个巨大的目录**，这点存储开销也是不得不重视的。而且，**除了普通索引之外，还有唯一索引，主键，全文索引等，各种索引类型都有可能带来更多额外的开销，如唯一索引插入时必须保证其唯一性，而唯一性检查也是不笔不小的开销**。\n\n这么说来，全表扫描和索引扫描孰优孰劣真心不好说，说句真心话，这是你自己的事情。记住：**为数据表建立索引是你自己的事情，永远不要期待有什么工具会自动帮你建立索引，没有工具会知道你未来会频繁地在哪个字段上进行条件查询，为哪个字段建立索引最优**。\n\n#### 初识索引\n在**利其器**一节中，我们讨论到，可以利用**explain**来进行SQL语句的性能分析。我们还是接着那时的例子，利用主键id进行查询与利用普通字段name进行查询，在查询效率上确有不同，而且一般情况下(查询绝大多数条数情况除外)前者优于后者。\n\n那么我们现在把name字段也修改为索引呢？利用以下语句进行修改：\n\n```bash\nalter table test add key name(name);\n```\n\n然后，我们再用**explain**进行查看：\n\n```bash\nexplain select * from test where name = 'yoxxwmxbpvhyxtyo';\n```\n\n结果稍微有点变化：\n\n\t+----+-------------+-------+------+---------------+------+---------+-------+------+--------------------------+\n\t| id | select_type | table | type | possible_keys | key  | key_len | ref   | rows | Extra                    |\n\t+----+-------------+-------+------+---------------+------+---------+-------+------+--------------------------+\n\t|  1 | SIMPLE      | test  | ref  | name          | name | 257     | const |    1 | Using where; Using index |\n\t+----+-------------+-------+------+---------------+------+---------+-------+------+--------------------------+\n\n现在是什么情况呢？我们可以看到，这时key字段的值为name，即本次查询采用了name字段的索引。另外，**对于没有使用主键索引或者唯一索引的条件查询，查询结果可能有多个匹配行，所以MySQL为这种情况定义的type为ref**，如本次结果中所示。\n\n那么，如果我们进行模糊查询呢？试下吧。\n\n```bash\nexplain select * from test where name like '%mxbpvhy';\n```\n\n看下结果：\n\n\t+----+-------------+-------+-------+---------------+------+---------+------+--------+--------------------------+\n\t| id | select_type | table | type  | possible_keys | key  | key_len | ref  | rows   | Extra                    |\n\t+----+-------------+-------+-------+---------------+------+---------+------+--------+--------------------------+\n\t|  1 | SIMPLE      | test  | index | NULL          | name | 257     | NULL | 100489 | Using where; Using index |\n\t+----+-------------+-------+-------+---------------+------+---------+------+--------+--------------------------+\n\n哇，还是很强力的，连模糊查询都能够利用name索引，可以看到type字段中明确写着index值。\n\n#### 使用组合索引\n实际项目过程中，查询中包含组合条件是不可避免的，如：\n\n\t... where a = 1 and b = 2\n\t... where a = 1 order by b\n\t... where a = 1 group by b\n\n这个时候，如果a和b字段都分别建立了索引，它们仍然不能同时发挥作用。因为**一次查询只能利用一个索引**。如何破？组合索引大叫：我来！\n\n还是基于先前的数据表，我们用以下命令删除先前增加的name索引，增加name_1和name_2两个字段，同时增加name，name_1和name_2的联合索引normal_key：\n\n```bash\nalter table test drop index name;\nalter table test add name_1 not null;\nalter table test add name_2 not null;\nalter table test add index normal_key(name, name_1, name_2);\n```\n\n至此，数据表table中，包含4个字段，具体情况如下：\n\n\t+--------+--------------+------+-----+---------+----------------+\n\t| Field  | Type         | Null | Key | Default | Extra          |\n\t+--------+--------------+------+-----+---------+----------------+\n\t| id     | int(11)      | NO   | PRI | NULL    | auto_increment |\n\t| name   | varchar(255) | NO   | MUL | NULL    |                |\n\t| name_1 | varchar(255) | NO   |     | NULL    |                |\n\t| name_2 | varchar(255) | NO   |     | NULL    |                |\n\t+--------+--------------+------+-----+---------+----------------+\n\n而查看数据表中index得：\n\n\t+-------+------------+------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+\n\t| Table | Non_unique | Key_name   | Seq_in_index | Column_name | Collation | Cardinality | Sub_part | Packed | Null | Index_type | Comment | Index_comment |\n\t+-------+------------+------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+\n\t| test  |          0 | PRIMARY    |            1 | id          | A         |      100288 |     NULL | NULL   |      | BTREE      |         |               |\n\t| test  |          1 | normal_key |            1 | name        | A         |         200 |     NULL | NULL   |      | BTREE      |         |               |\n\t| test  |          1 | normal_key |            2 | name_1      | A         |         200 |     NULL | NULL   |      | BTREE      |         |               |\n\t| test  |          1 | normal_key |            3 | name_2      | A         |         200 |     NULL | NULL   |      | BTREE      |         |               |\n\t+-------+------------+------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+\n\n可看，当前数据表的除了主键索引以外，还有我们刚设置的联合索引normal_key。\n\n这个时候，我们利用**explain**命令看下相关查询语句：\n\n```bash\nexplain select * from test where name = 'abc';\nexplain select * from test where name = 'abc' and name_1 = \"def\";\nexplain select * from test where name = 'abc' and name_1 = 'def' and name_2 = 'ghi';\n```\n\n这些查询语句的结果都是使用索引，具体结果大家可以自行尝试。\n\n这里我们要引入一个**“最左前缀”这个组合索引的基本原则**。这个概念可以如此解释：**如果查询条件检索时，只需要匹配联合索引中的最左顺序一个或多个字段，称为最左索引原则，或者叫最左前缀**。所以，我们查看如下SQL语句时，得到的结果应该是不使用索引。\n\n```bash\nexplain select * from test where name_2 = 'ghi' and name = 'abc';\n```\n\n**然而实际上，还是使用索引的，不得不佩服MySQL强大的SQL优化器**！\n\n#### 索引的正确使用姿势\n当然，事实上，**在整个数据库优化过程中，索引的利用永远是难点，所以，利用好你的explain工具，千万不要想当然**！\n\n凡是都有两面性，所以索引的使用也会有代价产生，具体可以归纳为以下几点：\n+ **索引会占据更多的磁盘空间，很多时候索引甚至比数据本身还要大**。不这现在磁盘的空间很容易达到TB级别，所以通常磁盘空间还未写满时，计算能力的瓶颈已经显现出来的。\n+ **当建立索引的字段发生更新时，会引发索引本身的更新，这将产生不小的计算开销**。这直接决定使用索引的数据表必须是读多写少。\n+ **索引需要我们花费一些额外的时候来维护**。MyISAM和Innodb类型的数据表存储结构会有不同，所以具体维护时也有些不同，比如MyISAM的索引写缓存由于断电可能造成索引的损坏，需要我们及时地手动修复。\n\n### 锁写与等待\n当有多个用户并发访问数据库中某一资源的时候，为了保证并发访问的一致性，数据库必须通过锁机制来协调这些访问。而**锁机制也是影响数据库性能的一个重要点**。\n\n**MySQL为MyISAM类型表提供了表级别的锁定，即当有请求对数据表有更新操作（如update)时，数据表就会被锁定，其他任何对当前表的操作将被排斥，甚至包括select查询**。另外需要注意的是，**更新操作有着默认高优先级，即当表锁释放后，更新操作将先获得锁定，然后才能轮到读取操作**。此机制将可能引发以下情况：频繁更新操作将会使得读取操作长时间等待。\n\n**MySQL为Innodb类型表提供了行锁，即当有请求对数据表有更新操作时，数据表不是全表被锁定，而是更新的特定行，其他任何对当前行的操作将被排斥，但是对其他行的操作将不被限制**。\n\n从概念上对比，似乎行锁要比表锁好。但这并不是绝对的，**理论上就锁定本身而言，行锁定的开销并不比表锁小**。比如对于update密集型的场景，行锁定并不是救世主，因为行锁单位锁定开销比表锁大，所以具体性能只能实测。\n\n### 事务性表的性能\n**MySQL中Innodb类型表不仅支持行锁定，还支持事务**。有时候，我们选择Innodb类型的数据表就是因为其支持事务。当然，如果我们没有在应用程序中使用事务操作的打算，而只是看中了其他特性，如行锁定，外键以及易于修复等，我们仍然可以使用它。\n\nInnodb实现事务是采用**预写日志方式（WAL）**完成的。当有事务提交时，Innodb首先将它写到内存中的事务日志缓冲区中，随后当事务日志写入磁盘时，Innodb才更新实际数据和索引。这里，事务日志写入磁盘的时机可以分为3种：\n+ innodb_flush_log_at_trx_commit=1。这个设置表示事务提交时立即将事务写入磁盘，同时实际数据和索引也更新。\n+ innodb_flush_log_at_trx_commit=0。这个设置表示事务提交时不立即将事务写入磁盘，而是每隔1秒写入磁盘文件一次，并且刷新到磁盘中，同时更新实际数据和索引。这种方式如果在事务提交和事务写入磁盘之间发生mysqld崩溃的话，那么在内存中的最近1秒的数据将会丢失，注意，是永久性丢失。\n+ innodb_flush_log_at_trx_commit=2。这个设置表示事务提交时立即写入磁盘，但没有刷新到磁盘，而是存放在磁盘缓冲区，每隔1秒刷新磁盘一次，同时更新数据和索引。这种方式如果发生mysqld崩溃的话，数据并不会丢失，因为存放在磁盘缓冲区的数据还是会刷新到磁盘中。但是如果操作系统崩溃的话，那就永久丢失了。\n\n显然，第2种方式性能最高，但是丢失数据的可能性也最大。\n\n另外，MySQL有一个选项会影响到上述3种方式的实现，它就是innodb_flush_method选项。我们可以将该选项设置为O_DIRECT，如下\n\n\tinnodb_flush_method = O_DIRECT\n\n如此一来，Innodb可以直接I/O，所有的读写操作将会跳过文件系统的系统缓冲区，提高I/O性能，当然，预写日志方式也就会随之改变。\n\n### 使用查询缓存\n**使用查询缓存的目的很简单，那就是提高数据库查询数据的性能**。\n\n**在默认情况下，MySQL是没有开启查询缓存功能**的，我们可以进行以下配置进行开启（开启256MB的内存空间来缓存查询结果）：\n\n\tquery_cache_size = 268435446\n\tquery_cache_type = 1\n\tquery_cache_limit = 1048576\n\n查询缓存功能，不论是MyISAM还是Innodb类型，对于以select为主的应用显然性能会大增。但是令人遗憾的是，MySQL的缓存过期策略并不是十分令人满意。**当一个数据表有更新操作后，那么涉及这个表的所有查询缓存均失效**。话虽如此，但是对于select操作占绝大部分的应用，还是极大的福音。我们只要注意不要将其使用在select和update交叉混合的应用就可以了。\n\n另外，我们可以利用mysqlreport查看查询缓存的状态，如下所示：\n\n\t__ Query Cache ______________________________________________________\n\tMemory usage   17.11k of  16.00M  %Used:   0.10\n\tBlock Fragmnt 100.00%\n\tHits                2     0.0/s\n\tInserts            13     0.0/s\n\tInsrt:Prune      13:1     0.0/s\n\tHit:Insert     0.15:1\n\n很显示，当前缓存区大小为16M，而现在使用了17K，另外，Insrt:Prume代表查询结果进入缓存的次数和过期被删除的次数的比例，当然，这个比例越大，表示查询操作与更新操作相比更频繁，也就更适合使用查询缓存。\n\n### 临时表\n我们利用mysqlreport时，可以发现有Using temporary的状态，如下：\n\n\t__ Created Temp ________________________________________________________\n\tDisk table         75     0.0/s\n\tTable             296     0.0/s    Size:  16.0M\n\tFile               10     0.0/s\n\n当然，我们这里的要求就是**尽量避免使用临时表，因为无论是在磁盘（Disk table），内存(Table)，还是在文件（File）中创建临时表，这都会是不小的开销**。\n\n### 线程池\n与临时表类似，我们可以从mysqlreport中看到线程的使用情况：\n\n\t__ Threads _________________________________________________________\n\tRunning             1 of    1\n\tCached              1 of    8      %Hit:  97.44\n\tCreated             2     0.0/s\n\tSlow                0       0/s\n\n这里我们看到，线程池的命中情况为97.44%，当然，命中率100%当然是最好的。一个比较好的以夷伐夷是在应用中，**尽量使用持久连接，这将在一定程度上减少线程的重复创建**。\n\n### 反范式化设计\n在学校的时候，数据库老师都会教我们，设计数据库的时候，要遵守一定的范式。比如说**第三范式**。简单的说，**第三范式要求在一个数据表中，非主键字段这之间不能存在依赖关系，这样可以避免更新异常、插入异常和删除异常，保证关系的一致性，并且减少数据冗余**。\n\n比如以下表的设计就是遵循范式：\n\n\t（用户ID，好友ID）\n\t（用户ID，用户昵称，用户邮箱，注册时间，联系电话）\n\n如果这是学校考试，那绝对是满分呐。我们对这两表中的数据进行查询，比如查询某用户的其好友的昵称。这里，我们可以有两种查询方式：\n+ 将两个表进行一次联合查询；\n+ 先在第一个表中查询出所有好友的ID，然后在第二个表中查询这些ID对应的昵称。\n\n显然，不论是采用哪一种方式，都需要打开两张数据表。那么，如果我们这么设计呢：\n\n\t（用户ID，好友ID，用户昵称）\n\t（用户ID，用户昵称，用户邮箱，注册时间，联系电话）\n\n这样一来，刚刚查询好友昵称的需求只需要打开第一张表就可以完成，当然付出的代价就是数据有冗余，而且进行数据更新时，可能会对数据造成不一致。但是实际中，有多少用户会一直修改它的昵称呢？所以，**实际中，引入一些反范式的设计也是可行的，当然前提是，它的性能将会提高**。\n\n### 放弃关系型数据库\n有些时候，相较于传统关系型数据库，我们采用Key-Value形式的数据库更加简单有效。具体可以阅读下相关资料 —— [NoSQL](http://en.wikipedia.org/wiki/NoSQL)。","slug":"/2015/02-01-0.html","published":1,"updated":"2015-06-19T16:09:05.000Z","comments":1,"photos":[],"link":"","_id":"ciiwjp2z2000rof6gopjc4xke"},{"date":"2015-01-29T16:00:00.000Z","layout":"post","title":"构建高性能服务器 -- 负载均衡篇","_content":"\n## 说在前面的话\n服务器规模的扩展是构建高性能服务器过程中不得不面对的事。当然，这里我们不是指**垂直扩展**，即增加服务器的硬件性能，如CPU频率，内存等，从而提升服务器单机处理能力，而是**水平扩展**，即增加服务器台数，而每台服务器的单机处理能力可能并不出众。\n\n那么，问题来了，这么多的机器，也可以称为服务器节点，该如何选择由哪个节点处理呢？会不会出现请求总是发向固定一个或者几个节点，从而造成这些节点负载高，请求来不及处理，同时剩余的节点又非常空闲呢？当然，这个时候**负载均衡**技术就该大显身手了。\n\n## HTTP重定向\nHttp重定向可以将HTTP请求进行转移，它在Web开发中十分常见，比如用户登陆成功后自动跳转到相应的管理页面。然而事实上它也可以用来做负载均衡。\n\n我们熟悉的镜像下载事实上就是HTTP重定向进行负载均衡的最鲜活生动的例子。我们以从[github](github.com)下载一个zip包为例。在你的终端中输入以下：\n\n```bash\nwget https://github.com/mogutt/TTServer/archive/master.zip\n```\n\n以上命令就是获取github上某一下载包，其过程如下：\n\n```base\n--2015-01-25 14:05:20--  https://github.com/mogutt/TTServer/archive/master.zip\nResolving github.com (github.com)... 192.30.252.130\nConnecting to github.com (github.com)|192.30.252.130|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://codeload.github.com/mogutt/TTServer/zip/master [following]\n--2015-01-25 14:05:22--  https://codeload.github.com/mogutt/TTServer/zip/master\nResolving codeload.github.com (codeload.github.com)... 192.30.252.147\nConnecting to codeload.github.com (codeload.github.com)|192.30.252.147|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 501048 (489K) [application/zip]\nSaving to: ‘master.zip’\n100%[==================================================================>] 501,048     45.4KB/s   in 12s\n2015-01-25 14:05:35 (40.9 KB/s) - ‘master.zip’ saved [501048/501048]\n```\n\n分析以上过程，我们发现，*wget*命令首先向*github.com*（192.30.252.130）发送一个http请求，但是收到的状态码为302，而**302状态码就是让*front end*重新发送请求至另外新的url上，在字段Location上标志，这里即*codeload.github.com*域名下**。这里有同学就会有疑问：哪里有负载均衡的影子？莫急，且听我慢慢道来。请注意这里重定向的做法，我们本来请求的是域名A，即*github.con*，但是服务却响应状态码302，让我们重新将请求发至域名B，即*codeload.github.com*。既然Http重定向可以将请求重新转发至另外的服务器，那么用来做负载均衡有何不可？我们可以总是将Http请求重新定向到负载较小的服务器，如此一来，负载均衡的目的就达到了。\n\n但是，现实总是残酷的。Http重定向实现负载均衡虽然简单易行，但是我们发现，每次请求都会客户端向服务器发送请求， 然后服务器响应Http重定向，然后客户端用新得到的服务器地址再一次请求，最后服务器发送正确响应。OMG，一个请求在客户端与服务端之间来回跑了两次！这是多大的消耗啊！所以**若是对性能有高要求，Http重定向实现负载均衡终归不是较优选择**。\n\n## DNS负载均衡\n我们知道，DNS负责提供域名解析服务，即将域名解析成实际服务器的IP地址。那么，我们能让DNS稍微智能点，在其解析成实际服务器地址时，帮我们进行负载均衡呢？当然，这里的答案的肯定的。\n\n首先，我们来看一个*www.google.com*在小猿所在地杭州西湖会解析成什么IP地址。在终端下输入：\n\n```bash\ndig www.google.com\n```\n\n得到如下结果:\n```bash\n; <<>> DiG 9.9.5-4.3-Ubuntu <<>> www.google.com\n;; global options: +cmd\n;; Got answer:\n;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 12748\n;; flags: qr rd ra; QUERY: 1, ANSWER: 5, AUTHORITY: 0, ADDITIONAL: 1\n;; OPT PSEUDOSECTION:\n; EDNS: version: 0, flags:; udp: 4096\n;; QUESTION SECTION:\n;www.google.com.                        IN      A\n;; ANSWER SECTION:\nwww.google.com.         30      IN      A       173.194.127.210\nwww.google.com.         30      IN      A       173.194.127.211\nwww.google.com.         30      IN      A       173.194.127.208\nwww.google.com.         30      IN      A       173.194.127.209\nwww.google.com.         30      IN      A       173.194.127.212\n;; Query time: 71 msec\n;; SERVER: 127.0.1.1#53(127.0.1.1)\n;; WHEN: Sun Jan 25 14:46:34 CST 2015\n;; MSG SIZE  rcvd: 123\n```\n\n这里，我们可以看到，*www.google.com*拥有5个不同的A记录，事实上DNS解析域名时，也是轮流解析成不同IP地址，以实现简单的负载均衡。\n\n但是，DNS实现负载均衡有一个巨大的弊端，即DNS会进行缓存。DNS缓存本身是一件好事，它会缓解DNS服务器的压力，并且达到快速解析URL的作用。但是若是采用DNS缓存进行负载均衡，其缓存功能就会带来一定的问题：若其中一台服务器出现故障，将其在DNS解析规则中移除，向它的更新要经过TTL时间（一般会设置为10分钟）才会对用户生效，这将是灾难型的。\n\n另一方面，由于DNS负载均衡调度器基本DNS层面，这将导致它的调度灵活性大大减少，比如无法在应用层面（根据HTTP请求的内容）对客户端请求进行策略调度，又或者无法根据服务器真实的负载情况进行灵活调度，将请求转发至负载较小的服务器。\n\n总之，**DNS负载均衡技术看似美好，但是由于它的缓存机制和基本DNS层的特性，最终将其推向无法实际应用的深渊**。\n\n## 反向代理负载均衡\n[反向代理](http://zh.wikipedia.org/wiki/%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86)大家都不陌生，但是它的功能不仅仅如此，事实上，它还能完成负载均衡的工作。**目前几乎所有主流的Web服务器都热衷于支持基于反向代理的负载均衡**。\n\n相比于之前介绍的Http重定向负载均衡和DNS负载均衡，反射代理负载均衡更注重的是请求的“转发”，而前两者更偏向于“转移”。当然，无论是“转发”还是“转移”，我们最终的目的还是相同的，即实现服务器的负载均衡。\n\n那么，反向代理实现负载均衡有什么优势呢？通过我们之前的分析，**Http重定向会让请求在广域网上来回多跑一次，耗时巨大，而DNS实现负载均衡又无法根据实际服务器的真实负载进行均衡，缺乏灵活性**。而反射代理负载均衡将这两个问题全部解决。\n\n但是，反射代理负载均衡也有它的缺点。由于我们是通过反射代理这种机制，即通过Web服务器进行Http请求的调度，这就意味着两件事：\n+ 任何对于实际服务器的HTTP请求都必须经过调度器；\n+ 调度器必须等待实际服务器的HTTP响应，并将它反馈给用户。\n\n而这两件事就决定着所有实际服务器的HTTP流量都要经过调度器，即Web服务器。所以，**若采用这种负载均衡方案，如果后期实际服务器压力巨大需要扩容时，就会有一个制约，那就是Web服务器将成为整个系统的瓶颈**。比如服务器不是密集计算型，则扩展实际服务器对整体的吞吐率提升没有多大的帮助，因为大量的压力在反向代理服务器上。当然，我们了解了这点，只要扩展反向代理服务器就行了。但是**我们将不得不面对服务器可能产生的实际服务器压力或者反向代理服务器压力**。\n\n## IP负载均衡\n之前讲述利用反向代理服务器实现负载均衡时，我们没有提到，这种**负载均衡方案是基于HTTP层面的，即应用层**。我们知道，应用层是网络分层模型中属于最上层，所以每次HTTP请求转发时，都要经过数据链路层（第二层）、网络层（第三层）、传输层（第四层）的转换，实际上这些性能开销是可以尽量避免的。首先，我们来看看传输层上有没有相应的负载均衡方案。\n\n还记得[网络地址转换（NAT）](http://en.wikipedia.org/wiki/Network_address_translation)技术吧。当然，这个过程还是一样的。\n\n![](/img/2015-01-30-0.jpg \"\")\n\n如上图所示，NAT服务器有两块网卡（可能虚拟出来），分别连接外部网络与内部网络，连接外部网络的IP地址为125.12.12.12，连接内部网络的IP地址为10.0.1.50。在内网中与NAT服务器相连的是两台实际服务器，IP地址分别为10.0.1.210和10.0.1.211，它们的默认网关均为10.0.1.50，同时它们在8000端口上监听服务。我们假设从外部IP为202.20.20.20:5656发送数据包至服务器地址125.12.12.12:80。这时，数据包的源IP地址与目的IP地址分别如下：\n\n\t来源IP地址: 202.20.20.20:5656\n\t目的IP地址： 125.12.12.12:80\n\n当数据包到达NAT服务器时内核缓冲区后，NAT服务修改其数据包的目的IP地址，将其修改为实际服务器IP地址，假设修改为10.0.1.210:8000，则经过NAT服务器后，数据包的源IP地址与目的地址分别如下：\n\n\t来源IP地址: 202.20.20.20:5656\n\t目的IP地址： 10.0.1.210:8000\n\n当然，这个数据包最终会到达10.0.1.210这台实际服务器，经过处理后，实际服务器返回响应数据包，其源IP地址与目的地址分别如下：\n\n\t来源IP地址: 10.0.1.210:8000\n\t目的IP地址：202.20.20.20:5656\n\n由于实际服务器的网关为10.0.1.50，所以数据包会到达NAT服务器，而数据包在NAT服务器的内核缓冲区中，其来源IP地址又会被修改为NAT服务器的IP地址，即125.12.12.12，这时其源IP地址与目的地址分别如下：\n\n\t来源IP地址: 125.12.12.12:80 \n\t目的IP地址： 202.20.20.20:5656\n\n所以，在客户端角度看来，他完全不知道有NAT服务器与实际服务器的存在，所以利用NAT服务器进行负载均衡是完全可行的，而且过程就如上述描述过程。\n\n那么问题就剩下这个NAT服务器如何实现了。往简单了说，就是如何修改IP数据包。事实上，Linux内核已经具备这样的能力，从Linux2.4内核开始，其内置的[Netfilter](http://en.wikipedia.org/wiki/Netfilter)模块就可以实现这样的功能。通过[iptables](http://en.wikipedia.org/wiki/Iptables)就可以控制Netfilter模块进行IP数据包的修改。\n\n不严谨的说，NAT服务器就如同路由器一样，它连接外部网络和私有网络，并将来自外部网络的数据包正确转发至私有网络机器。当然，实际上这不能称为路由器。**我们知道路由器的工作是存储转发，除了修改数据包的MAC地址以外，通常它不会对数据包做其他手脚，但这里的NAT服务器却是要对数据包进行必要的修改，包括来源地址和端口，或者目的地址和端口**。\n\n但是，与反向代理一样，NAT服务器**不仅要将用户的请求转发给实际服务器，同时还要将来自实际服务器的响应转发给用户，所以实际上在数据流量较大时，NAT服务器也将成为瓶颈**。请不要忘记，**NAT服务器的数据包转发是在内核缓存中实现的，所以其开销与应用层转发相比将会小很多，所以NAT服务器的转发能力主要取决于NAT服务器的网络带宽，当然同时包括外部网络和内部网络**。\n\nBWT，由于利用NAT实现负载均衡由于工作在运输层，所以还有一个附加的优点：**除了支持HTTP协议以下，还支持其他网络服务协议，如FTP，SMTP，DNS等**。\n\n## 直接路由\n之前讲述的是基于运输层的负载均衡实现，现在我们来看下基于数据链路层的实现。简单来说，它就是**修改数据包的目标MAC地址，将数据包转发到实际服务器上，并且最重要的是，实际服务器的响应包将直接发送至客户端，而不经过调度器**。\n\nR U kidding me？这不可能吧，不经过调度器直接将响应数据包发送至客户端，那不是要求**实际服务器要接入外部网络**？当然，这点是肯定的。\n\n### IP别名\n首先，我们来了解一下IP别名。我们知道，一个网络接口拥有一个IP地址，但是除此之外，我们还可以为它配置多个IP地址，它们称为**IP别名**。这里的**网络接口可以是物理网卡，如eth0，eth1，也可以是虚拟接口，如回环网络接口lo**。\n\n配置IP别名的方法如下：\n\n```bash\n$ ifconfig eth0:0 192.168.0.200\n```\n\n上述命令将给本机增加一个IP别名，具体为*192.168.0.200*。这时我们通过*ping*命令可以直接通过IP别名连接到本机，当然，在局域网其他机器上用*arp*命令也可以看到刚新加的IP别名，而且应该与其他另外一个IP拥有相同的MAC地址，而另外一个IP就是本机原来的IP地址。这时，我们就有两个IP指向了同一个MAC地址，即两个IP指向了同一个机器。\n\n### 修改MAC地址进行负载均衡\n之前我们也讨论过，将数据包的目标MAC地址修改成实际服务器的MAC地址，那么该数据包将会转发给实际服务器。同时，实际服务器又直接接入外部网络，所以实际服务器的响应包不经过调度服务器就可以直接发送回客户端。那么设置IP别名有什么作用呢？事实上，这种方法因为只操作在数据链路层，所以只修改了数据包的目的MAC地址，而网络层相关的数据，如IP地址和端口，还是保持原样的。所以当实际服务器收到数据包时，它会发现该数据包的IP地址并不是它自己的IP地址，这时会发生什么事呢？当然，这种事谁也不想发生。所以这个时候，IP别名就起到了关键性作用，将IP别名设置成与调度服务器的IP相同，这样实际服务器收到的IP包将会非常有归属感。\n\n我们还是看下示意图：\n\n![](/img/2015-01-30-1.jpg \"\")\n\n具体各服务器的IP地址，网关，IP别名如下表所示：\n\n| 服务器说明    | 外部网络IP地址 | 默认网关 |  IP别名 |\n| ------------- | ------------- | ----- | --- |\n|负载均衡调度器| 125.12.12.12 | 125.12.12.1 | 125.12.12.77 |\n| 实际服务器| 125.12.12.20 |   125.12.12.1 | 125.12.12.77 |\n| 实际服务器| 125.12.12.21 |    125.12.12.1 | 125.12.12.77 |\n\n我们看到，两台实际服务器都具有外网IP地址，即接入外部网络，同时均设置了IP别名为125.12.12.77。但是该IP地址并不是负载均衡调度器的IP地址，而负载均衡调度器同时也设置IP别名为125.12.12.77。这是出于什么考虑呢？这样做当然拥有其优点，这样负载均衡调度器可以方便进行替换，只要新设置的负载均衡调度器设置成与实际服务器相同的IP别名即可。\t\n\n当客户端数据包来临时，当然该数据包发向的IP地址为125.12.12.77，即负载均衡调度器可以收到该数据包。这里有同学就会有疑问，实际服务器与调度服务器拥有相同的IP别名，而且均接入外网，为什么不是实际服务器收到数据包呢？事实上，网关在收到数据包时，通过*arp*会问：你们谁的IP地址是125.12.12.77？这个时候，只要调度服务器回答：我！而实际服务器不作声就可以了。当然这里就不详细介绍怎么设置，有兴趣的同学可以搜索关键字“防止服务器响应ARP广播”即可。\n\n调度服务器通过某些策略，如[RR(Round-robin)](http://en.wikipedia.org/wiki/Round-robin_scheduling)，然后将数据包转发给后端实际服务器，假设这里转发给IP地址为125.12.12.20这台实际服务器（通过修改目标MAC地址）。该服务器收到数据包后，发现该数据包的目的IP地址正是自己的IP别名，因为就快乐的收下了。当其处理完业务逻辑，准备给客户端响应时，响应数据包绕过调度服务器，直接发送至125.12.12.1的网关，从而送向外网，到达客户端。\n\n整个过程非常流畅，**实际服务器收到的数据包经过调度服务器负载均衡的，而发送的响应数据包直接流向外网，绕过调度服务器**。如此一来，**上节中NAT负载均衡方法的弱点 -- 请求与响应均经过调度服务器，将毫不存在**。\n\n可惜的是，通过直接路由进行负载均衡也有其不优美之处。**首先，使用直接路由进行数据包转发是基于数据链路层的，因此无法修改数据包的目的端口。其次，由于实际服务器必须连接外网，因此要向IDC购买合法IP地址，不过相比于负载均衡硬件设备，它们还是要便宜得多**。\n\n## IP隧道\n前文讲述的**直接路由负载均衡方法，实际服务器和调度服务器必须在同一个网段，而本节讲述的IP隧道负载均衡方法可以跨WAN网段进行负载均衡**。\n\n基于IP隧道的数据包转发机制，往简单了说，就是**将调度器收到的IP数据包重新封装成一个新的IP数据包，然后将新的数据包转发给实际服务器，然后实际服务器将响应直接发送给客户端**。当然，大家都注意到了，利用此法进行负载均衡，**实际服务器也必须接入外网**，因为与直接路由方法相似，响应数据包要直接从实际服务器发送到客户端，而不经过调度服务器。\n\n另外，**基于IP隧道的负载均衡方式，由于可以跨WAN网段进行数据包转发，所以我们可以将实际服务器根据需要部属在不同的地域，并且根据就近访问的原则来转移请求，比如一些CDN服务便是基于IP隧道技术来实现的**。\n\n## 写在最后\n总的来说，各种负载均衡技术可归纳为：\n+ **基于HTTP重定向负载均衡性能上不佳；**\n+ **基于DNS负载均衡灵活性不够；**\n+ **基于反向代理负载均衡在应用层操作，可以根据应用层数据进行数据转发，但性能上相较于更低层负载均衡较差；**\n+ **基于IP负载均衡请求响应均经过调度服务器，后期服务器扩展上，调度服务器将成为瓶颈；**\n+ **基于直接路由和基于IP隧道的负载均衡技术都适合请求和响应不对称的服务器，如视频服务器，文件下载服务器等，可以非常有效地提高集群的扩展能力；**\n+ **实际实现过程中，还是要与业务紧密结合的，比如CDN服务需要将实际服务器部署在不同的IDC，所以只能采用基于IP隧道的方法。**\n\n\n","source":"_posts/2015-01-30-0.md","raw":"---\ndate: 2015-01-30\nlayout: post\ntitle: 构建高性能服务器 -- 负载均衡篇\npermalink: '/2015/01-30-0.html'\ncategories:\n- 服务器编程\ntags:\n- 性能\n---\n\n## 说在前面的话\n服务器规模的扩展是构建高性能服务器过程中不得不面对的事。当然，这里我们不是指**垂直扩展**，即增加服务器的硬件性能，如CPU频率，内存等，从而提升服务器单机处理能力，而是**水平扩展**，即增加服务器台数，而每台服务器的单机处理能力可能并不出众。\n\n那么，问题来了，这么多的机器，也可以称为服务器节点，该如何选择由哪个节点处理呢？会不会出现请求总是发向固定一个或者几个节点，从而造成这些节点负载高，请求来不及处理，同时剩余的节点又非常空闲呢？当然，这个时候**负载均衡**技术就该大显身手了。\n\n## HTTP重定向\nHttp重定向可以将HTTP请求进行转移，它在Web开发中十分常见，比如用户登陆成功后自动跳转到相应的管理页面。然而事实上它也可以用来做负载均衡。\n\n我们熟悉的镜像下载事实上就是HTTP重定向进行负载均衡的最鲜活生动的例子。我们以从[github](github.com)下载一个zip包为例。在你的终端中输入以下：\n\n```bash\nwget https://github.com/mogutt/TTServer/archive/master.zip\n```\n\n以上命令就是获取github上某一下载包，其过程如下：\n\n```base\n--2015-01-25 14:05:20--  https://github.com/mogutt/TTServer/archive/master.zip\nResolving github.com (github.com)... 192.30.252.130\nConnecting to github.com (github.com)|192.30.252.130|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://codeload.github.com/mogutt/TTServer/zip/master [following]\n--2015-01-25 14:05:22--  https://codeload.github.com/mogutt/TTServer/zip/master\nResolving codeload.github.com (codeload.github.com)... 192.30.252.147\nConnecting to codeload.github.com (codeload.github.com)|192.30.252.147|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 501048 (489K) [application/zip]\nSaving to: ‘master.zip’\n100%[==================================================================>] 501,048     45.4KB/s   in 12s\n2015-01-25 14:05:35 (40.9 KB/s) - ‘master.zip’ saved [501048/501048]\n```\n\n分析以上过程，我们发现，*wget*命令首先向*github.com*（192.30.252.130）发送一个http请求，但是收到的状态码为302，而**302状态码就是让*front end*重新发送请求至另外新的url上，在字段Location上标志，这里即*codeload.github.com*域名下**。这里有同学就会有疑问：哪里有负载均衡的影子？莫急，且听我慢慢道来。请注意这里重定向的做法，我们本来请求的是域名A，即*github.con*，但是服务却响应状态码302，让我们重新将请求发至域名B，即*codeload.github.com*。既然Http重定向可以将请求重新转发至另外的服务器，那么用来做负载均衡有何不可？我们可以总是将Http请求重新定向到负载较小的服务器，如此一来，负载均衡的目的就达到了。\n\n但是，现实总是残酷的。Http重定向实现负载均衡虽然简单易行，但是我们发现，每次请求都会客户端向服务器发送请求， 然后服务器响应Http重定向，然后客户端用新得到的服务器地址再一次请求，最后服务器发送正确响应。OMG，一个请求在客户端与服务端之间来回跑了两次！这是多大的消耗啊！所以**若是对性能有高要求，Http重定向实现负载均衡终归不是较优选择**。\n\n## DNS负载均衡\n我们知道，DNS负责提供域名解析服务，即将域名解析成实际服务器的IP地址。那么，我们能让DNS稍微智能点，在其解析成实际服务器地址时，帮我们进行负载均衡呢？当然，这里的答案的肯定的。\n\n首先，我们来看一个*www.google.com*在小猿所在地杭州西湖会解析成什么IP地址。在终端下输入：\n\n```bash\ndig www.google.com\n```\n\n得到如下结果:\n```bash\n; <<>> DiG 9.9.5-4.3-Ubuntu <<>> www.google.com\n;; global options: +cmd\n;; Got answer:\n;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 12748\n;; flags: qr rd ra; QUERY: 1, ANSWER: 5, AUTHORITY: 0, ADDITIONAL: 1\n;; OPT PSEUDOSECTION:\n; EDNS: version: 0, flags:; udp: 4096\n;; QUESTION SECTION:\n;www.google.com.                        IN      A\n;; ANSWER SECTION:\nwww.google.com.         30      IN      A       173.194.127.210\nwww.google.com.         30      IN      A       173.194.127.211\nwww.google.com.         30      IN      A       173.194.127.208\nwww.google.com.         30      IN      A       173.194.127.209\nwww.google.com.         30      IN      A       173.194.127.212\n;; Query time: 71 msec\n;; SERVER: 127.0.1.1#53(127.0.1.1)\n;; WHEN: Sun Jan 25 14:46:34 CST 2015\n;; MSG SIZE  rcvd: 123\n```\n\n这里，我们可以看到，*www.google.com*拥有5个不同的A记录，事实上DNS解析域名时，也是轮流解析成不同IP地址，以实现简单的负载均衡。\n\n但是，DNS实现负载均衡有一个巨大的弊端，即DNS会进行缓存。DNS缓存本身是一件好事，它会缓解DNS服务器的压力，并且达到快速解析URL的作用。但是若是采用DNS缓存进行负载均衡，其缓存功能就会带来一定的问题：若其中一台服务器出现故障，将其在DNS解析规则中移除，向它的更新要经过TTL时间（一般会设置为10分钟）才会对用户生效，这将是灾难型的。\n\n另一方面，由于DNS负载均衡调度器基本DNS层面，这将导致它的调度灵活性大大减少，比如无法在应用层面（根据HTTP请求的内容）对客户端请求进行策略调度，又或者无法根据服务器真实的负载情况进行灵活调度，将请求转发至负载较小的服务器。\n\n总之，**DNS负载均衡技术看似美好，但是由于它的缓存机制和基本DNS层的特性，最终将其推向无法实际应用的深渊**。\n\n## 反向代理负载均衡\n[反向代理](http://zh.wikipedia.org/wiki/%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86)大家都不陌生，但是它的功能不仅仅如此，事实上，它还能完成负载均衡的工作。**目前几乎所有主流的Web服务器都热衷于支持基于反向代理的负载均衡**。\n\n相比于之前介绍的Http重定向负载均衡和DNS负载均衡，反射代理负载均衡更注重的是请求的“转发”，而前两者更偏向于“转移”。当然，无论是“转发”还是“转移”，我们最终的目的还是相同的，即实现服务器的负载均衡。\n\n那么，反向代理实现负载均衡有什么优势呢？通过我们之前的分析，**Http重定向会让请求在广域网上来回多跑一次，耗时巨大，而DNS实现负载均衡又无法根据实际服务器的真实负载进行均衡，缺乏灵活性**。而反射代理负载均衡将这两个问题全部解决。\n\n但是，反射代理负载均衡也有它的缺点。由于我们是通过反射代理这种机制，即通过Web服务器进行Http请求的调度，这就意味着两件事：\n+ 任何对于实际服务器的HTTP请求都必须经过调度器；\n+ 调度器必须等待实际服务器的HTTP响应，并将它反馈给用户。\n\n而这两件事就决定着所有实际服务器的HTTP流量都要经过调度器，即Web服务器。所以，**若采用这种负载均衡方案，如果后期实际服务器压力巨大需要扩容时，就会有一个制约，那就是Web服务器将成为整个系统的瓶颈**。比如服务器不是密集计算型，则扩展实际服务器对整体的吞吐率提升没有多大的帮助，因为大量的压力在反向代理服务器上。当然，我们了解了这点，只要扩展反向代理服务器就行了。但是**我们将不得不面对服务器可能产生的实际服务器压力或者反向代理服务器压力**。\n\n## IP负载均衡\n之前讲述利用反向代理服务器实现负载均衡时，我们没有提到，这种**负载均衡方案是基于HTTP层面的，即应用层**。我们知道，应用层是网络分层模型中属于最上层，所以每次HTTP请求转发时，都要经过数据链路层（第二层）、网络层（第三层）、传输层（第四层）的转换，实际上这些性能开销是可以尽量避免的。首先，我们来看看传输层上有没有相应的负载均衡方案。\n\n还记得[网络地址转换（NAT）](http://en.wikipedia.org/wiki/Network_address_translation)技术吧。当然，这个过程还是一样的。\n\n![](/img/2015-01-30-0.jpg \"\")\n\n如上图所示，NAT服务器有两块网卡（可能虚拟出来），分别连接外部网络与内部网络，连接外部网络的IP地址为125.12.12.12，连接内部网络的IP地址为10.0.1.50。在内网中与NAT服务器相连的是两台实际服务器，IP地址分别为10.0.1.210和10.0.1.211，它们的默认网关均为10.0.1.50，同时它们在8000端口上监听服务。我们假设从外部IP为202.20.20.20:5656发送数据包至服务器地址125.12.12.12:80。这时，数据包的源IP地址与目的IP地址分别如下：\n\n\t来源IP地址: 202.20.20.20:5656\n\t目的IP地址： 125.12.12.12:80\n\n当数据包到达NAT服务器时内核缓冲区后，NAT服务修改其数据包的目的IP地址，将其修改为实际服务器IP地址，假设修改为10.0.1.210:8000，则经过NAT服务器后，数据包的源IP地址与目的地址分别如下：\n\n\t来源IP地址: 202.20.20.20:5656\n\t目的IP地址： 10.0.1.210:8000\n\n当然，这个数据包最终会到达10.0.1.210这台实际服务器，经过处理后，实际服务器返回响应数据包，其源IP地址与目的地址分别如下：\n\n\t来源IP地址: 10.0.1.210:8000\n\t目的IP地址：202.20.20.20:5656\n\n由于实际服务器的网关为10.0.1.50，所以数据包会到达NAT服务器，而数据包在NAT服务器的内核缓冲区中，其来源IP地址又会被修改为NAT服务器的IP地址，即125.12.12.12，这时其源IP地址与目的地址分别如下：\n\n\t来源IP地址: 125.12.12.12:80 \n\t目的IP地址： 202.20.20.20:5656\n\n所以，在客户端角度看来，他完全不知道有NAT服务器与实际服务器的存在，所以利用NAT服务器进行负载均衡是完全可行的，而且过程就如上述描述过程。\n\n那么问题就剩下这个NAT服务器如何实现了。往简单了说，就是如何修改IP数据包。事实上，Linux内核已经具备这样的能力，从Linux2.4内核开始，其内置的[Netfilter](http://en.wikipedia.org/wiki/Netfilter)模块就可以实现这样的功能。通过[iptables](http://en.wikipedia.org/wiki/Iptables)就可以控制Netfilter模块进行IP数据包的修改。\n\n不严谨的说，NAT服务器就如同路由器一样，它连接外部网络和私有网络，并将来自外部网络的数据包正确转发至私有网络机器。当然，实际上这不能称为路由器。**我们知道路由器的工作是存储转发，除了修改数据包的MAC地址以外，通常它不会对数据包做其他手脚，但这里的NAT服务器却是要对数据包进行必要的修改，包括来源地址和端口，或者目的地址和端口**。\n\n但是，与反向代理一样，NAT服务器**不仅要将用户的请求转发给实际服务器，同时还要将来自实际服务器的响应转发给用户，所以实际上在数据流量较大时，NAT服务器也将成为瓶颈**。请不要忘记，**NAT服务器的数据包转发是在内核缓存中实现的，所以其开销与应用层转发相比将会小很多，所以NAT服务器的转发能力主要取决于NAT服务器的网络带宽，当然同时包括外部网络和内部网络**。\n\nBWT，由于利用NAT实现负载均衡由于工作在运输层，所以还有一个附加的优点：**除了支持HTTP协议以下，还支持其他网络服务协议，如FTP，SMTP，DNS等**。\n\n## 直接路由\n之前讲述的是基于运输层的负载均衡实现，现在我们来看下基于数据链路层的实现。简单来说，它就是**修改数据包的目标MAC地址，将数据包转发到实际服务器上，并且最重要的是，实际服务器的响应包将直接发送至客户端，而不经过调度器**。\n\nR U kidding me？这不可能吧，不经过调度器直接将响应数据包发送至客户端，那不是要求**实际服务器要接入外部网络**？当然，这点是肯定的。\n\n### IP别名\n首先，我们来了解一下IP别名。我们知道，一个网络接口拥有一个IP地址，但是除此之外，我们还可以为它配置多个IP地址，它们称为**IP别名**。这里的**网络接口可以是物理网卡，如eth0，eth1，也可以是虚拟接口，如回环网络接口lo**。\n\n配置IP别名的方法如下：\n\n```bash\n$ ifconfig eth0:0 192.168.0.200\n```\n\n上述命令将给本机增加一个IP别名，具体为*192.168.0.200*。这时我们通过*ping*命令可以直接通过IP别名连接到本机，当然，在局域网其他机器上用*arp*命令也可以看到刚新加的IP别名，而且应该与其他另外一个IP拥有相同的MAC地址，而另外一个IP就是本机原来的IP地址。这时，我们就有两个IP指向了同一个MAC地址，即两个IP指向了同一个机器。\n\n### 修改MAC地址进行负载均衡\n之前我们也讨论过，将数据包的目标MAC地址修改成实际服务器的MAC地址，那么该数据包将会转发给实际服务器。同时，实际服务器又直接接入外部网络，所以实际服务器的响应包不经过调度服务器就可以直接发送回客户端。那么设置IP别名有什么作用呢？事实上，这种方法因为只操作在数据链路层，所以只修改了数据包的目的MAC地址，而网络层相关的数据，如IP地址和端口，还是保持原样的。所以当实际服务器收到数据包时，它会发现该数据包的IP地址并不是它自己的IP地址，这时会发生什么事呢？当然，这种事谁也不想发生。所以这个时候，IP别名就起到了关键性作用，将IP别名设置成与调度服务器的IP相同，这样实际服务器收到的IP包将会非常有归属感。\n\n我们还是看下示意图：\n\n![](/img/2015-01-30-1.jpg \"\")\n\n具体各服务器的IP地址，网关，IP别名如下表所示：\n\n| 服务器说明    | 外部网络IP地址 | 默认网关 |  IP别名 |\n| ------------- | ------------- | ----- | --- |\n|负载均衡调度器| 125.12.12.12 | 125.12.12.1 | 125.12.12.77 |\n| 实际服务器| 125.12.12.20 |   125.12.12.1 | 125.12.12.77 |\n| 实际服务器| 125.12.12.21 |    125.12.12.1 | 125.12.12.77 |\n\n我们看到，两台实际服务器都具有外网IP地址，即接入外部网络，同时均设置了IP别名为125.12.12.77。但是该IP地址并不是负载均衡调度器的IP地址，而负载均衡调度器同时也设置IP别名为125.12.12.77。这是出于什么考虑呢？这样做当然拥有其优点，这样负载均衡调度器可以方便进行替换，只要新设置的负载均衡调度器设置成与实际服务器相同的IP别名即可。\t\n\n当客户端数据包来临时，当然该数据包发向的IP地址为125.12.12.77，即负载均衡调度器可以收到该数据包。这里有同学就会有疑问，实际服务器与调度服务器拥有相同的IP别名，而且均接入外网，为什么不是实际服务器收到数据包呢？事实上，网关在收到数据包时，通过*arp*会问：你们谁的IP地址是125.12.12.77？这个时候，只要调度服务器回答：我！而实际服务器不作声就可以了。当然这里就不详细介绍怎么设置，有兴趣的同学可以搜索关键字“防止服务器响应ARP广播”即可。\n\n调度服务器通过某些策略，如[RR(Round-robin)](http://en.wikipedia.org/wiki/Round-robin_scheduling)，然后将数据包转发给后端实际服务器，假设这里转发给IP地址为125.12.12.20这台实际服务器（通过修改目标MAC地址）。该服务器收到数据包后，发现该数据包的目的IP地址正是自己的IP别名，因为就快乐的收下了。当其处理完业务逻辑，准备给客户端响应时，响应数据包绕过调度服务器，直接发送至125.12.12.1的网关，从而送向外网，到达客户端。\n\n整个过程非常流畅，**实际服务器收到的数据包经过调度服务器负载均衡的，而发送的响应数据包直接流向外网，绕过调度服务器**。如此一来，**上节中NAT负载均衡方法的弱点 -- 请求与响应均经过调度服务器，将毫不存在**。\n\n可惜的是，通过直接路由进行负载均衡也有其不优美之处。**首先，使用直接路由进行数据包转发是基于数据链路层的，因此无法修改数据包的目的端口。其次，由于实际服务器必须连接外网，因此要向IDC购买合法IP地址，不过相比于负载均衡硬件设备，它们还是要便宜得多**。\n\n## IP隧道\n前文讲述的**直接路由负载均衡方法，实际服务器和调度服务器必须在同一个网段，而本节讲述的IP隧道负载均衡方法可以跨WAN网段进行负载均衡**。\n\n基于IP隧道的数据包转发机制，往简单了说，就是**将调度器收到的IP数据包重新封装成一个新的IP数据包，然后将新的数据包转发给实际服务器，然后实际服务器将响应直接发送给客户端**。当然，大家都注意到了，利用此法进行负载均衡，**实际服务器也必须接入外网**，因为与直接路由方法相似，响应数据包要直接从实际服务器发送到客户端，而不经过调度服务器。\n\n另外，**基于IP隧道的负载均衡方式，由于可以跨WAN网段进行数据包转发，所以我们可以将实际服务器根据需要部属在不同的地域，并且根据就近访问的原则来转移请求，比如一些CDN服务便是基于IP隧道技术来实现的**。\n\n## 写在最后\n总的来说，各种负载均衡技术可归纳为：\n+ **基于HTTP重定向负载均衡性能上不佳；**\n+ **基于DNS负载均衡灵活性不够；**\n+ **基于反向代理负载均衡在应用层操作，可以根据应用层数据进行数据转发，但性能上相较于更低层负载均衡较差；**\n+ **基于IP负载均衡请求响应均经过调度服务器，后期服务器扩展上，调度服务器将成为瓶颈；**\n+ **基于直接路由和基于IP隧道的负载均衡技术都适合请求和响应不对称的服务器，如视频服务器，文件下载服务器等，可以非常有效地提高集群的扩展能力；**\n+ **实际实现过程中，还是要与业务紧密结合的，比如CDN服务需要将实际服务器部署在不同的IDC，所以只能采用基于IP隧道的方法。**\n\n\n","slug":"/2015/01-30-0.html","published":1,"updated":"2015-06-19T16:09:05.000Z","comments":1,"photos":[],"link":"","_id":"ciiwjp2z5000vof6gth1a0w8c"},{"date":"2015-01-24T16:00:00.000Z","layout":"post","title":"移动时代互联网金融的架构趋势","_content":"\n## 引子\n有幸参加了[又拍网](https://www.upyun.com/index.html)组织的Open Talk No.2 -- 移动时代互联网金融的架构趋势。虽然没有接触过互联网金融这方面的内容，但是怀着成为一个合格程序员的人生梦想的人，怎能错过这样的聚会。\n\n本次Talk请来了三位讲师分别讲述了其所在公司的相关后台技术架构，技术虽然各有千秋，但万变不离其中：**并发，缓存，异步是后台永恒的话题**。\n\n下面主要回顾下挖财和同盾科技的两位讲师的Key Point，而51信用卡的分享以其原始PPT呈现。\n\n## 挖财的互联网金融技术探索\n讲师是挖财首席架构师王福强，原阿里资深架构师。他的主题分为以下：\n\n+ **Separation Everywhere**，即组件分离，将服务分组，模块化，有点类似[SOA](http://en.wikipedia.org/wiki/Service-oriented_architecture)的味道（事实上就是SOA）。模块化架构不仅易于后期的代码重构，而且也方便后期的架构调整。而且，组件分离后，可以对各类服务进行分组，将耗时操作与非耗时操作分离，保证两者互不干涉，即使一方繁忙时也不影响另一方。\n\n+ **Async Everywhere**，即异步化。服务器并发量达到一定数量级，必需经过调用的异步化。当相对耗时调用等待时，可以进行其他调用的处理，以此让服务器并发化处理相应业务。\n\n+ **Message Passing Everywhere**，即消息化。服务器内部或者之间通信全部使用消息机制，统一调度。这里[消息中间件](http://baike.baidu.com/view/3118541.htm)就会大显身手。这里挖财就应用了[Kafka](http://kafka.apache.org/)。\n\n+ **Immutability Everywhere**，即持久化。内存中的数据在断电后是无法恢复的，所以一些重要数据，特别是互联网金融领域的相关数据，是不能丢失的，所以及时对数据进行持久化是十分必要的。\n\n+ **Security Everywhere**，即安全性。与持久化类似，互联网金融领域的一些数据是用户的敏感数据，所以对数据的安全必须要仔细考虑。如果数据被拖库的话，在业内声誉就基本毁于一旦了。\n\n+ **Intercept Everywhere**，即拦截。与安全性一样，对敏感业务，数据必须要多长一个心眼。\n\n+ **Auditing Everywhere**，即监控化。服务器硬件各项指标，如CPU负载，内存利用率，磁盘利用率，网络I/O状态等，服务器业务进程各项指标，如业务请求成功数，失败数等，都必须收集汇总，以显示服务器健康度。\n\n+ **Bulkheads Everywhere**，即隔离化。同样这也是服务器架构方面的注意点，合理分层化，模块化，某一服务的异常确保不会影响到其他服务。\n\n+ **Switches Everywhere**，即开关化。针对单独业务接口，或者单独用户，又或者单独IP进行服务开关化。在遇见异常情况下，如恶意用户进行的攻击，窃取私密数据时，及时关闭相应服务。\n\n+ **Redundancy Everywhere**，即冗余化。特别是金融重要数据，如果其丢失将造成不可挽回的损失，所以对相应数据的冗余化，及时做备份也是必要的。\n\n+ **Reactive Everywhere**，即事件驱动化（可能并不是很准确）。这里是指采用事件驱动，网络请求，信号发生等采用事件循环驱动，可以高性能进行并发服务处理。比如[libevent](http://libevent.org)、[libev](http://software.schmorp.de/pkg/libev.html)、[libuv](https://github.com/libuv/libuv)就是成熟的事件驱动框架。\n\n## 从零打造千万级的实时风控云服务\n讲师是来自同盾科技的联合创始人、技术总监张新波，原阿里集团安全部专家。\n\n### 挑战\n风控云服务如果要做好，就必需跨越以下几个挑战：\n+ **性能**\n+ **可用性**\n+ **可扩展性**\n\n事实上，所有后台服务器如果要支持大并发量都要考虑以上3点挑战。\n\n具体到风控云服务上（具体点就是同盾科技内部），性能上的挑战有：\n+ 实时性要求高，服务响应时间通常小于500ms（客户要求）\n+ 计算结果无法缓存，全部需要实时动态计算（风控业务要求)\n+ 参与计算数据量大，计算维度多且复杂（风控业务要求）\n+ 无法像静态资源盘多机房缓存和加速（风控业务要求）\n\n而可用性上有：\n+ 保证服务的稳定性，消除单点故障（服务器基本要求）\n+ 完备的灾备和紧急处理方案，以备不时之需（服务器基本要求）\n\n在可扩展性上则为：\n+ 应用服务器可线性扩展，支撑业务的快速发展（服务器基本要求）\n+ 海量数据的存储和计算，支持线性扩展（服务器基本要求）\n\n可见，在可用性和可扩展性上，同盾科技的实时风控云服务与一般高性能服务器挑战一致，但是在性能上却更具有挑战性，由于一些业务上的特殊情况，不能缓存计算结果将会对服务器的情况上造成巨大的伤害。\n\n### 服务器架构演化\n下图是同盾科技最早版本的服务器架构V0.1（切莫嘲笑其简单，创业初期先走业务实现是根本原则）：\n![](/img/2015-01-25-0.jpg \"\")\n\n我们可以看到，整套服务器采用[Apache](http://httpd.apache.org/)作为服务器的接入层，具体业务逻辑层分别用两台机器做为Admin控制和具体接口服务逻辑计算，而数据层则直接用[MySQL](http://www.mysql.com/)进行存储。特别注意，业务主要逻辑(用户校验，查找策略，保存数据)采用的是直接向数据库**同步**加载数据，而我们知道数据库操作的慢速操作，因此整个服务的并发上不去，明显这个操作将会成为巨大的瓶颈。\n\n因此，在V0.2时，针对V0.1中的同步向数据库读取数据的操作进行缓存优化，使用[Guava Cache](https://code.google.com/p/guava-libraries/wiki/CachesExplained)定时预先加载，缓存全部用户及对应的策略数据。当然这里有些同学就有疑问了，缓存全部用户数据这是不是脑洞太大了。没错，就是全部用户数据，由于早期用户数据不多且业务类型特性（面向企业）决定全部数据也不是不可控。\n在另一方面，数据库写入操作则采用异步写入，引入[Berkeley DB](http://en.wikipedia.org/wiki/Berkeley_DB)作为本地队列辅助进行异步写入。\n\n在V0.2中，随着用户数据量的增多，原先使用Guava Cache进行缓存的方式已经力不从心，所以在V0.3中直接用[Memcached](http://memcached.org/)代替，而且对缓存数据进行了Base64+Gzip的压缩，减少缓存的数据大小。当然，有同学有疑问进行数据压缩转换是否增加了性能压力。事实上，这点性能的损失对服务整体的耗时来说可以忽略不计，所以引入压缩转换减少的缓存量和网络传输量在性价比上来说是值得的。\n\n我们注意到，在上面提及的所有版本中都没有集群的概念，事实上，所有的服务都是单点。当然，这对于一个服务的可用性来说是不良信号，所以在V1.0版本时，不仅消除单点问题，而且新增监控系统([Zabbix](http://www.zabbix.com/))，同时，接入层由Apache替换成性能更强力的[Nginx](http://nginx.com/)，具体架构如下：\n![](/img/2015-01-25-1.jpg \"\")\n\n但是这样就够了吗？\n\n业务数据增加过快，直接引入了新的问题：数据库分表已无法解决数据增加过快问题。所以在V2.x中引入[Cassandra](http://cassandra.apache.org/)数据库，其Wide column store的特点正好解决数据单表过大无法存储的问题。同时，为了解决根据任意维度进行数据查询和分析的性能问题，引入[ElasticSerch](http://www.elasticsearch.org/)进行全字段索引查询。另一方面，坐拥大数据却不知利用则会冠以暴殄天物之名。所以引入[Spark](https://spark.apache.org/)进行离线分析，[Spark streaming](https://spark.apache.org/streaming/)结合[Kafka](https://spark.apache.org/streaming/)则进行实时流计算，\n所以现在的架构演化成如下：\n![](/img/2015-01-25-2.jpg \"\")\n\n### 架构演化带来的思考\n+ **使用熟悉、成熟和社区活跃的开源技术**。\n+ **先满足业务需求，再优化，逐步演进**。\n+ **监控报警，应急预案必须成为系统的一部分**。\n+ **纸上得来终觉浅，绝知此事要躬行**。\n\n## 51信用卡的日志分析变迁史\n参见文后Reference。\n\n## [Reference]\n+ [挖财的互联网金融技术探索](http://upyun-open-talk.b0.upaiyun.com/wacai.pdf)\n+ [从零打造千万级的实时风控云服务](http://upyun-open-talk.b0.upaiyun.com/tongdun.pdf)\n+ [51信用卡的日志分析变迁史](http://upyun-open-talk.b0.upaiyun.com/51xinyongka.pdf)","source":"_posts/2015-01-25-0.md","raw":"---\ndate: 2015-01-25\nlayout: post\ntitle: 移动时代互联网金融的架构趋势\npermalink: '/2015/01-25-0.html'\ncategories:\n- 服务器编程\ntags:\n- 架构\n---\n\n## 引子\n有幸参加了[又拍网](https://www.upyun.com/index.html)组织的Open Talk No.2 -- 移动时代互联网金融的架构趋势。虽然没有接触过互联网金融这方面的内容，但是怀着成为一个合格程序员的人生梦想的人，怎能错过这样的聚会。\n\n本次Talk请来了三位讲师分别讲述了其所在公司的相关后台技术架构，技术虽然各有千秋，但万变不离其中：**并发，缓存，异步是后台永恒的话题**。\n\n下面主要回顾下挖财和同盾科技的两位讲师的Key Point，而51信用卡的分享以其原始PPT呈现。\n\n## 挖财的互联网金融技术探索\n讲师是挖财首席架构师王福强，原阿里资深架构师。他的主题分为以下：\n\n+ **Separation Everywhere**，即组件分离，将服务分组，模块化，有点类似[SOA](http://en.wikipedia.org/wiki/Service-oriented_architecture)的味道（事实上就是SOA）。模块化架构不仅易于后期的代码重构，而且也方便后期的架构调整。而且，组件分离后，可以对各类服务进行分组，将耗时操作与非耗时操作分离，保证两者互不干涉，即使一方繁忙时也不影响另一方。\n\n+ **Async Everywhere**，即异步化。服务器并发量达到一定数量级，必需经过调用的异步化。当相对耗时调用等待时，可以进行其他调用的处理，以此让服务器并发化处理相应业务。\n\n+ **Message Passing Everywhere**，即消息化。服务器内部或者之间通信全部使用消息机制，统一调度。这里[消息中间件](http://baike.baidu.com/view/3118541.htm)就会大显身手。这里挖财就应用了[Kafka](http://kafka.apache.org/)。\n\n+ **Immutability Everywhere**，即持久化。内存中的数据在断电后是无法恢复的，所以一些重要数据，特别是互联网金融领域的相关数据，是不能丢失的，所以及时对数据进行持久化是十分必要的。\n\n+ **Security Everywhere**，即安全性。与持久化类似，互联网金融领域的一些数据是用户的敏感数据，所以对数据的安全必须要仔细考虑。如果数据被拖库的话，在业内声誉就基本毁于一旦了。\n\n+ **Intercept Everywhere**，即拦截。与安全性一样，对敏感业务，数据必须要多长一个心眼。\n\n+ **Auditing Everywhere**，即监控化。服务器硬件各项指标，如CPU负载，内存利用率，磁盘利用率，网络I/O状态等，服务器业务进程各项指标，如业务请求成功数，失败数等，都必须收集汇总，以显示服务器健康度。\n\n+ **Bulkheads Everywhere**，即隔离化。同样这也是服务器架构方面的注意点，合理分层化，模块化，某一服务的异常确保不会影响到其他服务。\n\n+ **Switches Everywhere**，即开关化。针对单独业务接口，或者单独用户，又或者单独IP进行服务开关化。在遇见异常情况下，如恶意用户进行的攻击，窃取私密数据时，及时关闭相应服务。\n\n+ **Redundancy Everywhere**，即冗余化。特别是金融重要数据，如果其丢失将造成不可挽回的损失，所以对相应数据的冗余化，及时做备份也是必要的。\n\n+ **Reactive Everywhere**，即事件驱动化（可能并不是很准确）。这里是指采用事件驱动，网络请求，信号发生等采用事件循环驱动，可以高性能进行并发服务处理。比如[libevent](http://libevent.org)、[libev](http://software.schmorp.de/pkg/libev.html)、[libuv](https://github.com/libuv/libuv)就是成熟的事件驱动框架。\n\n## 从零打造千万级的实时风控云服务\n讲师是来自同盾科技的联合创始人、技术总监张新波，原阿里集团安全部专家。\n\n### 挑战\n风控云服务如果要做好，就必需跨越以下几个挑战：\n+ **性能**\n+ **可用性**\n+ **可扩展性**\n\n事实上，所有后台服务器如果要支持大并发量都要考虑以上3点挑战。\n\n具体到风控云服务上（具体点就是同盾科技内部），性能上的挑战有：\n+ 实时性要求高，服务响应时间通常小于500ms（客户要求）\n+ 计算结果无法缓存，全部需要实时动态计算（风控业务要求)\n+ 参与计算数据量大，计算维度多且复杂（风控业务要求）\n+ 无法像静态资源盘多机房缓存和加速（风控业务要求）\n\n而可用性上有：\n+ 保证服务的稳定性，消除单点故障（服务器基本要求）\n+ 完备的灾备和紧急处理方案，以备不时之需（服务器基本要求）\n\n在可扩展性上则为：\n+ 应用服务器可线性扩展，支撑业务的快速发展（服务器基本要求）\n+ 海量数据的存储和计算，支持线性扩展（服务器基本要求）\n\n可见，在可用性和可扩展性上，同盾科技的实时风控云服务与一般高性能服务器挑战一致，但是在性能上却更具有挑战性，由于一些业务上的特殊情况，不能缓存计算结果将会对服务器的情况上造成巨大的伤害。\n\n### 服务器架构演化\n下图是同盾科技最早版本的服务器架构V0.1（切莫嘲笑其简单，创业初期先走业务实现是根本原则）：\n![](/img/2015-01-25-0.jpg \"\")\n\n我们可以看到，整套服务器采用[Apache](http://httpd.apache.org/)作为服务器的接入层，具体业务逻辑层分别用两台机器做为Admin控制和具体接口服务逻辑计算，而数据层则直接用[MySQL](http://www.mysql.com/)进行存储。特别注意，业务主要逻辑(用户校验，查找策略，保存数据)采用的是直接向数据库**同步**加载数据，而我们知道数据库操作的慢速操作，因此整个服务的并发上不去，明显这个操作将会成为巨大的瓶颈。\n\n因此，在V0.2时，针对V0.1中的同步向数据库读取数据的操作进行缓存优化，使用[Guava Cache](https://code.google.com/p/guava-libraries/wiki/CachesExplained)定时预先加载，缓存全部用户及对应的策略数据。当然这里有些同学就有疑问了，缓存全部用户数据这是不是脑洞太大了。没错，就是全部用户数据，由于早期用户数据不多且业务类型特性（面向企业）决定全部数据也不是不可控。\n在另一方面，数据库写入操作则采用异步写入，引入[Berkeley DB](http://en.wikipedia.org/wiki/Berkeley_DB)作为本地队列辅助进行异步写入。\n\n在V0.2中，随着用户数据量的增多，原先使用Guava Cache进行缓存的方式已经力不从心，所以在V0.3中直接用[Memcached](http://memcached.org/)代替，而且对缓存数据进行了Base64+Gzip的压缩，减少缓存的数据大小。当然，有同学有疑问进行数据压缩转换是否增加了性能压力。事实上，这点性能的损失对服务整体的耗时来说可以忽略不计，所以引入压缩转换减少的缓存量和网络传输量在性价比上来说是值得的。\n\n我们注意到，在上面提及的所有版本中都没有集群的概念，事实上，所有的服务都是单点。当然，这对于一个服务的可用性来说是不良信号，所以在V1.0版本时，不仅消除单点问题，而且新增监控系统([Zabbix](http://www.zabbix.com/))，同时，接入层由Apache替换成性能更强力的[Nginx](http://nginx.com/)，具体架构如下：\n![](/img/2015-01-25-1.jpg \"\")\n\n但是这样就够了吗？\n\n业务数据增加过快，直接引入了新的问题：数据库分表已无法解决数据增加过快问题。所以在V2.x中引入[Cassandra](http://cassandra.apache.org/)数据库，其Wide column store的特点正好解决数据单表过大无法存储的问题。同时，为了解决根据任意维度进行数据查询和分析的性能问题，引入[ElasticSerch](http://www.elasticsearch.org/)进行全字段索引查询。另一方面，坐拥大数据却不知利用则会冠以暴殄天物之名。所以引入[Spark](https://spark.apache.org/)进行离线分析，[Spark streaming](https://spark.apache.org/streaming/)结合[Kafka](https://spark.apache.org/streaming/)则进行实时流计算，\n所以现在的架构演化成如下：\n![](/img/2015-01-25-2.jpg \"\")\n\n### 架构演化带来的思考\n+ **使用熟悉、成熟和社区活跃的开源技术**。\n+ **先满足业务需求，再优化，逐步演进**。\n+ **监控报警，应急预案必须成为系统的一部分**。\n+ **纸上得来终觉浅，绝知此事要躬行**。\n\n## 51信用卡的日志分析变迁史\n参见文后Reference。\n\n## [Reference]\n+ [挖财的互联网金融技术探索](http://upyun-open-talk.b0.upaiyun.com/wacai.pdf)\n+ [从零打造千万级的实时风控云服务](http://upyun-open-talk.b0.upaiyun.com/tongdun.pdf)\n+ [51信用卡的日志分析变迁史](http://upyun-open-talk.b0.upaiyun.com/51xinyongka.pdf)","slug":"/2015/01-25-0.html","published":1,"updated":"2015-06-19T16:09:05.000Z","comments":1,"photos":[],"link":"","_id":"ciiwjp2z8000yof6gaf0lf9y1"},{"date":"2015-01-22T16:00:00.000Z","layout":"post","title":"构建高性能服务器 -- 缓存篇","_content":"\n引子\n------\n说到缓存，相信大家都不陌生。**缓存的目的都在于避免重复的慢速计算，比如数据库访问**。相对于慢速计算，缓存将会大大提高数据存取的速率，当然同时将会缩短用户每次请求处理的时间，从而提升服务器单位时间内的请求处理数，即吞吐率。\n\n操作系统中的缓存\n--------\n事实上，我们使用的操作系统中都存在着大量的缓存机制，比如文件系统存在**内核缓冲区**。它位于物理内存的内核地址空间，除了使用**O_DIRECT**标记打开的文件以外，所有对磁盘文件的读写操作都要经过它，所以它相当于磁盘的缓存区域。\n\n这块内核缓冲区也称为**页高速缓存**，实际上它包括以下两部分组成：\n\n* 读缓存区\n* 写缓存区\n\n读缓存区保存着最近从磁盘上读取的数据，当下次读取相同数据时，可以直接从读缓存区直接读取数据，避免了从磁盘上进行慢速操作。\n\n写缓存区则保存着将要写入磁盘的数据，从而避免用户进程直接进行磁盘数据的写入而产生慢速操作等待。\n\n所以无论是读缓存区还是写缓存区，都有效避免用户进程直接进行慢速操作，即直接与磁盘进行数据交互 ---- 读或者写。\n\n服务器中的缓存\n-----------\n与操作系统中的缓存类似，我们构建高性能服务器时，也可以**在服务器的业务逻辑层与数据层（数据一般存入数据库进行持久化）之间再加设一层缓存层**。当然，缓存层的作用也就是避免业务逻辑层与数据层直接交互，从而产生慢速操作，进而影响到服务器的性能。\n\n当业务逻辑层需要读取数据层的相关数据时，向缓存层请求相应数据，若数据存在于缓存层，则直接从缓存层读取，若不存在，则向后端数据层读取，并同时向缓存层保存一份。当下次请求相同数据时，则无需向数据层请求，因为缓存层中已有相应数据。\n\n当业务逻辑层需要向数据层写入数据时，首先向缓存层请求数据写入，并快速响应写入成功，而缓存层再异步向数据层真正写入数据。如此做法可以减少用户请求等待时间，提高服务器并发性能。\n\n分步式缓存系统\n----------\n开源社区已有非常成熟的分布式缓存系统，比如说[memcached](http://memcached.org/), [redis](http://redis.io/)等。它们都是属于[NoSQL](http://en.wikipedia.org/wiki/NoSQL)范畴，都是以Key-Value形式进行存储的。\n\n我们以memcached为例。\n\n首先，memcached高效的最大原因就是其**基于Key的Hash算法来存储数据结构，并且使用了非常高效的内存分配器（事先向操作系统请求了大片内存，再进行自我管理，避免大量内存申请与释放操作）**，所以使数据项的查询时间复杂度达到O(1)。\n\n其次，**memcached采用[libevent](http://libevent.org/)作为其底层的网络事件库**。而libevent又是业界较好的同类型开源库，所以从底层I/O网络模型上保障其可以进行高并发数据存取操作。\n\n再次，memcached是一种分步式缓存系统，所以**在理论上可以无限扩容，即扩展服务器数量，提高服务器集群并发处理能力**。而且，它采用**[一致性Hash](http://zh.wikipedia.org/zh/%E4%B8%80%E8%87%B4%E5%93%88%E5%B8%8C)**方法，从而减少因缓存服务器扩容或者下线造成的数据缓存失效问题。\n\nBTW，memcached采用**LRU(Least Recently Used)**及时淘汰非热点数据，从而保障所缓存数据均为热点数据，最大效率使用机器内存。","source":"_posts/2015-01-23-0.md","raw":"---\ndate: 2015-01-23\nlayout: post\ntitle: 构建高性能服务器 -- 缓存篇\npermalink: '/2015/01-23-0.html'\ncategories:\n- 服务器编程\ntags:\n- 性能\n---\n\n引子\n------\n说到缓存，相信大家都不陌生。**缓存的目的都在于避免重复的慢速计算，比如数据库访问**。相对于慢速计算，缓存将会大大提高数据存取的速率，当然同时将会缩短用户每次请求处理的时间，从而提升服务器单位时间内的请求处理数，即吞吐率。\n\n操作系统中的缓存\n--------\n事实上，我们使用的操作系统中都存在着大量的缓存机制，比如文件系统存在**内核缓冲区**。它位于物理内存的内核地址空间，除了使用**O_DIRECT**标记打开的文件以外，所有对磁盘文件的读写操作都要经过它，所以它相当于磁盘的缓存区域。\n\n这块内核缓冲区也称为**页高速缓存**，实际上它包括以下两部分组成：\n\n* 读缓存区\n* 写缓存区\n\n读缓存区保存着最近从磁盘上读取的数据，当下次读取相同数据时，可以直接从读缓存区直接读取数据，避免了从磁盘上进行慢速操作。\n\n写缓存区则保存着将要写入磁盘的数据，从而避免用户进程直接进行磁盘数据的写入而产生慢速操作等待。\n\n所以无论是读缓存区还是写缓存区，都有效避免用户进程直接进行慢速操作，即直接与磁盘进行数据交互 ---- 读或者写。\n\n服务器中的缓存\n-----------\n与操作系统中的缓存类似，我们构建高性能服务器时，也可以**在服务器的业务逻辑层与数据层（数据一般存入数据库进行持久化）之间再加设一层缓存层**。当然，缓存层的作用也就是避免业务逻辑层与数据层直接交互，从而产生慢速操作，进而影响到服务器的性能。\n\n当业务逻辑层需要读取数据层的相关数据时，向缓存层请求相应数据，若数据存在于缓存层，则直接从缓存层读取，若不存在，则向后端数据层读取，并同时向缓存层保存一份。当下次请求相同数据时，则无需向数据层请求，因为缓存层中已有相应数据。\n\n当业务逻辑层需要向数据层写入数据时，首先向缓存层请求数据写入，并快速响应写入成功，而缓存层再异步向数据层真正写入数据。如此做法可以减少用户请求等待时间，提高服务器并发性能。\n\n分步式缓存系统\n----------\n开源社区已有非常成熟的分布式缓存系统，比如说[memcached](http://memcached.org/), [redis](http://redis.io/)等。它们都是属于[NoSQL](http://en.wikipedia.org/wiki/NoSQL)范畴，都是以Key-Value形式进行存储的。\n\n我们以memcached为例。\n\n首先，memcached高效的最大原因就是其**基于Key的Hash算法来存储数据结构，并且使用了非常高效的内存分配器（事先向操作系统请求了大片内存，再进行自我管理，避免大量内存申请与释放操作）**，所以使数据项的查询时间复杂度达到O(1)。\n\n其次，**memcached采用[libevent](http://libevent.org/)作为其底层的网络事件库**。而libevent又是业界较好的同类型开源库，所以从底层I/O网络模型上保障其可以进行高并发数据存取操作。\n\n再次，memcached是一种分步式缓存系统，所以**在理论上可以无限扩容，即扩展服务器数量，提高服务器集群并发处理能力**。而且，它采用**[一致性Hash](http://zh.wikipedia.org/zh/%E4%B8%80%E8%87%B4%E5%93%88%E5%B8%8C)**方法，从而减少因缓存服务器扩容或者下线造成的数据缓存失效问题。\n\nBTW，memcached采用**LRU(Least Recently Used)**及时淘汰非热点数据，从而保障所缓存数据均为热点数据，最大效率使用机器内存。","slug":"/2015/01-23-0.html","published":1,"updated":"2015-06-19T16:09:05.000Z","comments":1,"photos":[],"link":"","_id":"ciiwjp2zb0012of6gz8qepc5y"},{"date":"2015-01-21T16:00:00.000Z","layout":"post","title":"构建高性能服务器 -- 指标篇","_content":"\n理想与现实\n============\n人们总是希望花最少的钱，办最多的事。对于服务器的构建也是如此，我们总是希望花最少的人力，最少的硬件设备条件，撑起最大的并发。当然理想总是那么的丰满，现实总是那么的骨感。虽说如此，但是我们不能没有理想，万一实现了呢？所以我们还是怀着敬畏的心，在构建高性能服务器的征途上奋力前行。\n\n----------\n\n性能指标 \n============\n\n服务器的性能指标很多，而且**相互之间还有着关联**。\n\n1 吞吐率    \n--------\n\n如何判定服务器的性能状况呢？通常我们采用吞吐率来量化这个指标。所谓吞吐率，就是单位时间内服务器处理的请求数。注意，吞吐率有时候还用于描述其他指标，如单位时间内的通信数据量等。\n\n当然，对于量化服务器性能这个指标，我们牢记，**吞吐率就是单位时间内服务器处理的请求数，单位是reqs/s，有时也作rps**，别无他意。\n\n2 CPU使用率，内存使用率，I/O Wait率  \n----------\n\n当然，服务器进程的CPU使用率，内存使用率，I/O Wait率也同样是评价服务器性能状况的重要指标。**当CPU使用率较低，即CPU未跑满时（这里均是在压测情况下），说明服务器的瓶颈不在CPU上。同样，当内存使用率不高时，则说明服务器的瓶颈不在内存不够上**。而至于I/O Wait率则不能简单的评价了。I/O Wait，它是指CPU空闲并且等待I/O操作完成的时间比例。但是，I/O Wait往往不能真实地代表I/O操作的情况或者工作量，它的设计出发点是用来衡量CPU性能的。假设有一任务需要花费10毫秒的I/O操作时间和10毫秒的CPU时间，那么I/O Wait率则为50%，这时并不意味着I/O操作的繁忙程度为50%。同样，I/O Wait为0%时，I/O操作也可能很繁忙。所以我们如果关心服务器的I/O情况的话，可以进行磁盘I/O测试或者查看网络I/O流量等。事实上，**从I/O Wait率上，我们可以猜测服务器进程是I/O密集型的还是CPU密集型的**。\n\n3 系统负载\n-----------\n在进程调度器维护的运行队列中，任何时刻至少存在一个进程，那就是正在运行的进程。而当运行队列中有不止一个进程的时候，就说明此时CPU比较忙碌，其他进程还在等待正在运行的进程释放CPU的执行权限。\n\n所以系统负载也是影响服务器性能的指标之一。**系统负载，即当然系统中等待CPU处理的进程数**，所以系统负载越高，服务器进程得到CPU时间片愈发困难，从而影响服务器性能的下降。\n\n4 进程上下文切换\n----------\n我们知道，操作系统中运行着不止一个进程，而进程数通常又是远远大于CPU核心数。所以进程不得不面对一个事实：**轮流使用CPU进行运算**。而当进程之间轮流占有CPU资源时，就会出现CPU上下文切换的过程，理所当然，这个过程不是免费的，也具有一定的开销。\n\n所以服务器进程上下文切换也会影响服务器的性能。**当服务器CPU上下文切换频繁时，切换上下文的消耗则不能忽视**。所以，适时查看服务器进程上下文切换频率也同样有助于构建高性能的服务器。\n\n5 系统调用数\n----------\n**进程有用户态和内核态两种运行模式**，进程可以在这两种运行模式之间切换。进程通常运行在用户态下，而进行需要对硬件外设进行操作时，如读取硬盘文件，发送网络数据等，进程就需要切换至内核态运行。\n\n**事实上这两种模式的切换对高级语言开发者来说是透明的，开发者只需要在需要的时候调用系统调用即可**。内核提供了一系列系统调用函数，如read(), send()等。所以**系统调用数从另一方面反应了用户态和内核态之间的切换数**。\n\n当然，用户态和内核态之间的切换也是需要开销的，所以构建高性能服务器的过程中，对系统调用数的统计亦不能忽视。\n\n----------\n\n如何测试\n===============\n\n1 吞吐率\n----------\n通常，我们关心的是服务器的最大吞吐率，即每秒最多能处理多少个请求，事实上就是平常我们所说的服务器压力测试。当然，压力测试工具有好多种，如[JMeter](http://en.wikipedia.org/wiki/Apache_JMeter)，[LoadRunner](http://en.wikipedia.org/wiki/HP_LoadRunner)等。当然，还有Apache附带的[ab](http://en.wikipedia.org/wiki/ApacheBench)工具。下面，我们以ab为例，简单测试下百度首页的情况。\n\n\tab -c10 -n100 www.baidu.com\n\n相应的结果如下（部分）：\n\n\tConcurrency Level:      10\n\tTime taken for tests:   9.031 seconds\n\tComplete requests:      100\n\tFailed requests:        97\n\t   (Connect: 0, Receive: 0, Length: 97, Exceptions: 0)\n\tTotal transferred:      8730133 bytes\n\tHTML transferred:       8645328 bytes\n\tRequests per second:    11.07 [#/sec] (mean)\n\tTime per request:       903.139 [ms] (mean)\n\tTime per request:       90.314 [ms] (mean, across all concurrent requests)\n\tTransfer rate:          943.99 [Kbytes/sec] received\n\n从上述测试中可以得到，我们对百度首页利用ab进行简单的压力测试（总共100次请求且并发数为10）总共花了9.031秒，那平均每个请求处理时间为90.314毫秒，但是由于并发数为10，所以每个用户的平均等待时间为903.139毫秒。当然，我们这里不评价百度首页的性能情况。\n\n2 CPU使用率，内存使用率，I/O Wait率\n----------\n我们查看服务器进程的CPU使用率，内存使用率，I/O Wait率可以直接使用linux的**top命令**，结果如下所示：\n\n\ttop - 21:47:41 up 50 min,  3 users,  load average: 0.01, 0.02, 0.05\n\tTasks: 379 total,   1 running, 378 sleeping,   0 stopped,   0 zombie\n\t%Cpu(s):  0.3 us,  0.3 sy,  0.0 ni, 99.3 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st\n\tKiB Mem:   2042180 total,  1025404 used,  1016776 free,    48868 buffers\n\tKiB Swap:   521212 total,        0 used,   521212 free.   501296 cached Mem\n\n\t  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND\n\t 2190 zhujief+  20   0 1171408  98036  63920 S   0.7  4.8   0:31.79 compiz\n\t  177 root      20   0       0      0      0 S   0.3  0.0   0:03.20 kworker/1:1\n\t 1436 root      20   0  319448  62368  22940 S   0.3  3.1   0:14.96 Xorg\n\n从top命令的结果中可以得到诸多有用的信息，如当前compiz进程的CPU使用率为0.7%，内存使用率为4.8%，具体使用为98036Kb物理内存。同样也可以看到I/O Wait率为0.0%，因为当前机器并没有跑任何I/O较为密集的程序。另外，iostat命令也可以查看I/O Wait情况。\n\n3 系统负载\n-----------\n通过**查看/proc/loadavg**文件内容，可以了解到当前运行队列的情况，即系统负载情况。运行如下命令:\n\n\tcat /proc/loadavg\n\n得到如下：\n\n\t0.00 0.01 0.05 1/512 5082\n\n即在过去1分钟，5分钟，15分钟内平均系统负载为0.00，0.01，0.05，即平均分别有0.00，0.01，0.05个进程正在等待。而1/512表示当前总共有512个进程，但是当前运行队列中只有1个进程。最右边的5082为最后创建的进程的进程ID。\n\n4 进程上下文切换\n----------\n利用[nmon](http://nmon.sourceforge.net/pmwiki.php)工具可以查看进程上下文切换情况。\n\n\tRunQueue \t\t1   \tLoad Average    CPU use since boot time              \n\tContextSwitch\t168.3 \t1 mins  0. 00   Uptime Days=  0 Hours= 1 Mins=59   \n\tForks \t\t\t0.0    \t5 mins  0.02    Idle   Days=  0 Hours= 3 Mins=53   \n\tInterrupts \t\t70.9   15 mins  0.05    Average CPU use=-95.54%           \n\n从上面的结果可以看到，当前系统上下文切换速度为168.3/s。\n\n\n5 系统调用数\n----------\n同样，在linux下我们可以利用相关工具查看进程的系统调用情况 -- [strace](http://linux.die.net/man/1/strace)。截取小段结果如下：\n\n\trecvmsg(5, 0x7fffe94c5540, 0)           = -1 EAGAIN (Resource temporarily unavailable)\n\trecvmsg(5, 0x7fffe94c5540, 0)           = -1 EAGAIN (Resource temporarily unavailable)\n\tpoll([{fd=5, events=POLLIN|POLLOUT}], 1, 4294967295) = 1 ([{fd=5, revents=POLLOUT}])\n\twritev(5, [{\"\\213\\n\\2\\0\\327`\\340\\0\", 8}, {NULL, 0}, {\"\", 0}], 3) = 8\n\n很明显，在截取的结果中，进程分别进行了recvmsg, poll, writev等系统调用，当然也就进行了用户态和内核态的切换。\n","source":"_posts/2015-01-22-0.md","raw":"---\ndate: 2015-01-22\nlayout: post\ntitle: 构建高性能服务器 -- 指标篇\npermalink: '/2015/01-22-0.html'\ncategories:\n- 服务器编程\ntags:\n- 性能\n---\n\n理想与现实\n============\n人们总是希望花最少的钱，办最多的事。对于服务器的构建也是如此，我们总是希望花最少的人力，最少的硬件设备条件，撑起最大的并发。当然理想总是那么的丰满，现实总是那么的骨感。虽说如此，但是我们不能没有理想，万一实现了呢？所以我们还是怀着敬畏的心，在构建高性能服务器的征途上奋力前行。\n\n----------\n\n性能指标 \n============\n\n服务器的性能指标很多，而且**相互之间还有着关联**。\n\n1 吞吐率    \n--------\n\n如何判定服务器的性能状况呢？通常我们采用吞吐率来量化这个指标。所谓吞吐率，就是单位时间内服务器处理的请求数。注意，吞吐率有时候还用于描述其他指标，如单位时间内的通信数据量等。\n\n当然，对于量化服务器性能这个指标，我们牢记，**吞吐率就是单位时间内服务器处理的请求数，单位是reqs/s，有时也作rps**，别无他意。\n\n2 CPU使用率，内存使用率，I/O Wait率  \n----------\n\n当然，服务器进程的CPU使用率，内存使用率，I/O Wait率也同样是评价服务器性能状况的重要指标。**当CPU使用率较低，即CPU未跑满时（这里均是在压测情况下），说明服务器的瓶颈不在CPU上。同样，当内存使用率不高时，则说明服务器的瓶颈不在内存不够上**。而至于I/O Wait率则不能简单的评价了。I/O Wait，它是指CPU空闲并且等待I/O操作完成的时间比例。但是，I/O Wait往往不能真实地代表I/O操作的情况或者工作量，它的设计出发点是用来衡量CPU性能的。假设有一任务需要花费10毫秒的I/O操作时间和10毫秒的CPU时间，那么I/O Wait率则为50%，这时并不意味着I/O操作的繁忙程度为50%。同样，I/O Wait为0%时，I/O操作也可能很繁忙。所以我们如果关心服务器的I/O情况的话，可以进行磁盘I/O测试或者查看网络I/O流量等。事实上，**从I/O Wait率上，我们可以猜测服务器进程是I/O密集型的还是CPU密集型的**。\n\n3 系统负载\n-----------\n在进程调度器维护的运行队列中，任何时刻至少存在一个进程，那就是正在运行的进程。而当运行队列中有不止一个进程的时候，就说明此时CPU比较忙碌，其他进程还在等待正在运行的进程释放CPU的执行权限。\n\n所以系统负载也是影响服务器性能的指标之一。**系统负载，即当然系统中等待CPU处理的进程数**，所以系统负载越高，服务器进程得到CPU时间片愈发困难，从而影响服务器性能的下降。\n\n4 进程上下文切换\n----------\n我们知道，操作系统中运行着不止一个进程，而进程数通常又是远远大于CPU核心数。所以进程不得不面对一个事实：**轮流使用CPU进行运算**。而当进程之间轮流占有CPU资源时，就会出现CPU上下文切换的过程，理所当然，这个过程不是免费的，也具有一定的开销。\n\n所以服务器进程上下文切换也会影响服务器的性能。**当服务器CPU上下文切换频繁时，切换上下文的消耗则不能忽视**。所以，适时查看服务器进程上下文切换频率也同样有助于构建高性能的服务器。\n\n5 系统调用数\n----------\n**进程有用户态和内核态两种运行模式**，进程可以在这两种运行模式之间切换。进程通常运行在用户态下，而进行需要对硬件外设进行操作时，如读取硬盘文件，发送网络数据等，进程就需要切换至内核态运行。\n\n**事实上这两种模式的切换对高级语言开发者来说是透明的，开发者只需要在需要的时候调用系统调用即可**。内核提供了一系列系统调用函数，如read(), send()等。所以**系统调用数从另一方面反应了用户态和内核态之间的切换数**。\n\n当然，用户态和内核态之间的切换也是需要开销的，所以构建高性能服务器的过程中，对系统调用数的统计亦不能忽视。\n\n----------\n\n如何测试\n===============\n\n1 吞吐率\n----------\n通常，我们关心的是服务器的最大吞吐率，即每秒最多能处理多少个请求，事实上就是平常我们所说的服务器压力测试。当然，压力测试工具有好多种，如[JMeter](http://en.wikipedia.org/wiki/Apache_JMeter)，[LoadRunner](http://en.wikipedia.org/wiki/HP_LoadRunner)等。当然，还有Apache附带的[ab](http://en.wikipedia.org/wiki/ApacheBench)工具。下面，我们以ab为例，简单测试下百度首页的情况。\n\n\tab -c10 -n100 www.baidu.com\n\n相应的结果如下（部分）：\n\n\tConcurrency Level:      10\n\tTime taken for tests:   9.031 seconds\n\tComplete requests:      100\n\tFailed requests:        97\n\t   (Connect: 0, Receive: 0, Length: 97, Exceptions: 0)\n\tTotal transferred:      8730133 bytes\n\tHTML transferred:       8645328 bytes\n\tRequests per second:    11.07 [#/sec] (mean)\n\tTime per request:       903.139 [ms] (mean)\n\tTime per request:       90.314 [ms] (mean, across all concurrent requests)\n\tTransfer rate:          943.99 [Kbytes/sec] received\n\n从上述测试中可以得到，我们对百度首页利用ab进行简单的压力测试（总共100次请求且并发数为10）总共花了9.031秒，那平均每个请求处理时间为90.314毫秒，但是由于并发数为10，所以每个用户的平均等待时间为903.139毫秒。当然，我们这里不评价百度首页的性能情况。\n\n2 CPU使用率，内存使用率，I/O Wait率\n----------\n我们查看服务器进程的CPU使用率，内存使用率，I/O Wait率可以直接使用linux的**top命令**，结果如下所示：\n\n\ttop - 21:47:41 up 50 min,  3 users,  load average: 0.01, 0.02, 0.05\n\tTasks: 379 total,   1 running, 378 sleeping,   0 stopped,   0 zombie\n\t%Cpu(s):  0.3 us,  0.3 sy,  0.0 ni, 99.3 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st\n\tKiB Mem:   2042180 total,  1025404 used,  1016776 free,    48868 buffers\n\tKiB Swap:   521212 total,        0 used,   521212 free.   501296 cached Mem\n\n\t  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND\n\t 2190 zhujief+  20   0 1171408  98036  63920 S   0.7  4.8   0:31.79 compiz\n\t  177 root      20   0       0      0      0 S   0.3  0.0   0:03.20 kworker/1:1\n\t 1436 root      20   0  319448  62368  22940 S   0.3  3.1   0:14.96 Xorg\n\n从top命令的结果中可以得到诸多有用的信息，如当前compiz进程的CPU使用率为0.7%，内存使用率为4.8%，具体使用为98036Kb物理内存。同样也可以看到I/O Wait率为0.0%，因为当前机器并没有跑任何I/O较为密集的程序。另外，iostat命令也可以查看I/O Wait情况。\n\n3 系统负载\n-----------\n通过**查看/proc/loadavg**文件内容，可以了解到当前运行队列的情况，即系统负载情况。运行如下命令:\n\n\tcat /proc/loadavg\n\n得到如下：\n\n\t0.00 0.01 0.05 1/512 5082\n\n即在过去1分钟，5分钟，15分钟内平均系统负载为0.00，0.01，0.05，即平均分别有0.00，0.01，0.05个进程正在等待。而1/512表示当前总共有512个进程，但是当前运行队列中只有1个进程。最右边的5082为最后创建的进程的进程ID。\n\n4 进程上下文切换\n----------\n利用[nmon](http://nmon.sourceforge.net/pmwiki.php)工具可以查看进程上下文切换情况。\n\n\tRunQueue \t\t1   \tLoad Average    CPU use since boot time              \n\tContextSwitch\t168.3 \t1 mins  0. 00   Uptime Days=  0 Hours= 1 Mins=59   \n\tForks \t\t\t0.0    \t5 mins  0.02    Idle   Days=  0 Hours= 3 Mins=53   \n\tInterrupts \t\t70.9   15 mins  0.05    Average CPU use=-95.54%           \n\n从上面的结果可以看到，当前系统上下文切换速度为168.3/s。\n\n\n5 系统调用数\n----------\n同样，在linux下我们可以利用相关工具查看进程的系统调用情况 -- [strace](http://linux.die.net/man/1/strace)。截取小段结果如下：\n\n\trecvmsg(5, 0x7fffe94c5540, 0)           = -1 EAGAIN (Resource temporarily unavailable)\n\trecvmsg(5, 0x7fffe94c5540, 0)           = -1 EAGAIN (Resource temporarily unavailable)\n\tpoll([{fd=5, events=POLLIN|POLLOUT}], 1, 4294967295) = 1 ([{fd=5, revents=POLLOUT}])\n\twritev(5, [{\"\\213\\n\\2\\0\\327`\\340\\0\", 8}, {NULL, 0}, {\"\", 0}], 3) = 8\n\n很明显，在截取的结果中，进程分别进行了recvmsg, poll, writev等系统调用，当然也就进行了用户态和内核态的切换。\n","slug":"/2015/01-22-0.html","published":1,"updated":"2015-06-19T16:09:05.000Z","comments":1,"photos":[],"link":"","_id":"ciiwjp2zd0015of6geqmjlgcl"},{"date":"2014-12-27T16:00:00.000Z","layout":"post","title":"经典算法巡礼(七) -- 排序之堆排序","_content":"\n一、优先队列\n-----------\n很多时候，我们需要处理有序的元素，但不一定要求它们全部有序，或是不一定要一次就将它们排序。比如你可能启动了若干个定时器，那么下一次处理定时器事件只需要考虑距离现在时间最近的定时器即可，定时器触发时间无须全部有序，只需要处理优化级最高的定时器即可。\n\n这种情况下，一个合适的数据结构应该支持两种操作：**删除最小元素**和**插入元素**。而且这两种操作的效率应该在可接受范围之内。这种数据类型叫[**优先队列**](http://zh.wikipedia.org/wiki/%E5%84%AA%E5%85%88%E4%BD%87%E5%88%97)。\n\n二、堆的定义\n-----------\n[**二叉堆**](http://zh.wikipedia.org/zh/%E4%BA%8C%E5%8F%89%E5%A0%86)能够很好的实现**优先队列**的基本操作。在二叉堆中，每个元素都要保证大于等于它的孩子结点。相应的，这些孩子结点同样要大于等于它们的孩子结点，以此类推。当然，这样的二叉堆又称**最大堆**。与最大堆类似，若每个元素均小于等于它的孩子结点，则称**最小堆**。之前提到的定时器触发问题，它所适合的数据结构应该为最小堆。\n\n三、二叉堆表示法\n-----------\n二叉堆是[完全二叉树](http://zh.wikipedia.org/zh/%E4%BA%8C%E5%8F%89%E6%A0%91)，因此可以只用数组来表示二叉堆。具体方法是将二叉树的结点按照层级顺序放入数组中，根结点放在位置1，它的子结点放在位置2和3，而子结点的子结点则放在位置4，5，6，7，以此类推。而事实上，很容易就可以在数组中表示二叉树，即位置k的结点，它的子结点在数组中的位置则为2k和2k+1。\n\n四、堆的操作\n------------\n在堆的有序化过程中，我们会碰到以下两种情况：\n\n* 当某个结点的优先级上升(或者在堆底中加入一个新的元素)时，我们需要**由下至上**恢复堆的有序性；\n* 当某个结点的优先级下降(比如根结点被替换为一个新的元素)时，我们需要**由上至下**恢复堆的有序列性。\n\n为了解决以上两个问题，就有了下面将要描述的**上浮(swin)**和**下沉(sink)**操作。\n\n**由下至上的有序化（上浮）**\n\n由于某结点的变化，造成了该结点比它的父结点更大（最大堆情况），从而影响了堆的有序性。比如堆中有新的元素加入堆底，而该新加入元素又比它的父结点更大，则需要将其与它的父结点交换位置，从而恢复它及其父结点的有序性。当然，这个过程会不停重复，直至堆中元素全部有序为止。整个过程就是之前所说的由下至上的上浮过程。具体[golang](https://golang.org/)可参考如下：\n\n\tfunc (this *HeapPQ) swim(idx int) {\n\t\tfor idx > 1 && this.less(idx/2, idx) == true {\n\t\t\tthis.exch(idx/2, idx)\n\t\t\tidx /= 2\n\t\t}\n\t}\n\n**由上至下的有序化（下沉）**  \n\n由于某结点的变化，造成了该结点比它的子结点更小（最大堆情况），从而影响了堆的有序性。比如删除堆中根结点的元素，并原先在堆底的元素放置于根结点位置。事实上这就是最大堆中取最大元素的操作。当然，为了保持堆的有序性，则对新的根结点进行下沉操作，若根结点比它的子结点中的任意一个小，则将根结点与此结点交换，同时将该子结点进行重复操作，直到堆恢复有序性为止。整个过程就是之前的说的由上至下的下沉过程。具体[golang](https://golang.org/)可参考如下：\n\n\tfunc (this *HeapPQ) sink(idx int) {\n\t\tfor 2*idx <= this.Size() {\n\t\t\tchild := 2 * idx\n\t\t\tif child < this.Size() && this.less(child, child+1) == true {\n\t\t\t\tchild++\n\t\t\t}\n\t\t\tif this.less(idx, child) != true {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\tthis.exch(idx, child)\n\t\t\tidx = child\n\t\t}\n\t}\n\n五、堆排序\n------------\n堆排序可以分为两个阶段：\n\n* **堆的构造阶段**\n* **下沉排序阶段**\n\n构造一个堆，可以用以下两种方法进行。第一种，从左至右遍历数组，用swin()保证扫描指针左侧的所有元素已经是一棵堆有序的完全树即可。第二种，事实上是更聪明更高效的方法。就是**从右至左用sink()函数构造子堆**。开始时我们只需要扫描数组中的一半元素，所以是更高效的方法。\n\n第二个阶段，即下沉排序阶段，我们可以将堆中最大元素删除，然后放入堆缩小后数组空出的位置。\n\n整个过程用代码表述如下：\n\n\tfunc (this *HeapSort) sink(a []Comparable, i int, j int, compare Compare) {\n\t\tb := a[i:j]\n\t\tb = append(make([]Comparable, 1), b...)\n\t\tsize := len(b) - 1\n\n\t\tfunc(idx int) {\n\t\t\tfor 2*idx <= size {\n\t\t\t\tchild := 2 * idx\n\t\t\t\t// fmt.Println(idx, child, size)\n\t\t\t\tif child < size && compare(b[child], b[child+1]) < 0 {\n\t\t\t\t\tchild++\n\t\t\t\t}\n\t\t\t\tif compare(b[idx], b[child]) < 0 {\n\t\t\t\t\tthis.exch(b, idx, child)\n\t\t\t\t\tidx = child\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tbreak\n\t\t\t}\n\t\t}(1)\n\n\t\tcopy(a[i:j], b[1:])\n\t}\n\n\t// Sort中参数类型Comparable为统一的可比较接口，若为整数数组排序，则Comparable为int即可\n\t// Sort中参数类型Compare为配合Comparable接口的比较方法，若为整数数组排序，则Compare即满足a int < a int即可\n\tfunc (this *HeapSort) Sort(a []Comparable, compare Compare) {\n\t\tn := len(a)\n\n\t\t// 堆构造\n\t\tfor i := n / 2; i >= 0; i-- {\n\t\t\tthis.sink(a, i, n, compare)\n\t\t}\n\n\t\t// 堆排序的下沉阶段\n\t\tfor i := n - 1; i > 1; {\n\t\t\tthis.exch(a, 0, i)\n\t\t\ti--\n\t\t\tthis.sink(a, 0, i, compare)\n\t\t}\n\t}\n\n至于堆排序的效率，在sink()函数中，比较操作最多进行2logN次，所以排序整个数组最多需要N*2logN次比较操作，因此**堆排序的时间复杂度为O(NlogN)**，所以可以用于大规模数据的排序。\n\n**堆排序是能够同时最优地利用空间和时间的方法，即使在最坏的情况下，它也能保证使用~2NlogN次比较和恒定的额外空间**。但现代系统的许多应用很少使用它，因为**堆排序无法有效利用缓存**。数组元素很少和相邻的其他元素进行比较，因此缓存未命中的次数要远远高于大多数比较都在相邻元素间进行的算法，如快速排序，归并排序，甚至是希尔排序（希尔排序算是没有多少相信元素间的比较的算法了）。\n\n但是，**用堆实现优先队列在现代应用程序中却起着重要的作用，因为它能在插入操作和删除最大元素操作保证对数级别的运行时间（logN）**。\n\n\n\n\n\n\n\n\n\n\n\n\n","source":"_posts/2014-12-28-2.md","raw":"---\ndate: 2014-12-28\nlayout: post\ntitle: 经典算法巡礼(七) -- 排序之堆排序\npermalink: '/2014/12-28-2.html'\ncategories:\n- 算法\ntags:\n- 排序\n---\n\n一、优先队列\n-----------\n很多时候，我们需要处理有序的元素，但不一定要求它们全部有序，或是不一定要一次就将它们排序。比如你可能启动了若干个定时器，那么下一次处理定时器事件只需要考虑距离现在时间最近的定时器即可，定时器触发时间无须全部有序，只需要处理优化级最高的定时器即可。\n\n这种情况下，一个合适的数据结构应该支持两种操作：**删除最小元素**和**插入元素**。而且这两种操作的效率应该在可接受范围之内。这种数据类型叫[**优先队列**](http://zh.wikipedia.org/wiki/%E5%84%AA%E5%85%88%E4%BD%87%E5%88%97)。\n\n二、堆的定义\n-----------\n[**二叉堆**](http://zh.wikipedia.org/zh/%E4%BA%8C%E5%8F%89%E5%A0%86)能够很好的实现**优先队列**的基本操作。在二叉堆中，每个元素都要保证大于等于它的孩子结点。相应的，这些孩子结点同样要大于等于它们的孩子结点，以此类推。当然，这样的二叉堆又称**最大堆**。与最大堆类似，若每个元素均小于等于它的孩子结点，则称**最小堆**。之前提到的定时器触发问题，它所适合的数据结构应该为最小堆。\n\n三、二叉堆表示法\n-----------\n二叉堆是[完全二叉树](http://zh.wikipedia.org/zh/%E4%BA%8C%E5%8F%89%E6%A0%91)，因此可以只用数组来表示二叉堆。具体方法是将二叉树的结点按照层级顺序放入数组中，根结点放在位置1，它的子结点放在位置2和3，而子结点的子结点则放在位置4，5，6，7，以此类推。而事实上，很容易就可以在数组中表示二叉树，即位置k的结点，它的子结点在数组中的位置则为2k和2k+1。\n\n四、堆的操作\n------------\n在堆的有序化过程中，我们会碰到以下两种情况：\n\n* 当某个结点的优先级上升(或者在堆底中加入一个新的元素)时，我们需要**由下至上**恢复堆的有序性；\n* 当某个结点的优先级下降(比如根结点被替换为一个新的元素)时，我们需要**由上至下**恢复堆的有序列性。\n\n为了解决以上两个问题，就有了下面将要描述的**上浮(swin)**和**下沉(sink)**操作。\n\n**由下至上的有序化（上浮）**\n\n由于某结点的变化，造成了该结点比它的父结点更大（最大堆情况），从而影响了堆的有序性。比如堆中有新的元素加入堆底，而该新加入元素又比它的父结点更大，则需要将其与它的父结点交换位置，从而恢复它及其父结点的有序性。当然，这个过程会不停重复，直至堆中元素全部有序为止。整个过程就是之前所说的由下至上的上浮过程。具体[golang](https://golang.org/)可参考如下：\n\n\tfunc (this *HeapPQ) swim(idx int) {\n\t\tfor idx > 1 && this.less(idx/2, idx) == true {\n\t\t\tthis.exch(idx/2, idx)\n\t\t\tidx /= 2\n\t\t}\n\t}\n\n**由上至下的有序化（下沉）**  \n\n由于某结点的变化，造成了该结点比它的子结点更小（最大堆情况），从而影响了堆的有序性。比如删除堆中根结点的元素，并原先在堆底的元素放置于根结点位置。事实上这就是最大堆中取最大元素的操作。当然，为了保持堆的有序性，则对新的根结点进行下沉操作，若根结点比它的子结点中的任意一个小，则将根结点与此结点交换，同时将该子结点进行重复操作，直到堆恢复有序性为止。整个过程就是之前的说的由上至下的下沉过程。具体[golang](https://golang.org/)可参考如下：\n\n\tfunc (this *HeapPQ) sink(idx int) {\n\t\tfor 2*idx <= this.Size() {\n\t\t\tchild := 2 * idx\n\t\t\tif child < this.Size() && this.less(child, child+1) == true {\n\t\t\t\tchild++\n\t\t\t}\n\t\t\tif this.less(idx, child) != true {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\tthis.exch(idx, child)\n\t\t\tidx = child\n\t\t}\n\t}\n\n五、堆排序\n------------\n堆排序可以分为两个阶段：\n\n* **堆的构造阶段**\n* **下沉排序阶段**\n\n构造一个堆，可以用以下两种方法进行。第一种，从左至右遍历数组，用swin()保证扫描指针左侧的所有元素已经是一棵堆有序的完全树即可。第二种，事实上是更聪明更高效的方法。就是**从右至左用sink()函数构造子堆**。开始时我们只需要扫描数组中的一半元素，所以是更高效的方法。\n\n第二个阶段，即下沉排序阶段，我们可以将堆中最大元素删除，然后放入堆缩小后数组空出的位置。\n\n整个过程用代码表述如下：\n\n\tfunc (this *HeapSort) sink(a []Comparable, i int, j int, compare Compare) {\n\t\tb := a[i:j]\n\t\tb = append(make([]Comparable, 1), b...)\n\t\tsize := len(b) - 1\n\n\t\tfunc(idx int) {\n\t\t\tfor 2*idx <= size {\n\t\t\t\tchild := 2 * idx\n\t\t\t\t// fmt.Println(idx, child, size)\n\t\t\t\tif child < size && compare(b[child], b[child+1]) < 0 {\n\t\t\t\t\tchild++\n\t\t\t\t}\n\t\t\t\tif compare(b[idx], b[child]) < 0 {\n\t\t\t\t\tthis.exch(b, idx, child)\n\t\t\t\t\tidx = child\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tbreak\n\t\t\t}\n\t\t}(1)\n\n\t\tcopy(a[i:j], b[1:])\n\t}\n\n\t// Sort中参数类型Comparable为统一的可比较接口，若为整数数组排序，则Comparable为int即可\n\t// Sort中参数类型Compare为配合Comparable接口的比较方法，若为整数数组排序，则Compare即满足a int < a int即可\n\tfunc (this *HeapSort) Sort(a []Comparable, compare Compare) {\n\t\tn := len(a)\n\n\t\t// 堆构造\n\t\tfor i := n / 2; i >= 0; i-- {\n\t\t\tthis.sink(a, i, n, compare)\n\t\t}\n\n\t\t// 堆排序的下沉阶段\n\t\tfor i := n - 1; i > 1; {\n\t\t\tthis.exch(a, 0, i)\n\t\t\ti--\n\t\t\tthis.sink(a, 0, i, compare)\n\t\t}\n\t}\n\n至于堆排序的效率，在sink()函数中，比较操作最多进行2logN次，所以排序整个数组最多需要N*2logN次比较操作，因此**堆排序的时间复杂度为O(NlogN)**，所以可以用于大规模数据的排序。\n\n**堆排序是能够同时最优地利用空间和时间的方法，即使在最坏的情况下，它也能保证使用~2NlogN次比较和恒定的额外空间**。但现代系统的许多应用很少使用它，因为**堆排序无法有效利用缓存**。数组元素很少和相邻的其他元素进行比较，因此缓存未命中的次数要远远高于大多数比较都在相邻元素间进行的算法，如快速排序，归并排序，甚至是希尔排序（希尔排序算是没有多少相信元素间的比较的算法了）。\n\n但是，**用堆实现优先队列在现代应用程序中却起着重要的作用，因为它能在插入操作和删除最大元素操作保证对数级别的运行时间（logN）**。\n\n\n\n\n\n\n\n\n\n\n\n\n","slug":"/2014/12-28-2.html","published":1,"updated":"2015-06-19T16:09:05.000Z","comments":1,"photos":[],"link":"","_id":"ciiwjp2zf0018of6g4za5lknw"},{"date":"2014-12-27T16:00:00.000Z","layout":"post","title":"经典算法巡礼(六) -- 排序之快速排序","_content":"\n[快速排序](http://zh.wikipedia.org/wiki/%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F)正如她的名字，她是一种排序效率相当高的算法，而且**可能是应用最广泛**的排序算法了。快速排序流行的原因是她**实现简单，适用于各种不同的输入数据且在一般应用中比其他排序算法都要快**。不仅如此，她与[归并排序](http://codingforever.cn/2014/12-28-0.html)不同，她**只需要很小的辅助空间就可以进行排序**。\n\n快速排序也是[**分治思想**](http://en.wikipedia.org/wiki/Divide_and_conquer_algorithms)的典型应用。她与[归并排序](http://codingforever.cn/2014/12-28-0.html)是互补的：归并排序将数组分成两个子数组分别排序，并将有序的子数组归并以将整个数组排序；而快速排序而是当两个子数组都有序时，整个数组也就自己有序了。前者的递归调用发生在处理整个数组之前，而后者的递归调用发生在处理整个之后。\n\n快速排序最主要的操作就是patition，即**切分操作**。选择数组中一元素，以该元素做为基准切分元素，姑且将其称为P，切分后使P之前的所有元素都小于P(排序成递增序列)，P之后的所有元素都大于P。然后对P切分成的两个子数组分别再一次进行切分操作。重复此过程直到不能切分为止，即整个数组排序完成。\n\n那么如何选择这个切分基准元素P呢？通常是随机取数组中任意值，所以快速排序的效率是和概率相关的，但实际使用过程中排序效率还是非常可观的。具体[golang](https://golang.org/)实现如下： \n\n\t// partition方法即为快速排序中重要的切分操作，以首元素做为基准，将剩余元素从两端寻找，分别找到大于（小于）基准的元素并交换，重复此过程直到剩余元素全部遍历为止\n\tfunc (this *QuickSort) partition(a []Comparable, compare Compare, lo int, hi int) int {\n\t\ti := lo + 1\n\t\tj := hi\n\t\tv := a[lo]\n\t\tfor true {\n\t\t\tfor this.less(a[i], v, compare) == true {\n\t\t\t\tif i == hi {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t\ti++\n\t\t\t}\n\t\t\tfor this.less(a[j], v, compare) == false {\n\t\t\t\tif j == lo {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t\tj--\n\t\t\t}\n\t\t\tif i >= j {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\tthis.exch(a, i, j)\n\t\t\ti++\n\t\t\tj--\n\t\t}\n\t\tthis.exch(a, lo, j)\n\n\t\treturn j\n\t}\n\n\t// Sort中参数类型Comparable为统一的可比较接口，若为整数数组排序，则Comparable为int即可\n\t// Sort中参数类型Compare为配合Comparable接口的比较方法，若为整数数组排序，则Compare即满足a int < a int即可\n\tfunc (this *QuickSort) Sort(a []Comparable, compare Compare, lo int, hi int) {\n\t\tif hi <= lo {\n\t\t\treturn\n\t\t}\n\n\t\tp := this.partition(a, compare, lo, hi)\n\t\tthis.Sort(a, compare, lo, p-1)\n\t\tthis.Sort(a, compare, p+1, hi)\n\t}\n\n上述实现过程在切分操作时，只是简单取数组第一个元素做为切分基准元素。如此做法，**排序效率则与输入序列相关了，因此可以在排序之前shuffee数组，如此一来就与概率相关了**。\n\n分析快速排序的过程，可以得到每次patition时，需要N-1次比较操作（数组元素为N的情况下），同时又可得到此patition过程需要进行logN次。因此，整个快速排序需要**(N-1)logN ~ NlogN**次比较操作，也就是说其**时间复杂度为O(NlogN)**。因此，她也是**可以应用于大规模数组的排序，而且也不需要[归并排序](http://codingforever.cn/2014/12-28-0.html)大量的额外空间，同时也没有[希尔排序](http://codingforever.cn/2014/12-27-3.html)的不确定性**。\n\n当然，其实快速排序有一种方便的改进，即可在对有大量相同元素的数组排序时，效率大大提高。她是由[Dijkstra](http://en.wikipedia.org/wiki/Edsger_W._Dijkstra)提出的“**三向切分的快速排序**“。具体实现如下：\n\n\t// Sort方法采用”三向切分的快速排序“法进行排序\n\tfunc (this *QuickSort) Sort(a []Comparable, compare Compare, lo int, hi int) {\n\t\tif hi <= lo {\n\t\t\treturn\n\t\t}\n\n\t\tlt := lo\n\t\ti := lo + 1\n\t\tgt := hi\n\n\t\tv := a[lo]\n\t\tfor i <= gt {\n\t\t\tcmp := compare(v, a[i])\n\t\t\tif cmp < 0 {\n\t\t\t\tthis.exch(a, i, gt)\n\t\t\t\tgt--\n\t\t\t} else if cmp > 0 {\n\t\t\t\tthis.exch(a, i, lt)\n\t\t\t\ti++\n\t\t\t\tlt++\n\t\t\t} else {\n\t\t\t\ti++\n\t\t\t}\n\t\t}\n\t\tthis.Sort(a, compare, lo, lt-1)\n\t\tthis.Sort(a, compare, gt+1, hi)\n\t}\n\n\"三向切分的快速排序\"中的切分方法过程如下：  \n\n她遍历数组一次，维护一个指针lt使得a[lo..lt-1]中的元素都小于v(即切分基准元素)，一个指针gt使得a[gt+1..hi]中的元素都大于v，一个指针i使得a[lt..i-1]全部等于v，而a[i..gt]中的元素都还未确定。正如上述代码中所示，等遍历完数组后，数组就分为三部分，a[lo..lt-1]为小于v的部分，a[gt+1..hi]为大于v的部分，而a[lt..gt]则为等于v的部分。然后，对不等于v的部分数组再次切分递归，直到不能切分为止。  \n\n而**如果数组中有大量相同元素时，采用”三向切分“方法就不会对相同部分再次进行重复比较，大大提高排序性能。而当没有重复元素时，”三向切分“方法又等同时原始快速排序**。因此，”三向切分的快速排序“通常被用于实际场合中进行快速排序。\n\n\n\n\n\n","source":"_posts/2014-12-28-1.md","raw":"---\ndate: 2014-12-28\nlayout: post\ntitle: 经典算法巡礼(六) -- 排序之快速排序\npermalink: '/2014/12-28-1.html'\ncategories:\n- 算法\ntags:\n- 排序\n---\n\n[快速排序](http://zh.wikipedia.org/wiki/%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F)正如她的名字，她是一种排序效率相当高的算法，而且**可能是应用最广泛**的排序算法了。快速排序流行的原因是她**实现简单，适用于各种不同的输入数据且在一般应用中比其他排序算法都要快**。不仅如此，她与[归并排序](http://codingforever.cn/2014/12-28-0.html)不同，她**只需要很小的辅助空间就可以进行排序**。\n\n快速排序也是[**分治思想**](http://en.wikipedia.org/wiki/Divide_and_conquer_algorithms)的典型应用。她与[归并排序](http://codingforever.cn/2014/12-28-0.html)是互补的：归并排序将数组分成两个子数组分别排序，并将有序的子数组归并以将整个数组排序；而快速排序而是当两个子数组都有序时，整个数组也就自己有序了。前者的递归调用发生在处理整个数组之前，而后者的递归调用发生在处理整个之后。\n\n快速排序最主要的操作就是patition，即**切分操作**。选择数组中一元素，以该元素做为基准切分元素，姑且将其称为P，切分后使P之前的所有元素都小于P(排序成递增序列)，P之后的所有元素都大于P。然后对P切分成的两个子数组分别再一次进行切分操作。重复此过程直到不能切分为止，即整个数组排序完成。\n\n那么如何选择这个切分基准元素P呢？通常是随机取数组中任意值，所以快速排序的效率是和概率相关的，但实际使用过程中排序效率还是非常可观的。具体[golang](https://golang.org/)实现如下： \n\n\t// partition方法即为快速排序中重要的切分操作，以首元素做为基准，将剩余元素从两端寻找，分别找到大于（小于）基准的元素并交换，重复此过程直到剩余元素全部遍历为止\n\tfunc (this *QuickSort) partition(a []Comparable, compare Compare, lo int, hi int) int {\n\t\ti := lo + 1\n\t\tj := hi\n\t\tv := a[lo]\n\t\tfor true {\n\t\t\tfor this.less(a[i], v, compare) == true {\n\t\t\t\tif i == hi {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t\ti++\n\t\t\t}\n\t\t\tfor this.less(a[j], v, compare) == false {\n\t\t\t\tif j == lo {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t\tj--\n\t\t\t}\n\t\t\tif i >= j {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\tthis.exch(a, i, j)\n\t\t\ti++\n\t\t\tj--\n\t\t}\n\t\tthis.exch(a, lo, j)\n\n\t\treturn j\n\t}\n\n\t// Sort中参数类型Comparable为统一的可比较接口，若为整数数组排序，则Comparable为int即可\n\t// Sort中参数类型Compare为配合Comparable接口的比较方法，若为整数数组排序，则Compare即满足a int < a int即可\n\tfunc (this *QuickSort) Sort(a []Comparable, compare Compare, lo int, hi int) {\n\t\tif hi <= lo {\n\t\t\treturn\n\t\t}\n\n\t\tp := this.partition(a, compare, lo, hi)\n\t\tthis.Sort(a, compare, lo, p-1)\n\t\tthis.Sort(a, compare, p+1, hi)\n\t}\n\n上述实现过程在切分操作时，只是简单取数组第一个元素做为切分基准元素。如此做法，**排序效率则与输入序列相关了，因此可以在排序之前shuffee数组，如此一来就与概率相关了**。\n\n分析快速排序的过程，可以得到每次patition时，需要N-1次比较操作（数组元素为N的情况下），同时又可得到此patition过程需要进行logN次。因此，整个快速排序需要**(N-1)logN ~ NlogN**次比较操作，也就是说其**时间复杂度为O(NlogN)**。因此，她也是**可以应用于大规模数组的排序，而且也不需要[归并排序](http://codingforever.cn/2014/12-28-0.html)大量的额外空间，同时也没有[希尔排序](http://codingforever.cn/2014/12-27-3.html)的不确定性**。\n\n当然，其实快速排序有一种方便的改进，即可在对有大量相同元素的数组排序时，效率大大提高。她是由[Dijkstra](http://en.wikipedia.org/wiki/Edsger_W._Dijkstra)提出的“**三向切分的快速排序**“。具体实现如下：\n\n\t// Sort方法采用”三向切分的快速排序“法进行排序\n\tfunc (this *QuickSort) Sort(a []Comparable, compare Compare, lo int, hi int) {\n\t\tif hi <= lo {\n\t\t\treturn\n\t\t}\n\n\t\tlt := lo\n\t\ti := lo + 1\n\t\tgt := hi\n\n\t\tv := a[lo]\n\t\tfor i <= gt {\n\t\t\tcmp := compare(v, a[i])\n\t\t\tif cmp < 0 {\n\t\t\t\tthis.exch(a, i, gt)\n\t\t\t\tgt--\n\t\t\t} else if cmp > 0 {\n\t\t\t\tthis.exch(a, i, lt)\n\t\t\t\ti++\n\t\t\t\tlt++\n\t\t\t} else {\n\t\t\t\ti++\n\t\t\t}\n\t\t}\n\t\tthis.Sort(a, compare, lo, lt-1)\n\t\tthis.Sort(a, compare, gt+1, hi)\n\t}\n\n\"三向切分的快速排序\"中的切分方法过程如下：  \n\n她遍历数组一次，维护一个指针lt使得a[lo..lt-1]中的元素都小于v(即切分基准元素)，一个指针gt使得a[gt+1..hi]中的元素都大于v，一个指针i使得a[lt..i-1]全部等于v，而a[i..gt]中的元素都还未确定。正如上述代码中所示，等遍历完数组后，数组就分为三部分，a[lo..lt-1]为小于v的部分，a[gt+1..hi]为大于v的部分，而a[lt..gt]则为等于v的部分。然后，对不等于v的部分数组再次切分递归，直到不能切分为止。  \n\n而**如果数组中有大量相同元素时，采用”三向切分“方法就不会对相同部分再次进行重复比较，大大提高排序性能。而当没有重复元素时，”三向切分“方法又等同时原始快速排序**。因此，”三向切分的快速排序“通常被用于实际场合中进行快速排序。\n\n\n\n\n\n","slug":"/2014/12-28-1.html","published":1,"updated":"2015-06-19T16:09:05.000Z","comments":1,"photos":[],"link":"","_id":"ciiwjp2zi001cof6gmt6bdhx1"},{"date":"2014-12-27T16:00:00.000Z","layout":"post","title":"经典算法巡礼(五) -- 排序之归并排序","_content":"\n\n[归并排序](http://en.wikipedia.org/wiki/Merge_sort)是创建在**归并操作**上的一种有效排序算法。**所谓归并操作，指的是将两个已经排序的序列合并成一个序列的操作**。归并排序是[**分治思想**](http://en.wikipedia.org/wiki/Divide_and_conquer_algorithms)的典型示范。\n\n归并排序具体步骤如下：\n\n1. 申请大小等于两个已排序序列之和的空间，该空间用来存放合并后的序列；\n2. 设定两个指针，初始位置分别为两个已排序序列的起始位置；\n3. 比较两个指针所指向的元素，选择较小的元素放入合并的空间中（若进行升序排序），并移动指针到下一个位置；\n4. 重复步骤3直至其中某一指针到达序列尾；\n5. 将另一序列剩下的元素直接复制到合并序列中。\n\n用[golang](https://golang.org/)实现如下： \n\n\t// merge方法实现归并排序中的归并操作，将两个已排序数组归并操作成一个已排序数组\n\tfunc (this *MergeSort) merge(a []Comparable, compare Compare, lo int, mid int, hi int) {\n\t\ti := lo\n\t\tj := mid + 1\n\n\t\tarrayBak := make([]Comparable, len(a))\n\t\tcopy(arrayBak, a)\n\n\t\tfor k := lo; k <= hi; k++ {\n\t\t\tif i > mid {\n\t\t\t\ta[k] = arrayBak[j]\n\t\t\t\tj++\n\t\t\t} else if j > hi {\n\t\t\t\ta[k] = arrayBak[i]\n\t\t\t\ti++\n\t\t\t} else if this.less(arrayBak[i], arrayBak[j], compare) {\n\t\t\t\ta[k] = arrayBak[i]\n\t\t\t\ti++\n\t\t\t} else {\n\t\t\t\ta[k] = arrayBak[j]\n\t\t\t\tj++\n\t\t\t}\n\t\t}\n\t}\n\n\t// Sort1采用自顶向下方法进行归并排序\n\t// Sort中参数类型Comparable为统一的可比较接口，若为整数数组排序，则Comparable为int即可\n\t// Sort中参数类型Compare为配合Comparable接口的比较方法，若为整数数组排序，则Compare即满足a int < a int即可\n\tfunc (this *MergeSort) sort1(a []Comparable, compare Compare, lo int, hi int) {\n\t\tif lo >= hi {\n\t\t\treturn\n\t\t}\n\n\t\tmid := (lo + hi) / 2\n\n\t\tthis.sort1(a, compare, lo, mid)\n\t\tthis.sort1(a, compare, mid+1, hi)\n\t\tthis.merge(a, compare, lo, mid, hi)\n\t}\n\n\t// Sort2采用自底向上方法进行归并排序，先从子数组为1开始归并操作，逐渐递增，直到归并成完整数组为止\n\t// Sort中参数类型Comparable为统一的可比较接口，若为整数数组排序，则Comparable为int即可\n\t// Sort中参数类型Compare为配合Comparable接口的比较方法，若为整数数组排序，则Compare即满足a int < a int即可\n\tfunc (this *MergeSort) sort2(a []Comparable, compare Compare) {\n\t\tfor sz := 1; sz < len(a); sz += sz {\n\t\t\tfor lo := 0; lo < len(a)-sz; lo += sz + sz {\n\t\t\t\tthis.merge(a, compare, lo, lo+sz-1, int(math.Min(float64(lo+sz+sz-1), float64(len(a)-1))))\n\t\t\t}\n\t\t}\n\t}\n\n下面我们来考虑下归并排序的效率问题。首先我们假设数组有N个元素，而N的值为2^n，所以采用归并排序的过程，可以用如下图的树状图表示：\n\n![树状图](/img/2014-12-28-0.png \"树状图\")\n\n图中每一个结点都表示一个merge()方法归并而成的一个数组。这棵树正好有n层。对于0到n-1之间的任意k，自顶向下的第k层有2^k个子数组，每个子数组又包含有2^(n-k)元素，所以归并操作最多需要2^(n-k)次比较。因此，每层的比较操作次数为2^n次，所以n次总共需要n*2^n次比较操作。又由于N=2^n，所以归并排序整个数组最多需要n*2^n=NlogN次比较操作。当然，每次归并操作最少需要2^(n-k)/2次比较，所以归并排序整个数组的话，最小需要NlogN/2次比较操作。综合上述分析，**归并排序需要NlogN/2至NlogN次比较操作**，因此其**时间复杂度是线性对数型的，即O(NlogN)**。\n\n可见，**归并排序是适合用于大规模数据排序**的算法。但不要忘了，归并排序有个明显的缺陷，即她需要申请与排序数组相同大小的数组进行归并操作，在空间利用方面并不是十分理想，因此可能**不适合用于空间不宽裕的场合**。","source":"_posts/2014-12-28-0.md","raw":"---\ndate: 2014-12-28\nlayout: post\ntitle: 经典算法巡礼(五) -- 排序之归并排序\npermalink: '/2014/12-28-0.html'\ncategories:\n- 算法\ntags:\n- 排序\n---\n\n\n[归并排序](http://en.wikipedia.org/wiki/Merge_sort)是创建在**归并操作**上的一种有效排序算法。**所谓归并操作，指的是将两个已经排序的序列合并成一个序列的操作**。归并排序是[**分治思想**](http://en.wikipedia.org/wiki/Divide_and_conquer_algorithms)的典型示范。\n\n归并排序具体步骤如下：\n\n1. 申请大小等于两个已排序序列之和的空间，该空间用来存放合并后的序列；\n2. 设定两个指针，初始位置分别为两个已排序序列的起始位置；\n3. 比较两个指针所指向的元素，选择较小的元素放入合并的空间中（若进行升序排序），并移动指针到下一个位置；\n4. 重复步骤3直至其中某一指针到达序列尾；\n5. 将另一序列剩下的元素直接复制到合并序列中。\n\n用[golang](https://golang.org/)实现如下： \n\n\t// merge方法实现归并排序中的归并操作，将两个已排序数组归并操作成一个已排序数组\n\tfunc (this *MergeSort) merge(a []Comparable, compare Compare, lo int, mid int, hi int) {\n\t\ti := lo\n\t\tj := mid + 1\n\n\t\tarrayBak := make([]Comparable, len(a))\n\t\tcopy(arrayBak, a)\n\n\t\tfor k := lo; k <= hi; k++ {\n\t\t\tif i > mid {\n\t\t\t\ta[k] = arrayBak[j]\n\t\t\t\tj++\n\t\t\t} else if j > hi {\n\t\t\t\ta[k] = arrayBak[i]\n\t\t\t\ti++\n\t\t\t} else if this.less(arrayBak[i], arrayBak[j], compare) {\n\t\t\t\ta[k] = arrayBak[i]\n\t\t\t\ti++\n\t\t\t} else {\n\t\t\t\ta[k] = arrayBak[j]\n\t\t\t\tj++\n\t\t\t}\n\t\t}\n\t}\n\n\t// Sort1采用自顶向下方法进行归并排序\n\t// Sort中参数类型Comparable为统一的可比较接口，若为整数数组排序，则Comparable为int即可\n\t// Sort中参数类型Compare为配合Comparable接口的比较方法，若为整数数组排序，则Compare即满足a int < a int即可\n\tfunc (this *MergeSort) sort1(a []Comparable, compare Compare, lo int, hi int) {\n\t\tif lo >= hi {\n\t\t\treturn\n\t\t}\n\n\t\tmid := (lo + hi) / 2\n\n\t\tthis.sort1(a, compare, lo, mid)\n\t\tthis.sort1(a, compare, mid+1, hi)\n\t\tthis.merge(a, compare, lo, mid, hi)\n\t}\n\n\t// Sort2采用自底向上方法进行归并排序，先从子数组为1开始归并操作，逐渐递增，直到归并成完整数组为止\n\t// Sort中参数类型Comparable为统一的可比较接口，若为整数数组排序，则Comparable为int即可\n\t// Sort中参数类型Compare为配合Comparable接口的比较方法，若为整数数组排序，则Compare即满足a int < a int即可\n\tfunc (this *MergeSort) sort2(a []Comparable, compare Compare) {\n\t\tfor sz := 1; sz < len(a); sz += sz {\n\t\t\tfor lo := 0; lo < len(a)-sz; lo += sz + sz {\n\t\t\t\tthis.merge(a, compare, lo, lo+sz-1, int(math.Min(float64(lo+sz+sz-1), float64(len(a)-1))))\n\t\t\t}\n\t\t}\n\t}\n\n下面我们来考虑下归并排序的效率问题。首先我们假设数组有N个元素，而N的值为2^n，所以采用归并排序的过程，可以用如下图的树状图表示：\n\n![树状图](/img/2014-12-28-0.png \"树状图\")\n\n图中每一个结点都表示一个merge()方法归并而成的一个数组。这棵树正好有n层。对于0到n-1之间的任意k，自顶向下的第k层有2^k个子数组，每个子数组又包含有2^(n-k)元素，所以归并操作最多需要2^(n-k)次比较。因此，每层的比较操作次数为2^n次，所以n次总共需要n*2^n次比较操作。又由于N=2^n，所以归并排序整个数组最多需要n*2^n=NlogN次比较操作。当然，每次归并操作最少需要2^(n-k)/2次比较，所以归并排序整个数组的话，最小需要NlogN/2次比较操作。综合上述分析，**归并排序需要NlogN/2至NlogN次比较操作**，因此其**时间复杂度是线性对数型的，即O(NlogN)**。\n\n可见，**归并排序是适合用于大规模数据排序**的算法。但不要忘了，归并排序有个明显的缺陷，即她需要申请与排序数组相同大小的数组进行归并操作，在空间利用方面并不是十分理想，因此可能**不适合用于空间不宽裕的场合**。","slug":"/2014/12-28-0.html","published":1,"updated":"2015-06-19T16:09:05.000Z","comments":1,"photos":[],"link":"","_id":"ciiwjp2zk001fof6g1o8hgpj7"},{"date":"2014-12-26T16:00:00.000Z","layout":"post","title":"经典算法巡礼(四) -- 排序之希尔排序","_content":"\n[希尔排序](http://en.wikipedia.org/wiki/Shellsort)与之前的排序算法不同，她是以她的发明者[Donald Shell](http://en.wikipedia.org/wiki/Donald_Shell)来命名的。她是[插入排序](http://codingforever.cn/2014/12-27-2.html)的一种改进版本。\n\n希尔排序是基于[插入排序](http://codingforever.cn/2014/12-27-2.html)的以下两点性质而提出的改进算法：\n\n* 插入排序的效率与输入序列有关，当输入序列处于基本排好序的情况下可以达到线性排序的效率；\n* 插入排序在大规模乱序情况下，效率是比较低的，因为她只会交换相邻的元素，因此元素只能一点点从数组的一端移动到另一端，即最差情况下的平方级别的效率。\n\n希尔排序为了加快速度简单地改进了[插入排序](http://codingforever.cn/2014/12-27-2.html)，交换不相邻的元素以对数组的局部进行排序，并最终用插入排序将局部有序的数组排序。\n\n**希尔排序的思想是使数组中任意间隔为h的元素都是有序的**。换句话说，**希尔排序就是将数组中任意间隔为h的元素组成的新数组排列有序**，当h为1时，该数组就排序完成了。事实上，h为1时，希尔排序就是[插入排序](http://codingforever.cn/2014/12-27-2.html)。\n\n那么，为什么希尔排序会比较高效呢？首先，我们知道**[插入排序](http://codingforever.cn/2014/12-27-2.html)对于基本有序的数组排序效率是线性的**。希尔排序在排序之初，间隔为h的元素组成的新数组都很短，而且基本处于有序状态，所以采用[插入排序](http://codingforever.cn/2014/12-27-2.html)对子数组排序是很高效的。然后当h递减时，又由于已进行过几轮排序的原因，子数组又是基本牌有状态的，所以很适合采用[插入排序](http://codingforever.cn/2014/12-27-2.html)。\n\n说了这么多，其实希尔排序就是将数组中元素以h为间隔取出元素组成新的数组，并用[插入排序](http://codingforever.cn/2014/12-27-2.html)将新数组排列有序。递减h的值，重复以上过程，直到h==1为止。\n\n那么，h应该如何递减呢？事实上要回答这个问题并不简单。希尔算法的性能不仅取决于h，还取决于各h之间的数学性质，比如它们的公因子等。这里，我们以h=h*3+1做为h的递增方法，用[golang](https://golang.org/)实现如下：\n\n\t// Sort方法从将间隔为h的元素组成的子数组进行插入排序，重复此过程直到h==1\n\t// Sort中参数类型Comparable为统一的可比较接口，若为整数数组排序，则Comparable为int即可\n\t// Sort中参数类型Compare为配合Comparable接口的比较方法，若为整数数组排序，则Compare即满足a int < a int即可\n\tfunc (this *ShellSort) Sort(a []Comparable, compare Compare) {\n\t\tarrayLen := len(a)\n\n\t\th := 1\n\t\tfor h < arrayLen/3 {\n\t\t\th = 3*h + 1\n\t\t}\n\n\t\tfor h >= 1 {\n\t\t\t// 对间隔为h的子数组进行插入排序\n\t\t\tfor i := h; i < len(a); i++ {\n\t\t\t\tfor j := i; j >= h && this.less(a[j], a[j-h], compare); j -= h {\n\t\t\t\t\tthis.exch(a, j, j-h)\n\t\t\t\t}\n\t\t\t}\n\t\t\th = h / 3\n\t\t}\n\t}\n\n这里，我们并**不讨论希尔排序的时间复杂度，因为这个问题至今还没有确定的答案**，但肯定的是，她是可以用于进行大规模数据的排序，在最坏情况下**时间复杂度可以达到O(NlogN*logN)**。","source":"_posts/2014-12-27-3.md","raw":"---\ndate: 2014-12-27\nlayout: post\ntitle: 经典算法巡礼(四) -- 排序之希尔排序\npermalink: '/2014/12-27-3.html'\ncategories:\n- 算法\ntags:\n- 排序\n---\n\n[希尔排序](http://en.wikipedia.org/wiki/Shellsort)与之前的排序算法不同，她是以她的发明者[Donald Shell](http://en.wikipedia.org/wiki/Donald_Shell)来命名的。她是[插入排序](http://codingforever.cn/2014/12-27-2.html)的一种改进版本。\n\n希尔排序是基于[插入排序](http://codingforever.cn/2014/12-27-2.html)的以下两点性质而提出的改进算法：\n\n* 插入排序的效率与输入序列有关，当输入序列处于基本排好序的情况下可以达到线性排序的效率；\n* 插入排序在大规模乱序情况下，效率是比较低的，因为她只会交换相邻的元素，因此元素只能一点点从数组的一端移动到另一端，即最差情况下的平方级别的效率。\n\n希尔排序为了加快速度简单地改进了[插入排序](http://codingforever.cn/2014/12-27-2.html)，交换不相邻的元素以对数组的局部进行排序，并最终用插入排序将局部有序的数组排序。\n\n**希尔排序的思想是使数组中任意间隔为h的元素都是有序的**。换句话说，**希尔排序就是将数组中任意间隔为h的元素组成的新数组排列有序**，当h为1时，该数组就排序完成了。事实上，h为1时，希尔排序就是[插入排序](http://codingforever.cn/2014/12-27-2.html)。\n\n那么，为什么希尔排序会比较高效呢？首先，我们知道**[插入排序](http://codingforever.cn/2014/12-27-2.html)对于基本有序的数组排序效率是线性的**。希尔排序在排序之初，间隔为h的元素组成的新数组都很短，而且基本处于有序状态，所以采用[插入排序](http://codingforever.cn/2014/12-27-2.html)对子数组排序是很高效的。然后当h递减时，又由于已进行过几轮排序的原因，子数组又是基本牌有状态的，所以很适合采用[插入排序](http://codingforever.cn/2014/12-27-2.html)。\n\n说了这么多，其实希尔排序就是将数组中元素以h为间隔取出元素组成新的数组，并用[插入排序](http://codingforever.cn/2014/12-27-2.html)将新数组排列有序。递减h的值，重复以上过程，直到h==1为止。\n\n那么，h应该如何递减呢？事实上要回答这个问题并不简单。希尔算法的性能不仅取决于h，还取决于各h之间的数学性质，比如它们的公因子等。这里，我们以h=h*3+1做为h的递增方法，用[golang](https://golang.org/)实现如下：\n\n\t// Sort方法从将间隔为h的元素组成的子数组进行插入排序，重复此过程直到h==1\n\t// Sort中参数类型Comparable为统一的可比较接口，若为整数数组排序，则Comparable为int即可\n\t// Sort中参数类型Compare为配合Comparable接口的比较方法，若为整数数组排序，则Compare即满足a int < a int即可\n\tfunc (this *ShellSort) Sort(a []Comparable, compare Compare) {\n\t\tarrayLen := len(a)\n\n\t\th := 1\n\t\tfor h < arrayLen/3 {\n\t\t\th = 3*h + 1\n\t\t}\n\n\t\tfor h >= 1 {\n\t\t\t// 对间隔为h的子数组进行插入排序\n\t\t\tfor i := h; i < len(a); i++ {\n\t\t\t\tfor j := i; j >= h && this.less(a[j], a[j-h], compare); j -= h {\n\t\t\t\t\tthis.exch(a, j, j-h)\n\t\t\t\t}\n\t\t\t}\n\t\t\th = h / 3\n\t\t}\n\t}\n\n这里，我们并**不讨论希尔排序的时间复杂度，因为这个问题至今还没有确定的答案**，但肯定的是，她是可以用于进行大规模数据的排序，在最坏情况下**时间复杂度可以达到O(NlogN*logN)**。","slug":"/2014/12-27-3.html","published":1,"updated":"2015-06-19T16:09:05.000Z","comments":1,"photos":[],"link":"","_id":"ciiwjp2zo001iof6gv8helixr"},{"date":"2014-12-26T16:00:00.000Z","layout":"post","title":"经典算法巡礼(三) -- 排序之插入排序","_content":"\n[插入排序](http://en.wikipedia.org/wiki/Insertion_sort)，与之前的[冒泡排序](http://codingforever.cn/2014/12-27-0.html)和[选择排序](http://codingforever.cn/2014/12-27-1.html)一样，其名称就说明了她的原理。所谓插入排序，就是对于数组中未排序的元素，依次遍历寻找合适的位置并插入到已排序的子数组中。当数组中没有未排序的元素时，插入排序即完成。\n\n同样，还是先展示[golang](https://golang.org/)实现的版本：\n\n\t// Sort方法从数组头开始，将未排序的元素依次选择合适的位置插入已排序的子数组中\n\t// 这里并不是找到合适位置后再将元素插入，而是交换元素至合适位置\n\t// Sort中参数类型Comparable为统一的可比较接口，若为整数数组排序，则Comparable为int即可\n\t// Sort中参数类型Compare为配合Comparable接口的比较方法，若为整数数组排序，则Compare即满足a int < a int即可\n\tfunc (this *InsertionSort) Sort(a []Comparable, compare Compare) {\n\t\tfor i := 1; i < len(a); i++ {\n\t\t\tfor j := i; j > 0 && this.less(a[j], a[j-1], compare); j-- {\n\t\t\t\tthis.exch(a, j, j-1)\n\t\t\t}\n\t\t}\n\t}要\n\n还是与之前一样，我们以数组元素的比较作为一次操作，分析插入排序其效率如何。事实上，在最差情况下，采用插入排序需要的比较次数为**0+1+2+...+N-1**次，简化后即为**(N-1)/2*N = (N^2-N)/2 ~ N^2**。而在最好的情况下，排入排序需要的比较次数则为**N-1**次。\n\n可见，插入排序的**时间复杂度是O(N^2)**，同样是万恶的**平方级别**。但是，与[冒泡排序](http://codingforever.cn/2014/12-27-0.html)和[选择排序](http://codingforever.cn/2014/12-27-1.html)不同，插入排序所需的比较次数是**与输入数组相关的**，在最差的情况下才需要N^2次的操作。然而事实就是事实，插入排序还是**只适用于小型数组的排序，不能满足大量数据的排序**。","source":"_posts/2014-12-27-2.md","raw":"---\ndate: 2014-12-27\nlayout: post\ntitle: 经典算法巡礼(三) -- 排序之插入排序\npermalink: '/2014/12-27-2.html'\ncategories:\n- 算法\ntags:\n- 排序\n---\n\n[插入排序](http://en.wikipedia.org/wiki/Insertion_sort)，与之前的[冒泡排序](http://codingforever.cn/2014/12-27-0.html)和[选择排序](http://codingforever.cn/2014/12-27-1.html)一样，其名称就说明了她的原理。所谓插入排序，就是对于数组中未排序的元素，依次遍历寻找合适的位置并插入到已排序的子数组中。当数组中没有未排序的元素时，插入排序即完成。\n\n同样，还是先展示[golang](https://golang.org/)实现的版本：\n\n\t// Sort方法从数组头开始，将未排序的元素依次选择合适的位置插入已排序的子数组中\n\t// 这里并不是找到合适位置后再将元素插入，而是交换元素至合适位置\n\t// Sort中参数类型Comparable为统一的可比较接口，若为整数数组排序，则Comparable为int即可\n\t// Sort中参数类型Compare为配合Comparable接口的比较方法，若为整数数组排序，则Compare即满足a int < a int即可\n\tfunc (this *InsertionSort) Sort(a []Comparable, compare Compare) {\n\t\tfor i := 1; i < len(a); i++ {\n\t\t\tfor j := i; j > 0 && this.less(a[j], a[j-1], compare); j-- {\n\t\t\t\tthis.exch(a, j, j-1)\n\t\t\t}\n\t\t}\n\t}要\n\n还是与之前一样，我们以数组元素的比较作为一次操作，分析插入排序其效率如何。事实上，在最差情况下，采用插入排序需要的比较次数为**0+1+2+...+N-1**次，简化后即为**(N-1)/2*N = (N^2-N)/2 ~ N^2**。而在最好的情况下，排入排序需要的比较次数则为**N-1**次。\n\n可见，插入排序的**时间复杂度是O(N^2)**，同样是万恶的**平方级别**。但是，与[冒泡排序](http://codingforever.cn/2014/12-27-0.html)和[选择排序](http://codingforever.cn/2014/12-27-1.html)不同，插入排序所需的比较次数是**与输入数组相关的**，在最差的情况下才需要N^2次的操作。然而事实就是事实，插入排序还是**只适用于小型数组的排序，不能满足大量数据的排序**。","slug":"/2014/12-27-2.html","published":1,"updated":"2015-06-19T16:09:05.000Z","comments":1,"photos":[],"link":"","_id":"ciiwjp2zq001lof6g8jjh099b"},{"date":"2014-12-26T16:00:00.000Z","layout":"post","title":"经典算法巡礼(二) -- 排序之选择排序","_content":"\n[选择排序](http://en.wikipedia.org/wiki/Selection_sort)，如[冒泡排序](http://codingforever.cn/2014/12-27-0.html)一样，从名字中即可大概猜测其排序的原理。其工作原理就是从未排序的数组中选出最大（小）的元素，将其放置至数组的首（尾）部，重复此过程直至没有未排序的子数组。\n\n当然，在分析该排序算法前还是先将[golang](https://golang.org/)实现版本放置出来献下丑：\n\n\t// Sort方法从数组头开始，将未排序的元素做为子数组，并在子数组中选择中最小的元素，将其放置子数组的最首位置做为已排序元素，重复此过程，直到所有数组元素排序完成为止\n\t// Sort中参数类型Comparable为统一的可比较接口，若为整数数组排序，则Comparable为int即可\n\t// Sort中参数类型Compare为配合Comparable接口的比较方法，若为整数数组排序，则Compare即满足a int < a int即可\n\tfunc (this *SelectSort) Sort(a []Comparable, compare Compare) {\n\t\tfor i := 0; i < len(a); i++ {\n\t\t\tmin := i\n\t\t\tfor j := i + 1; j < len(a); j++ {\n\t\t\t\tif this.less(a[j], a[min], compare) == true {\n\t\t\t\t\tmin = j\n\t\t\t\t}\n\t\t\t}\n\t\t\tthis.exch(a, i, min)\n\t\t}\n\t}\n\n同样，我们用与[冒泡排序](http://codingforever.cn/2014/12-27-0.html)相同的方法分析其效率。观察选择排序的代码实现，明显她也是**时间复杂度为O(N^2)**的排序算法。同样以元素比较作为单元操作，完成一个长度为N的数组的排序工作需要**N-1 + N-2 + ... + 2 + 1**次比较操作，简化后为**(N-1)/2*N = (N^2-N)/2 ~ N^2**。\n\n与[冒泡排序](http://codingforever.cn/2014/12-27-0.html)不同的是，虽然两种排序算法的比较次数是相同的，但是其元素交换操作数目并不是相同的。选择排序的交换操作**最多为N次**，而冒泡排序的交换操作却与数组中不满足顺序的元素对数量相同，即与被排序数组相关，在最差情况下，其次数与比较次数相同，即**N^2**。\n\n虽然选择排序在元素交换方面比[冒泡排序](http://codingforever.cn/2014/12-27-0.html)具有一定的优势，但是其时间复杂度依然是万恶的**平方级别的，即O(N^2)**，所以其依然**只适用于小型数组的排序，不能满足大量数据的排序**。","source":"_posts/2014-12-27-1.md","raw":"---\ndate: 2014-12-27\nlayout: post\ntitle: 经典算法巡礼(二) -- 排序之选择排序\npermalink: '/2014/12-27-1.html'\ncategories:\n- 算法\ntags:\n- 排序\n---\n\n[选择排序](http://en.wikipedia.org/wiki/Selection_sort)，如[冒泡排序](http://codingforever.cn/2014/12-27-0.html)一样，从名字中即可大概猜测其排序的原理。其工作原理就是从未排序的数组中选出最大（小）的元素，将其放置至数组的首（尾）部，重复此过程直至没有未排序的子数组。\n\n当然，在分析该排序算法前还是先将[golang](https://golang.org/)实现版本放置出来献下丑：\n\n\t// Sort方法从数组头开始，将未排序的元素做为子数组，并在子数组中选择中最小的元素，将其放置子数组的最首位置做为已排序元素，重复此过程，直到所有数组元素排序完成为止\n\t// Sort中参数类型Comparable为统一的可比较接口，若为整数数组排序，则Comparable为int即可\n\t// Sort中参数类型Compare为配合Comparable接口的比较方法，若为整数数组排序，则Compare即满足a int < a int即可\n\tfunc (this *SelectSort) Sort(a []Comparable, compare Compare) {\n\t\tfor i := 0; i < len(a); i++ {\n\t\t\tmin := i\n\t\t\tfor j := i + 1; j < len(a); j++ {\n\t\t\t\tif this.less(a[j], a[min], compare) == true {\n\t\t\t\t\tmin = j\n\t\t\t\t}\n\t\t\t}\n\t\t\tthis.exch(a, i, min)\n\t\t}\n\t}\n\n同样，我们用与[冒泡排序](http://codingforever.cn/2014/12-27-0.html)相同的方法分析其效率。观察选择排序的代码实现，明显她也是**时间复杂度为O(N^2)**的排序算法。同样以元素比较作为单元操作，完成一个长度为N的数组的排序工作需要**N-1 + N-2 + ... + 2 + 1**次比较操作，简化后为**(N-1)/2*N = (N^2-N)/2 ~ N^2**。\n\n与[冒泡排序](http://codingforever.cn/2014/12-27-0.html)不同的是，虽然两种排序算法的比较次数是相同的，但是其元素交换操作数目并不是相同的。选择排序的交换操作**最多为N次**，而冒泡排序的交换操作却与数组中不满足顺序的元素对数量相同，即与被排序数组相关，在最差情况下，其次数与比较次数相同，即**N^2**。\n\n虽然选择排序在元素交换方面比[冒泡排序](http://codingforever.cn/2014/12-27-0.html)具有一定的优势，但是其时间复杂度依然是万恶的**平方级别的，即O(N^2)**，所以其依然**只适用于小型数组的排序，不能满足大量数据的排序**。","slug":"/2014/12-27-1.html","published":1,"updated":"2015-06-19T16:09:05.000Z","comments":1,"photos":[],"link":"","_id":"ciiwjp2zt001oof6grbezs3i6"},{"date":"2014-12-26T16:00:00.000Z","layout":"post","title":"经典算法巡礼(一) -- 排序之冒泡排序","_content":"\n[**冒泡排序**](http://en.wikipedia.org/wiki/Bubble_sort)是一种简单的排序算法，相信绝大多数人学会的第一种排序算法就是她了。\n\n事实上，她重复地遍历需要排序的元素，一次比较相邻的两个元素，如果不满足预先定义的比较条件，则交换；否则继续下一组元素比较，直至遍历完成需要排序的所有元素。当然，遍历需要排序的元素需要重复进行，直到没有需要排序的元素为止。遍历需要排序的元素时，每一次交换不满足顺序条件的元素就如同气泡一样，从元素序列的一端慢慢“上升”到序列的另一端，此现象如同水中冒气泡一样，此排序算法以此得名。\n\n具体实现也较为简单，用[golang](https://golang.org/)表示如下：\n\n\t// Sort方法从数组头开始冒泡，将最小元素位置上升到最后，直到数组排序完成为止\n\t// Sort中参数类型Comparable为统一的可比较接口，若为整数数组排序，则Comparable为int即可\n\t// Sort中参数类型Compare为配合Comparable接口的比较方法，若为整数数组排序，则Compare即满足a int < a int即可\n\tfunc (this *BubbleSort) Sort(a []Comparable, compare Compare) {\n\t\tfor i := 0; i < len(a); i++ {\n\t\t\tfor j := 1; j < len(a)-i; j++ {\n\t\t\t\tif this.less(a[j], a[j-1], compare) {\n\t\t\t\t\tthis.exch(a, j-1, j)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n那么，冒泡排序的效率如何呢？事实上，她不咋滴。且看上述代码中的两重循环吧，这可是复杂度的恶梦啊。当然，很明显，她的[时间复杂度](http://en.wikipedia.org/wiki/Time_complexity)是**O(N^2)**。\n\n为了方便，我们以一次比较作为一次时间复杂度操作。根据冒泡排序的实现的思路，对长度为N的数组进行排序所需要的比较次数为**N-1 + N-2 + ... + 1 + 0**，即**(N-1)/2*N = (N^2-N)/2 ~ N^2**。可见，通用简单的数学计算，冒泡排序的时间复杂度确实就是**O(N^2)**。\n\n换种通俗的方式来说，**冒泡排序的时间复杂度是平方级别的**。因此，她只**适合对少量元素进行排序，而无法用于大规模数据的排序**，可谓是中看不中用啊。","source":"_posts/2014-12-27-0.md","raw":"---\ndate: 2014-12-27\nlayout: post\ntitle: 经典算法巡礼(一) -- 排序之冒泡排序\npermalink: '/2014/12-27-0.html'\ncategories:\n- 算法\ntags:\n- 排序\n---\n\n[**冒泡排序**](http://en.wikipedia.org/wiki/Bubble_sort)是一种简单的排序算法，相信绝大多数人学会的第一种排序算法就是她了。\n\n事实上，她重复地遍历需要排序的元素，一次比较相邻的两个元素，如果不满足预先定义的比较条件，则交换；否则继续下一组元素比较，直至遍历完成需要排序的所有元素。当然，遍历需要排序的元素需要重复进行，直到没有需要排序的元素为止。遍历需要排序的元素时，每一次交换不满足顺序条件的元素就如同气泡一样，从元素序列的一端慢慢“上升”到序列的另一端，此现象如同水中冒气泡一样，此排序算法以此得名。\n\n具体实现也较为简单，用[golang](https://golang.org/)表示如下：\n\n\t// Sort方法从数组头开始冒泡，将最小元素位置上升到最后，直到数组排序完成为止\n\t// Sort中参数类型Comparable为统一的可比较接口，若为整数数组排序，则Comparable为int即可\n\t// Sort中参数类型Compare为配合Comparable接口的比较方法，若为整数数组排序，则Compare即满足a int < a int即可\n\tfunc (this *BubbleSort) Sort(a []Comparable, compare Compare) {\n\t\tfor i := 0; i < len(a); i++ {\n\t\t\tfor j := 1; j < len(a)-i; j++ {\n\t\t\t\tif this.less(a[j], a[j-1], compare) {\n\t\t\t\t\tthis.exch(a, j-1, j)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n那么，冒泡排序的效率如何呢？事实上，她不咋滴。且看上述代码中的两重循环吧，这可是复杂度的恶梦啊。当然，很明显，她的[时间复杂度](http://en.wikipedia.org/wiki/Time_complexity)是**O(N^2)**。\n\n为了方便，我们以一次比较作为一次时间复杂度操作。根据冒泡排序的实现的思路，对长度为N的数组进行排序所需要的比较次数为**N-1 + N-2 + ... + 1 + 0**，即**(N-1)/2*N = (N^2-N)/2 ~ N^2**。可见，通用简单的数学计算，冒泡排序的时间复杂度确实就是**O(N^2)**。\n\n换种通俗的方式来说，**冒泡排序的时间复杂度是平方级别的**。因此，她只**适合对少量元素进行排序，而无法用于大规模数据的排序**，可谓是中看不中用啊。","slug":"/2014/12-27-0.html","published":1,"updated":"2015-06-19T16:09:05.000Z","comments":1,"photos":[],"link":"","_id":"ciiwjp2zw001rof6gkc2hz1lb"},{"date":"2014-12-11T16:00:00.000Z","layout":"post","title":"案例研究：union-find算法(四) — 加权quick-union算法","_content":"\n\n在[Quick-Union算法](https://zhujiefirst.github.io/2014/12-08-0.html)中，在Union方法中归并两个分量时，我们始终是分量p归并至分量q。事实上，这里我们可以进行简单的优化，将含有节点少的分量归并至含有节点多的分量，如此做法可以减少分量形成的树的高度，从而在Find方法中寻找根节点时，适当增加效率。\n\n加权Quick-Union算法首先就要保存各分量包含的节点数，struct具体修改成如下：\n\n\ttype UFWeightQuickUnion struct {\n\t    UF\n\t    sz []int\n\t}\n\n当然Init方法也要做相应的修改：\n\n\tfunc (u *UFWeightQuickUnion) Init(n int) {\n\t    u.count = n\n\t    u.id = make([]int, 0, n)\n\t    u.sz = make([]int, 0, n)\n\t    for i := 0; i < n; i++ {\n\t        u.id = append(u.id, i)\n\t        u.sz = append(u.sz, 1)\n\t    }\n\t}\n\n具体归并两个分量时，首先判断分量p与q含有节点数的多少，再将节点数少的分量归并至节点数多的分量，具体做法如下：\n\n\tfunc (u *UFWeightQuickUnion) Union(p int, q int) {\n\t    pRoot := u.Find(p)\n\t    qRoot := u.Find(q)\n\t \n\t    if pRoot == qRoot {\n\t        return\n\t    }\n\t \n\t    if u.sz[pRoot] < u.sz[qRoot] {\n\t        u.id[pRoot] = qRoot\n\t        u.sz[qRoot] = u.sz[qRoot] + u.sz[pRoot]\n\t    } else {\n\t        u.id[qRoot] = pRoot\n\t        u.sz[pRoot] = u.sz[pRoot] + u.sz[qRoot]\n\t    }\n\t    u.count--\n\t}\n\n当然，Find方法与Quick-Union保持一样：\n\n\tfunc (u *UFWeightQuickUnion) Find(p int) int {\n\t    for p != u.id[p] {\n\t        p = u.id[p]\n\t    }\n\t    return p\n\t}\n\n那么，加权Quick-Union算法到底效率如何呢？首先，我们可以分析得到分量所形成的树高度最大为logN,那么，Find方法访问数组的次数为1到logN次。所以，Union方法访问数组的次数相应为3到2logN+1次，即最多2logN+1~logN次。\n\n可见，**加权Quick-Union算法解决之前提出的问题时，最多访问数组NlogN次**，完全可以用于现实项目。","source":"_posts/2014-12-12-0.md","raw":"---\ndate: 2014-12-12\nlayout: post\ntitle: 案例研究：union-find算法(四) — 加权quick-union算法\npermalink: '/2014/12-12-0.html'\ncategories:\n- 算法\ntags:\n- union-find\n---\n\n\n在[Quick-Union算法](https://zhujiefirst.github.io/2014/12-08-0.html)中，在Union方法中归并两个分量时，我们始终是分量p归并至分量q。事实上，这里我们可以进行简单的优化，将含有节点少的分量归并至含有节点多的分量，如此做法可以减少分量形成的树的高度，从而在Find方法中寻找根节点时，适当增加效率。\n\n加权Quick-Union算法首先就要保存各分量包含的节点数，struct具体修改成如下：\n\n\ttype UFWeightQuickUnion struct {\n\t    UF\n\t    sz []int\n\t}\n\n当然Init方法也要做相应的修改：\n\n\tfunc (u *UFWeightQuickUnion) Init(n int) {\n\t    u.count = n\n\t    u.id = make([]int, 0, n)\n\t    u.sz = make([]int, 0, n)\n\t    for i := 0; i < n; i++ {\n\t        u.id = append(u.id, i)\n\t        u.sz = append(u.sz, 1)\n\t    }\n\t}\n\n具体归并两个分量时，首先判断分量p与q含有节点数的多少，再将节点数少的分量归并至节点数多的分量，具体做法如下：\n\n\tfunc (u *UFWeightQuickUnion) Union(p int, q int) {\n\t    pRoot := u.Find(p)\n\t    qRoot := u.Find(q)\n\t \n\t    if pRoot == qRoot {\n\t        return\n\t    }\n\t \n\t    if u.sz[pRoot] < u.sz[qRoot] {\n\t        u.id[pRoot] = qRoot\n\t        u.sz[qRoot] = u.sz[qRoot] + u.sz[pRoot]\n\t    } else {\n\t        u.id[qRoot] = pRoot\n\t        u.sz[pRoot] = u.sz[pRoot] + u.sz[qRoot]\n\t    }\n\t    u.count--\n\t}\n\n当然，Find方法与Quick-Union保持一样：\n\n\tfunc (u *UFWeightQuickUnion) Find(p int) int {\n\t    for p != u.id[p] {\n\t        p = u.id[p]\n\t    }\n\t    return p\n\t}\n\n那么，加权Quick-Union算法到底效率如何呢？首先，我们可以分析得到分量所形成的树高度最大为logN,那么，Find方法访问数组的次数为1到logN次。所以，Union方法访问数组的次数相应为3到2logN+1次，即最多2logN+1~logN次。\n\n可见，**加权Quick-Union算法解决之前提出的问题时，最多访问数组NlogN次**，完全可以用于现实项目。","slug":"/2014/12-12-0.html","published":1,"updated":"2015-06-19T16:09:05.000Z","comments":1,"photos":[],"link":"","_id":"ciiwjp2zy001uof6geudkk1if"},{"date":"2014-12-07T16:00:00.000Z","layout":"post","title":"案例研究：union-find算法(三) -- quick-union算法","_content":"\n\n**Quick-Union算法**，就是提高Union方法的速度。在[Quick-Find算法](https://zhujiefirst.github.io/2014/12-07-0.html)中，Union方法每次调用均会遍历id[ ]数组，那么如何才能提高Union方法的效率呢。当然，这里我们先要赋予数组id[ ]不同的意义。Quick-Find中，id[i]表示第i个触点所有的分量为id[i]的值。而这里，**id[i]的值表示与触点i具有相同分量的触点，即触点i和触点id[i]具有相同的分量**。\n\n当然，id[i]必须构成一棵树，当达到根节点时，id[i]=i，即触点i的同一分量的下一个触点为其本身。\n\n根据id[ ]数组被赋予的新的意义，Find方法也需要修改。具体实现如下：\n\n\tfunc (u *UFQuickUnion) Find(p int) int {\n\t    for p != u.id[p] {\n\t        p = u.id[p]\n\t    }\n\t    return p\n\t}\n\n上述代码就是找到触点p所在树的根节点，其根节点触点的索引即为我们所需的分量值。\n\n另外，Union方法也修改为如下：\n\n\tfunc (u *UFQuickUnion) Union(p int, q int) {\n\t    pRoot := u.Find(p)\n\t    qRoot := u.Find(q)\n\t \n\t    if pRoot == qRoot {\n\t        return\n\t    }\n\t \n\t    u.id[pRoot] = qRoot\n\t    u.count--\n\t}\n\n先通过Find方法找到触点p和触点q所在的分量值，然后直接修改触点p所有的分量值与触点q相同即可，即将触点p的下一个触点设置为触点q。\n\n通过Find方法和Union方法的代码展示，**Quick-Union算法看起来比Quick-Find算法更快**，因为它不需要遍历整个id[ ]数组。那么，事实上呢？\n\n首先我们来看Find方法。在最好的情况下，Find方法只需要一次数组访问即可(触点p恰巧为树的根节点)；在最坏的情况下，Find方法需要2N-1次数组访问(触点p恰巧在树叶上且所有触点组成了一个链表)，其中条件判断语句N次，赋值语句N-1次。\n\n然后，我们再分析下Union方法。在Union方法中，调用了两次Find方法，最后归并分量时又对数组进行了1次访问。所以，Union方法在最好的情况下，需要访问id[ ]数组3次，而在最坏的情况下，需要访问数组2N-1次。\n\n因此，假设我们使用Quick-Union算法来解决动态连通性问题并且最后只得到了一个连通分量，那么至少需要调用N-1次Union方法，即在最好的情况下，至少需要访问(N-1)*3 ~ N次数组，而在最坏的情况下，需要调用(N-1)*(2N-1) ~ N^2次数组。所以，同样可以推断，Quick-Union算法在最好的情况下，是线性复杂度的，在最坏的情况下，是平方复杂度的。\n\n可见，**Quick-Union算法的复杂度是在最好情况下是线性级别的，在最坏情况下是平方级别的**。所以，Quick-Find算法可以作为Quick-Find算法的改进。那么，Quick-Union算法是不是还有改进的余地？当然有。请移步[加权Quick-Union算法](https://zhujiefirst.github.io/2014/12-12-0.html)。","source":"_posts/2014-12-08-0.md","raw":"---\ndate: 2014-12-08\nlayout: post\ntitle: 案例研究：union-find算法(三) -- quick-union算法\npermalink: '/2014/12-08-0.html'\ncategories:\n- 算法\ntags:\n- union-find\n---\n\n\n**Quick-Union算法**，就是提高Union方法的速度。在[Quick-Find算法](https://zhujiefirst.github.io/2014/12-07-0.html)中，Union方法每次调用均会遍历id[ ]数组，那么如何才能提高Union方法的效率呢。当然，这里我们先要赋予数组id[ ]不同的意义。Quick-Find中，id[i]表示第i个触点所有的分量为id[i]的值。而这里，**id[i]的值表示与触点i具有相同分量的触点，即触点i和触点id[i]具有相同的分量**。\n\n当然，id[i]必须构成一棵树，当达到根节点时，id[i]=i，即触点i的同一分量的下一个触点为其本身。\n\n根据id[ ]数组被赋予的新的意义，Find方法也需要修改。具体实现如下：\n\n\tfunc (u *UFQuickUnion) Find(p int) int {\n\t    for p != u.id[p] {\n\t        p = u.id[p]\n\t    }\n\t    return p\n\t}\n\n上述代码就是找到触点p所在树的根节点，其根节点触点的索引即为我们所需的分量值。\n\n另外，Union方法也修改为如下：\n\n\tfunc (u *UFQuickUnion) Union(p int, q int) {\n\t    pRoot := u.Find(p)\n\t    qRoot := u.Find(q)\n\t \n\t    if pRoot == qRoot {\n\t        return\n\t    }\n\t \n\t    u.id[pRoot] = qRoot\n\t    u.count--\n\t}\n\n先通过Find方法找到触点p和触点q所在的分量值，然后直接修改触点p所有的分量值与触点q相同即可，即将触点p的下一个触点设置为触点q。\n\n通过Find方法和Union方法的代码展示，**Quick-Union算法看起来比Quick-Find算法更快**，因为它不需要遍历整个id[ ]数组。那么，事实上呢？\n\n首先我们来看Find方法。在最好的情况下，Find方法只需要一次数组访问即可(触点p恰巧为树的根节点)；在最坏的情况下，Find方法需要2N-1次数组访问(触点p恰巧在树叶上且所有触点组成了一个链表)，其中条件判断语句N次，赋值语句N-1次。\n\n然后，我们再分析下Union方法。在Union方法中，调用了两次Find方法，最后归并分量时又对数组进行了1次访问。所以，Union方法在最好的情况下，需要访问id[ ]数组3次，而在最坏的情况下，需要访问数组2N-1次。\n\n因此，假设我们使用Quick-Union算法来解决动态连通性问题并且最后只得到了一个连通分量，那么至少需要调用N-1次Union方法，即在最好的情况下，至少需要访问(N-1)*3 ~ N次数组，而在最坏的情况下，需要调用(N-1)*(2N-1) ~ N^2次数组。所以，同样可以推断，Quick-Union算法在最好的情况下，是线性复杂度的，在最坏的情况下，是平方复杂度的。\n\n可见，**Quick-Union算法的复杂度是在最好情况下是线性级别的，在最坏情况下是平方级别的**。所以，Quick-Find算法可以作为Quick-Find算法的改进。那么，Quick-Union算法是不是还有改进的余地？当然有。请移步[加权Quick-Union算法](https://zhujiefirst.github.io/2014/12-12-0.html)。","slug":"/2014/12-08-0.html","published":1,"updated":"2015-06-19T16:09:05.000Z","comments":1,"photos":[],"link":"","_id":"ciiwjp300001yof6gdjrc0rwh"},{"date":"2014-12-06T16:00:00.000Z","layout":"post","title":"案例研究：union-find算法(二) -- quick-find算法","_content":"\n所谓**Quick-Find算法**，顾名思义就是Find实现是Quick版本，而相对于Union，则显得不那么Quick了。当然，这是通过结论推导原因，放在这里是十分牵强的。所以，还是正常思维，如果要实现这个功能，当然，暴力算法是不可少的。而恰巧，这个暴力算法正好就是**Quick-Find算法**。\n\n首先，我们考虑Find的实现。寻找触点p对应的分量，由于id[ ]存放着各触点对应的分量，所以简单粗暴的id[p]就是触点p对应的分量。所以，Find的实现如下：\n\n\tfunc (u *UFQuickFind) Find(p int) int {\n\t    return u.id[p]\n\t}\n\n其次，再来考虑Union的实现。由于id[ ]存放着各触点对应的分量，而Union的功能就是把触点p和触点q的分量统一，即id[p]==id[q]即可，当然，原来与p(q)处于同一分量的触点也满足上式即可。所以，具体实现可参考如下：\n\n\tfunc (u *UFQuickFind) Union(p int, q int) {\n\t    pID := u.Find(p)\n\t    qID := u.Find(q)\n\t \n\t    if pID == qID {\n\t        return\n\t    }\n\t \n\t    for i := 0; i < len(u.id); i++ {\n\t        if u.id[i] == pID {\n\t            u.id[i] = qID\n\t        }\n\t    }\n\t \n\t    u.count--\n\t}\n\n分析上述Union方法的实现，简单来说就是触点p和触点q的分量如果不统一，则遍历所有触点，将原来属于触点p的分量的所有触点，全部统一成触点q的分量，如此做法即可达到触点p和触点q的分量统一，同时原先与触点p属于相同分量的其他触点依然保持处于相同分量的条件。\n\n那么，我们来分析下Quick-Find算法是否符合我们所说的，当问题规模增大时，解决问题所花的时间是否我们依然可以接受。\n\n首先，我们来看下Find方法。Find方法的速度显然是很快的，因为它只需要访问id[ ]数组一次。  \n那么，Union方法呢。很明显，Union方法的实现并不是很理想，因为每一次调用Union方法均要遍历一次id[ ]数组。我们可以具体算一下Union方法到底访问id[ ]数组多少次。归并两个分量操作首先会调用两次Find方法，而每个Find方法都会访问id[ ]数组一次，所以Union方法最起码要访问id[ ]数组2次。然后，Union方法在需要归并的时候，必须遍历id[ ]数组一次，所以Union方法最起码要访问id[ ]数组2+N次，其中N为id[ ]数组的大小。最后，检查id[ ]数组时，如果触点的分量需要改变时，则又需要访问id[ ]数组一次，所以还要加上1 ~ N-1次数组访问（至少有一个触点是q,一个触点是p)。综上所述，归并两个分量的Union方法访问数组的次数在N+3与2N+1之间。  \n单次调用Union方法其实我们并没有感觉该方法复杂度有多高（线性，id[ ]数组的访问为耗时单元），但是当我们具体处理问题时，比如我们用Quick-Find算法来解决之前说的动态连通性问题时，假设最后只得到了一个连通分量，那么根据上面的分析，我们**至少需要访问数组(N+3)(N+1) ~ N^2次**。因此，可以猜想，Quick-Find算法的复杂度是平方级别的（在最后得到少数连通分量的情况下，比如分析时的1条连通分量）。  \n\n可见，**Quick-Find算法的复杂度是平方级别的**，即当问题规则增长为原来的2倍时，计算所需的时间则为原来的2^2(4)倍。所以，Quick-Find算法并不是十分优秀。","source":"_posts/2014-12-07-0.md","raw":"---\ndate: 2014-12-07\nlayout: post\ntitle: 案例研究：union-find算法(二) -- quick-find算法\npermalink: '/2014/12-07-0.html'\ncategories:\n- 算法\ntags:\n- union-find\n---\n\n所谓**Quick-Find算法**，顾名思义就是Find实现是Quick版本，而相对于Union，则显得不那么Quick了。当然，这是通过结论推导原因，放在这里是十分牵强的。所以，还是正常思维，如果要实现这个功能，当然，暴力算法是不可少的。而恰巧，这个暴力算法正好就是**Quick-Find算法**。\n\n首先，我们考虑Find的实现。寻找触点p对应的分量，由于id[ ]存放着各触点对应的分量，所以简单粗暴的id[p]就是触点p对应的分量。所以，Find的实现如下：\n\n\tfunc (u *UFQuickFind) Find(p int) int {\n\t    return u.id[p]\n\t}\n\n其次，再来考虑Union的实现。由于id[ ]存放着各触点对应的分量，而Union的功能就是把触点p和触点q的分量统一，即id[p]==id[q]即可，当然，原来与p(q)处于同一分量的触点也满足上式即可。所以，具体实现可参考如下：\n\n\tfunc (u *UFQuickFind) Union(p int, q int) {\n\t    pID := u.Find(p)\n\t    qID := u.Find(q)\n\t \n\t    if pID == qID {\n\t        return\n\t    }\n\t \n\t    for i := 0; i < len(u.id); i++ {\n\t        if u.id[i] == pID {\n\t            u.id[i] = qID\n\t        }\n\t    }\n\t \n\t    u.count--\n\t}\n\n分析上述Union方法的实现，简单来说就是触点p和触点q的分量如果不统一，则遍历所有触点，将原来属于触点p的分量的所有触点，全部统一成触点q的分量，如此做法即可达到触点p和触点q的分量统一，同时原先与触点p属于相同分量的其他触点依然保持处于相同分量的条件。\n\n那么，我们来分析下Quick-Find算法是否符合我们所说的，当问题规模增大时，解决问题所花的时间是否我们依然可以接受。\n\n首先，我们来看下Find方法。Find方法的速度显然是很快的，因为它只需要访问id[ ]数组一次。  \n那么，Union方法呢。很明显，Union方法的实现并不是很理想，因为每一次调用Union方法均要遍历一次id[ ]数组。我们可以具体算一下Union方法到底访问id[ ]数组多少次。归并两个分量操作首先会调用两次Find方法，而每个Find方法都会访问id[ ]数组一次，所以Union方法最起码要访问id[ ]数组2次。然后，Union方法在需要归并的时候，必须遍历id[ ]数组一次，所以Union方法最起码要访问id[ ]数组2+N次，其中N为id[ ]数组的大小。最后，检查id[ ]数组时，如果触点的分量需要改变时，则又需要访问id[ ]数组一次，所以还要加上1 ~ N-1次数组访问（至少有一个触点是q,一个触点是p)。综上所述，归并两个分量的Union方法访问数组的次数在N+3与2N+1之间。  \n单次调用Union方法其实我们并没有感觉该方法复杂度有多高（线性，id[ ]数组的访问为耗时单元），但是当我们具体处理问题时，比如我们用Quick-Find算法来解决之前说的动态连通性问题时，假设最后只得到了一个连通分量，那么根据上面的分析，我们**至少需要访问数组(N+3)(N+1) ~ N^2次**。因此，可以猜想，Quick-Find算法的复杂度是平方级别的（在最后得到少数连通分量的情况下，比如分析时的1条连通分量）。  \n\n可见，**Quick-Find算法的复杂度是平方级别的**，即当问题规则增长为原来的2倍时，计算所需的时间则为原来的2^2(4)倍。所以，Quick-Find算法并不是十分优秀。","slug":"/2014/12-07-0.html","published":1,"updated":"2015-06-19T16:09:05.000Z","comments":1,"photos":[],"link":"","_id":"ciiwjp3020021of6g8sy0xhq9"},{"date":"2014-11-30T16:00:00.000Z","layout":"post","title":"案例研究：union-find算法(一) -- 问题","_content":"\n**问题描述**:  \n问题的输入是一列整数对，其中每个整数都表示一个某种类型的对象，一对整数p, q可以被理解为”p和q是相连的”。假设”相连”是一种等价关系，这就意味着相连满足以下3个性质： \n\n* __自反性__: p和p是相连的。 \n* __对称性__: 如果p和q是相连的，则q和p也是相连的。 \n* __传递性__: 如果p和q是相连的，而且q和r也是相连的，则p和r也是相连的。 \n\n等价关系能够将对象分为多个等价类。在这里，当且仅当两个对象相连时它们才属于同一个等价类。现在寻找这样一种解决方法，过滤序列中所有无意义的整数对，即输入整数对为p,q时，如果已知的所有整数对都不能说明p和q是相连的话，则认为p，q是不相连的，并将p，q写入到输入中，否则认为p，q已经是相连的，应该抛弃这个整数对。 \n\n**问题解法**:  \n当然，这个问题如果用在问题规则增大的情况下，想要快速实现这个功能将会愈发困难，所以需要某种算法，将问题简单化，即使在问题规则增大的时候，在可接受的时间范围内等到结果。 \n\n就目前对问题的描述，由于没有具体业务的渗入，所以我们将以网络方面的术语对问题相关变量进行命名。这里，我们将对象称之为**触点**，将整数对称为**连接**，而将等价类称为连通分量，简称**分量**。 \n\n**众所周知，数据结构的性质将直接影响到算法的效率**。所以我们用int类型的数组id[ ]直接表示所有对象它所在的分量值，如id\\[i\\](假设其值为I)表示对象i所在的分量值为I。因此，我们可以这样定义保存必要信息的struct: \n\n    type UF struct {\n        id    []int     //  各触点包含分量信息 \n        count int       //  包含分量总数\n    }\n\n当然，接口也可以事先定义： \n\n    type UFI interface {\n        Init(n int)                         // 初始化\n        Union(p int, q int)                 // 连通触点p和q\n        Find(p int) int                     // 寻找触点p对应的分量\n        Connected(find func(int)int, p int, q int) bool         \n                                            // 检查触点p和q是否连通\n        Count() int                         // 分量总数\n    }\n\n首先，我们假设一开始有N个触点，每个触点都构成了一个只包含有它自己的分量，因此可以将id[i]的值初始化为i，具体Init方法如下： \n\n    func (u *UF) Init(n int) {\n        u.count = n\n        u.id = make([]int, 0, n)\n        for i := 0; i < n; i++ {\n            u.id = append(u.id, i)\n        }\n    }\n\n当然，返回当前分量总数和检查触点是否连通都比较直接，如下： \n\n    func (u *UF) Count() int {\n        return u.count\n    }\n     \n    func (u *UF) Connected(find func(int)int, p int, q int) bool {\n        return find(p) == find(q)\n    }\n\n那么, 具体算法事实上就是剩下两个接口，即Union和Find的不同实现了。 \n\n下面就是Union和Find不同实现产生的几种不同算法：  \n1. [Quick-Find算法](https://zhujiefirst.github.io/2014/12-07-0.html)  \n2. [Quick-Union算法](https://zhujiefirst.github.io/2014/12-08-0.html)    \n3. [加权Quick-Union算法](https://zhujiefirst.github.io/2014/12-12-0.html)  ","source":"_posts/2014-12-01-0.md","raw":"---\ndate: 2014-12-01\nlayout: post\ntitle: 案例研究：union-find算法(一) -- 问题\npermalink: '/2014/12-01-0.html'\ncategories:\n- 算法\ntags:\n- union-find\n---\n\n**问题描述**:  \n问题的输入是一列整数对，其中每个整数都表示一个某种类型的对象，一对整数p, q可以被理解为”p和q是相连的”。假设”相连”是一种等价关系，这就意味着相连满足以下3个性质： \n\n* __自反性__: p和p是相连的。 \n* __对称性__: 如果p和q是相连的，则q和p也是相连的。 \n* __传递性__: 如果p和q是相连的，而且q和r也是相连的，则p和r也是相连的。 \n\n等价关系能够将对象分为多个等价类。在这里，当且仅当两个对象相连时它们才属于同一个等价类。现在寻找这样一种解决方法，过滤序列中所有无意义的整数对，即输入整数对为p,q时，如果已知的所有整数对都不能说明p和q是相连的话，则认为p，q是不相连的，并将p，q写入到输入中，否则认为p，q已经是相连的，应该抛弃这个整数对。 \n\n**问题解法**:  \n当然，这个问题如果用在问题规则增大的情况下，想要快速实现这个功能将会愈发困难，所以需要某种算法，将问题简单化，即使在问题规则增大的时候，在可接受的时间范围内等到结果。 \n\n就目前对问题的描述，由于没有具体业务的渗入，所以我们将以网络方面的术语对问题相关变量进行命名。这里，我们将对象称之为**触点**，将整数对称为**连接**，而将等价类称为连通分量，简称**分量**。 \n\n**众所周知，数据结构的性质将直接影响到算法的效率**。所以我们用int类型的数组id[ ]直接表示所有对象它所在的分量值，如id\\[i\\](假设其值为I)表示对象i所在的分量值为I。因此，我们可以这样定义保存必要信息的struct: \n\n    type UF struct {\n        id    []int     //  各触点包含分量信息 \n        count int       //  包含分量总数\n    }\n\n当然，接口也可以事先定义： \n\n    type UFI interface {\n        Init(n int)                         // 初始化\n        Union(p int, q int)                 // 连通触点p和q\n        Find(p int) int                     // 寻找触点p对应的分量\n        Connected(find func(int)int, p int, q int) bool         \n                                            // 检查触点p和q是否连通\n        Count() int                         // 分量总数\n    }\n\n首先，我们假设一开始有N个触点，每个触点都构成了一个只包含有它自己的分量，因此可以将id[i]的值初始化为i，具体Init方法如下： \n\n    func (u *UF) Init(n int) {\n        u.count = n\n        u.id = make([]int, 0, n)\n        for i := 0; i < n; i++ {\n            u.id = append(u.id, i)\n        }\n    }\n\n当然，返回当前分量总数和检查触点是否连通都比较直接，如下： \n\n    func (u *UF) Count() int {\n        return u.count\n    }\n     \n    func (u *UF) Connected(find func(int)int, p int, q int) bool {\n        return find(p) == find(q)\n    }\n\n那么, 具体算法事实上就是剩下两个接口，即Union和Find的不同实现了。 \n\n下面就是Union和Find不同实现产生的几种不同算法：  \n1. [Quick-Find算法](https://zhujiefirst.github.io/2014/12-07-0.html)  \n2. [Quick-Union算法](https://zhujiefirst.github.io/2014/12-08-0.html)    \n3. [加权Quick-Union算法](https://zhujiefirst.github.io/2014/12-12-0.html)  ","slug":"/2014/12-01-0.html","published":1,"updated":"2015-06-19T16:09:05.000Z","comments":1,"photos":[],"link":"","_id":"ciiwjp3040024of6g8sthtsii"},{"date":"2014-11-19T16:00:00.000Z","layout":"post","title":"Golang性能分析工具","_content":"\n\n作为一名合格的开发人员，对自己开发程序的性能分析是必不可少的技能。c++可以采用gperftools进行性能分析，那么go呢？是否也有同样逼格的工具？当当当当~当然有，她就是pprof!\n\npprof是go自带的性能分析工具，当然她优雅，美丽，易操作。see~\n\n\tpackage main\n\t \n\timport (\n\t    \"os\"\n\t    \"runtime/pprof\"\n\t)\n\t \n\tfunc main() {\n\t    f, _ := os.Create(\"profile_file\")\n\t    pprof.StartCPUProfile(f)     // 开始cpu profile，结果写到文件f中\n\t    defer pprof.StopCPUProfile() // 结束profile\n\t \n\t    doSomething();\n\t}\n\n上述程序具体鄙人就不解释了。运行app，生成profile_file文件，直接采用go tool pprof进行分析。\n\n更多信息，可以参见[go官方文档](http://golang.org/pkg/net/http/pprof/)。","source":"_posts/2014-11-20-0.md","raw":"---\ndate: 2014-11-20\nlayout: post\ntitle: Golang性能分析工具\npermalink: '/2014/11-20-0.html'\ncategories:\n- golang\ntags:\n- 性能\n- pprof\n---\n\n\n作为一名合格的开发人员，对自己开发程序的性能分析是必不可少的技能。c++可以采用gperftools进行性能分析，那么go呢？是否也有同样逼格的工具？当当当当~当然有，她就是pprof!\n\npprof是go自带的性能分析工具，当然她优雅，美丽，易操作。see~\n\n\tpackage main\n\t \n\timport (\n\t    \"os\"\n\t    \"runtime/pprof\"\n\t)\n\t \n\tfunc main() {\n\t    f, _ := os.Create(\"profile_file\")\n\t    pprof.StartCPUProfile(f)     // 开始cpu profile，结果写到文件f中\n\t    defer pprof.StopCPUProfile() // 结束profile\n\t \n\t    doSomething();\n\t}\n\n上述程序具体鄙人就不解释了。运行app，生成profile_file文件，直接采用go tool pprof进行分析。\n\n更多信息，可以参见[go官方文档](http://golang.org/pkg/net/http/pprof/)。","slug":"/2014/11-20-0.html","published":1,"updated":"2015-06-19T16:09:05.000Z","comments":1,"photos":[],"link":"","_id":"ciiwjp3060027of6gr8i4ds8t"},{"date":"2014-11-17T16:00:00.000Z","layout":"post","title":"投掷色子10次，所投点数总数为50点的可能性是多少种","_content":"\n\n\n**问**：投掷色子10次，所投点数总数为50点的可能性是多少种？\n\n这是道经典的面试问题，当然，面试时可能让你编程实现，也可能用数学知识做答。这里我们就从这两方面分别解析下如何破题。\n\n**一、编程实现**  \n事实上，编程解决这题目着实不麻烦。首先我们定义一个过程f(x,y)表示投掷色子x次，所投点数为y点的可能性种数。分析投色子的过程，由于投掷一次色子可能的点数为1~6点,不难发现如下公式：\n\n\tf(x,y)=f(x-1,y-1)+f(x-1,y-2)+f(x-1,y-3)+f(x-1,y-4)+f(x-1,y-5)+f(x-1,y-6)\n\n而f(x,y)在当6*xy时，值为0，当6*x=y时，值为1，当x=y时，值为1。\n到这里，其实已经可以用递归解决这个问题了，代码如下：\n\n\t// 投times次数色子，得到points点数，有多少种可能投法\n\tfunc ThrowDice(times int, points int) int {\n\t    if times*MaxPoint < points {\n\t        return 0\n\t    }\n\t    if times*MaxPoint == points {\n\t        return 1\n\t    }\n\t    if times*MinPoint > points {\n\t        return 0\n\t    }\n\t    if times*MinPoint == points {\n\t        return 1\n\t    }\n\t    if times == 1 {\n\t        return 1\n\t    }\n\t    nextTimes := times - 1\n\t    return ThrowDice(nextTimes, points-OnePoint) + ThrowDice(nextTimes, points-TwoPoint) + ThrowDice(nextTimes, points-ThreePoint) + ThrowDice(nextTimes, points-FourPoint) + ThrowDice(nextTimes, points-FivePoint) + ThrowDice(nextTimes, points-SixPoint)\n\t}\n\n**二、数学实现**  \n这个问题的数学解法事实上用组合数学的知识很容易解决。\n\n首先，投一次色子的过程我们可以用一多项式表示：**x+x^2+x^3+x^4+x^5+x^6**,具体各项的系数为投掷的可能种类数，如上述多项式中x^5表示投掷一次色子，得到点数为5的可能种类数为1。\n\n既然有这种表示方法，原来投掷10次色子的问题用多项式表示如下：**(x+x^2+x^3+x^4+x^5+x^6)^10**。 原来问题的解即为多项式中x^50的系数。当然，这个多项式可以用数学公式解出来，我们就直接用python的sympy库计算，得出解为85225次。  ","source":"_posts/2014-11-18-0.md","raw":"---\ndate: 2014-11-18\nlayout: post\ntitle: 投掷色子10次，所投点数总数为50点的可能性是多少种\npermalink: '/2014/11-18-0.html'\ncategories:\n- 算法\ntags:\n- 面试题\n---\n\n\n\n**问**：投掷色子10次，所投点数总数为50点的可能性是多少种？\n\n这是道经典的面试问题，当然，面试时可能让你编程实现，也可能用数学知识做答。这里我们就从这两方面分别解析下如何破题。\n\n**一、编程实现**  \n事实上，编程解决这题目着实不麻烦。首先我们定义一个过程f(x,y)表示投掷色子x次，所投点数为y点的可能性种数。分析投色子的过程，由于投掷一次色子可能的点数为1~6点,不难发现如下公式：\n\n\tf(x,y)=f(x-1,y-1)+f(x-1,y-2)+f(x-1,y-3)+f(x-1,y-4)+f(x-1,y-5)+f(x-1,y-6)\n\n而f(x,y)在当6*xy时，值为0，当6*x=y时，值为1，当x=y时，值为1。\n到这里，其实已经可以用递归解决这个问题了，代码如下：\n\n\t// 投times次数色子，得到points点数，有多少种可能投法\n\tfunc ThrowDice(times int, points int) int {\n\t    if times*MaxPoint < points {\n\t        return 0\n\t    }\n\t    if times*MaxPoint == points {\n\t        return 1\n\t    }\n\t    if times*MinPoint > points {\n\t        return 0\n\t    }\n\t    if times*MinPoint == points {\n\t        return 1\n\t    }\n\t    if times == 1 {\n\t        return 1\n\t    }\n\t    nextTimes := times - 1\n\t    return ThrowDice(nextTimes, points-OnePoint) + ThrowDice(nextTimes, points-TwoPoint) + ThrowDice(nextTimes, points-ThreePoint) + ThrowDice(nextTimes, points-FourPoint) + ThrowDice(nextTimes, points-FivePoint) + ThrowDice(nextTimes, points-SixPoint)\n\t}\n\n**二、数学实现**  \n这个问题的数学解法事实上用组合数学的知识很容易解决。\n\n首先，投一次色子的过程我们可以用一多项式表示：**x+x^2+x^3+x^4+x^5+x^6**,具体各项的系数为投掷的可能种类数，如上述多项式中x^5表示投掷一次色子，得到点数为5的可能种类数为1。\n\n既然有这种表示方法，原来投掷10次色子的问题用多项式表示如下：**(x+x^2+x^3+x^4+x^5+x^6)^10**。 原来问题的解即为多项式中x^50的系数。当然，这个多项式可以用数学公式解出来，我们就直接用python的sympy库计算，得出解为85225次。  ","slug":"/2014/11-18-0.html","published":1,"updated":"2015-06-19T16:09:05.000Z","comments":1,"photos":[],"link":"","_id":"ciiwjp309002dof6gimnfu2uq"},{"date":"2014-11-15T16:00:00.000Z","layout":"post","title":"如何生成不重复随机数","_content":"\n\n如何生成不重复随机数？\n\n当然，简单粗暴的方法永远是可行的。生成一个随机数，在已生成的随机数中遍历，若未在其中，则归入随机数数组中，否则重新生成一随机数再重复此过程。\n\n具体代码可参照如下：\n\n\tN = 10\n\tna := make([]int32, 0, N)\n\tfor {\n\t    n := rand.Int31()\n\t    for _, v := range na {\n\t        if n == v {\n\t            continue\n\t        }\n\t    }\n\t    na = append(na, n)\n\t    if len(na) == N {\n\t        break\n\t    }\n\t}\n\tlog.Println(na)\n\n当然，这个方法很很黄很暴力。首先，此方法复杂度为N^2,在生成随机数量较小的情况下还可以接受，但随着问题规模的增大，此法顿时露出其狰狞的面孔，指数复杂度可不是盖的。其次，此法有个极端情况，那就是若每次生成的随机数都在之前的生成数组中，那不是个死循环。oh,no.\n\n那么没有其他方法了吗？额，可以牺牲空间来实现这个功能。首先，预先生成好所有随机数的可能范围，然后再每次随机一个数，取该数所指的位置的数将其做为新生成的数, 最后将该位置的数删除以确保取到不重复的随机数。代码如下：\n\n\tN = 10\n\tna := make([]int, 0, N)\n\tpna := make([]int, 0, 2*N)\n\tfor i := 0; i < 2*N; i++ {\n\t    pna = append(pna, i)\n\t}\n\tfor i := 0; i < N; i++ {\n\t    p := rand.Intn(2*N - i)\n\t    na = append(na, pna[p])\n\t    pna = append(pna[:p], pna[p+1:]...)\n\t}\n\tlog.Println(na)\n\n这里，我们用slice存放预先生成的数，事实上存在一定的性能问题。slice的随机读虽然性能比较高，但是从slice中删除元素性能就不太理想了。如果想解决删除元素的性能问题，我们可以采用list代替slice,上述代码转换成如下：\n\n\tN = 10\n\tna := make([]int, 0, N)\n\tpna := list.New()\n\tfor i := 0; i < 2*N; i++ {\n\t    pna.PushBack(i)\n\t}\n\tfor i := 0; i < N; i++ {\n\t    p := rand.Intn(2*N - i)\n\t    na = append(na, func(l *list.List, pos int) int {\n\t        e := l.Front()\n\t        for j := 0; j < pos; j++ {\n\t            e = e.Next()\n\t        }\n\t        l.Remove(e)\n\t        return e.Value.(int)\n\t    }(pna, p))\n\t}\n\tlog.Println(na)\n\n但是，删除元素的性能问题虽然已经解决，但是list的随机读性能便成大问题了。所以上述方法并没有解决根本问题。\n\n让我们想想，既然slice的随机读性能高，但是删除元素性能不理想，索性我们就不删除元素，只是将其移动至最后，将其排除在下一轮随机选择之外，代码如下：\n\n\tN = 10\n\tna := make([]int, 0, N)\n\tpna := make([]int, 0, 2*N)\n\tfor i := 0; i < 2*N; i++ {\n\t    pna = append(pna, i)\n\t}\n\tfor i := 0; i < N; i++ {\n\t    p := rand.Intn(2*N - i)\n\t    na = append(na, pna[p])\n\t    pna[p], pna[2*N-i-1] = pna[2*N-i-1], pna[p]\n\t}\n\tlog.Println(na)\n\n至此，我们得到了一个牺牲空间，但是性能上可接受，在最坏情况下又不会进入死循环的无重复随机数生成方法。以上4种方法具体性能如下（仅供参考）:\n\n\tforceMethod:94.0661ms\n\tarrayMethod:42.0317ms\n\tlistMethod:302.211ms\n\tbetterMethod:1.0043ms\n","source":"_posts/2014-11-16-0.md","raw":"---\ndate: 2014-11-16\nlayout: post\ntitle: 如何生成不重复随机数\npermalink: '/2014/11-16-0.html'\ncategories:\n- 算法\ntags:\n- 面试题\n---\n\n\n如何生成不重复随机数？\n\n当然，简单粗暴的方法永远是可行的。生成一个随机数，在已生成的随机数中遍历，若未在其中，则归入随机数数组中，否则重新生成一随机数再重复此过程。\n\n具体代码可参照如下：\n\n\tN = 10\n\tna := make([]int32, 0, N)\n\tfor {\n\t    n := rand.Int31()\n\t    for _, v := range na {\n\t        if n == v {\n\t            continue\n\t        }\n\t    }\n\t    na = append(na, n)\n\t    if len(na) == N {\n\t        break\n\t    }\n\t}\n\tlog.Println(na)\n\n当然，这个方法很很黄很暴力。首先，此方法复杂度为N^2,在生成随机数量较小的情况下还可以接受，但随着问题规模的增大，此法顿时露出其狰狞的面孔，指数复杂度可不是盖的。其次，此法有个极端情况，那就是若每次生成的随机数都在之前的生成数组中，那不是个死循环。oh,no.\n\n那么没有其他方法了吗？额，可以牺牲空间来实现这个功能。首先，预先生成好所有随机数的可能范围，然后再每次随机一个数，取该数所指的位置的数将其做为新生成的数, 最后将该位置的数删除以确保取到不重复的随机数。代码如下：\n\n\tN = 10\n\tna := make([]int, 0, N)\n\tpna := make([]int, 0, 2*N)\n\tfor i := 0; i < 2*N; i++ {\n\t    pna = append(pna, i)\n\t}\n\tfor i := 0; i < N; i++ {\n\t    p := rand.Intn(2*N - i)\n\t    na = append(na, pna[p])\n\t    pna = append(pna[:p], pna[p+1:]...)\n\t}\n\tlog.Println(na)\n\n这里，我们用slice存放预先生成的数，事实上存在一定的性能问题。slice的随机读虽然性能比较高，但是从slice中删除元素性能就不太理想了。如果想解决删除元素的性能问题，我们可以采用list代替slice,上述代码转换成如下：\n\n\tN = 10\n\tna := make([]int, 0, N)\n\tpna := list.New()\n\tfor i := 0; i < 2*N; i++ {\n\t    pna.PushBack(i)\n\t}\n\tfor i := 0; i < N; i++ {\n\t    p := rand.Intn(2*N - i)\n\t    na = append(na, func(l *list.List, pos int) int {\n\t        e := l.Front()\n\t        for j := 0; j < pos; j++ {\n\t            e = e.Next()\n\t        }\n\t        l.Remove(e)\n\t        return e.Value.(int)\n\t    }(pna, p))\n\t}\n\tlog.Println(na)\n\n但是，删除元素的性能问题虽然已经解决，但是list的随机读性能便成大问题了。所以上述方法并没有解决根本问题。\n\n让我们想想，既然slice的随机读性能高，但是删除元素性能不理想，索性我们就不删除元素，只是将其移动至最后，将其排除在下一轮随机选择之外，代码如下：\n\n\tN = 10\n\tna := make([]int, 0, N)\n\tpna := make([]int, 0, 2*N)\n\tfor i := 0; i < 2*N; i++ {\n\t    pna = append(pna, i)\n\t}\n\tfor i := 0; i < N; i++ {\n\t    p := rand.Intn(2*N - i)\n\t    na = append(na, pna[p])\n\t    pna[p], pna[2*N-i-1] = pna[2*N-i-1], pna[p]\n\t}\n\tlog.Println(na)\n\n至此，我们得到了一个牺牲空间，但是性能上可接受，在最坏情况下又不会进入死循环的无重复随机数生成方法。以上4种方法具体性能如下（仅供参考）:\n\n\tforceMethod:94.0661ms\n\tarrayMethod:42.0317ms\n\tlistMethod:302.211ms\n\tbetterMethod:1.0043ms\n","slug":"/2014/11-16-0.html","published":1,"updated":"2015-06-19T16:09:05.000Z","comments":1,"photos":[],"link":"","_id":"ciiwjp30c002hof6gvftwcuww"},{"date":"2014-11-13T16:00:00.000Z","layout":"post","title":"Go中实现Set类型","_content":"\n\n这几天用go实现项目原有的xml数据导入服务器新设计的数据库中，以实现数据从客户机向服务器的转移。由于服务器的接口协议为json,所以面临的问题就是从xml解析出相应的struct，并将其转换为json。在这个过程中，go中xml与json库就不得不赞一下了。\n\n只需简单的定义struct的结构，并用相应的标签表示xml或者json中的字段名称即可，编码方便性不言而喻。具体定义可以参见如下：\n\n\ttype XmlSample struct {\n\t    A int `xml:\"AField\"`\n\t    B string `xml:\"BField\"`\n\t}\n\n\ttype JsonSample struct {\n\t    A int `json:\"AField\"`\n\t    B string `json:\"BField\"`\n\t}\n\n那么这个和“go中如何实现set”有半毛钱关系？是没有关系，鄙人好闲扯。那么，再来看下go中如何实现set。\n\n起因是这样的：某天，鄙人欲实现一不重复随机数生成器，即将产生的随机数放入set中，如何可保证产生的随机数的唯一性。但是，鄙人发现go中没有set这样的container！这可怎么破？只能自己实现个了。既然go中有map,索性基于map实现个吧。纳尼？map是map,如何将其转成set!哈哈，map中的keys不是需要保证其唯一性么，我们只是利用map中keys而已。\n\n首先我们定义一个struct，以存放set中元素，定义如下：\n\n\ttype Set struct {\n\t    set map[interface{}]struct{}\n\t}\n\nmap[interface{}]struct{}中keys的类型比较容易理解，因为set要适合所有类型元素，所以interface{}类型最为合适。但是values的类型是个什么东东？可以是个简单的bool型么，或者int型也可以嘛。是的，values的具体类型当然可以是bool,int，如果想作孽，可以定义成map[stirng]string也可，但是为什么要选择struct{}呢？嗯，原因么，因为鄙人在google group上看到说,struct{}可以占有较少的空间（其实是不占空间，具体鄙人才疏学浅，未能得证），所以采用以上定义方法。\n\n如此一定义，便可亮出Set可以接收的方法，无非是InSet(), Insert(), Size(), Clear()这几样，如下：\n\n\tfunc (s *Set) InSet(e interface{}) bool {\n\t    _, ok := s.set[e]\n\t    return ok\n\t}\n\n\tfunc (s *Set) Insert(e interface{}) bool {\n\t    in := s.InSet(e)\n\t    s.set[e] = struct{}{}\n\t    return in\n\t}\n\n\tfunc (s *Set) Clear() {\n\t    s.set = make(map[interface{}]Struct{})\n\t}\n\n\tfunc (s *Set) Size() int {\n\t    return len(s.set)\n\t}\n\n额，好像还少了点东西。怎么遍历元素呢？当然，我是指不暴露其内部实现的遍历。go中range又只能支持slice,map,chan。那么，再增加个方法，将内部set返回，如下：\n\n\tfunc (s *Set) Range() map[interface{}]struct{}{\n\t    return s.set\n\t}\n\nSet需要遍历时，只需for i, v := range s.Range()即可。嗯，不是说不暴露其内部实现么，Range方法一出，看返回值大家都知道啦。额，鄙人未曾想到更甚的方法，暂时就这样吧。\n\nBTW, 这述代码中可以将struct{}先type成自定义None类型，这样代码就更具体美感了。嘿嘿。","source":"_posts/2014-11-14-0.md","raw":"---\ndate: 2014-11-14\nlayout: post\ntitle: Go中实现Set类型\npermalink: '/2014/11-14-0.html'\ncategories:\n- golang\ntags:\n- 小技巧\n---\n\n\n这几天用go实现项目原有的xml数据导入服务器新设计的数据库中，以实现数据从客户机向服务器的转移。由于服务器的接口协议为json,所以面临的问题就是从xml解析出相应的struct，并将其转换为json。在这个过程中，go中xml与json库就不得不赞一下了。\n\n只需简单的定义struct的结构，并用相应的标签表示xml或者json中的字段名称即可，编码方便性不言而喻。具体定义可以参见如下：\n\n\ttype XmlSample struct {\n\t    A int `xml:\"AField\"`\n\t    B string `xml:\"BField\"`\n\t}\n\n\ttype JsonSample struct {\n\t    A int `json:\"AField\"`\n\t    B string `json:\"BField\"`\n\t}\n\n那么这个和“go中如何实现set”有半毛钱关系？是没有关系，鄙人好闲扯。那么，再来看下go中如何实现set。\n\n起因是这样的：某天，鄙人欲实现一不重复随机数生成器，即将产生的随机数放入set中，如何可保证产生的随机数的唯一性。但是，鄙人发现go中没有set这样的container！这可怎么破？只能自己实现个了。既然go中有map,索性基于map实现个吧。纳尼？map是map,如何将其转成set!哈哈，map中的keys不是需要保证其唯一性么，我们只是利用map中keys而已。\n\n首先我们定义一个struct，以存放set中元素，定义如下：\n\n\ttype Set struct {\n\t    set map[interface{}]struct{}\n\t}\n\nmap[interface{}]struct{}中keys的类型比较容易理解，因为set要适合所有类型元素，所以interface{}类型最为合适。但是values的类型是个什么东东？可以是个简单的bool型么，或者int型也可以嘛。是的，values的具体类型当然可以是bool,int，如果想作孽，可以定义成map[stirng]string也可，但是为什么要选择struct{}呢？嗯，原因么，因为鄙人在google group上看到说,struct{}可以占有较少的空间（其实是不占空间，具体鄙人才疏学浅，未能得证），所以采用以上定义方法。\n\n如此一定义，便可亮出Set可以接收的方法，无非是InSet(), Insert(), Size(), Clear()这几样，如下：\n\n\tfunc (s *Set) InSet(e interface{}) bool {\n\t    _, ok := s.set[e]\n\t    return ok\n\t}\n\n\tfunc (s *Set) Insert(e interface{}) bool {\n\t    in := s.InSet(e)\n\t    s.set[e] = struct{}{}\n\t    return in\n\t}\n\n\tfunc (s *Set) Clear() {\n\t    s.set = make(map[interface{}]Struct{})\n\t}\n\n\tfunc (s *Set) Size() int {\n\t    return len(s.set)\n\t}\n\n额，好像还少了点东西。怎么遍历元素呢？当然，我是指不暴露其内部实现的遍历。go中range又只能支持slice,map,chan。那么，再增加个方法，将内部set返回，如下：\n\n\tfunc (s *Set) Range() map[interface{}]struct{}{\n\t    return s.set\n\t}\n\nSet需要遍历时，只需for i, v := range s.Range()即可。嗯，不是说不暴露其内部实现么，Range方法一出，看返回值大家都知道啦。额，鄙人未曾想到更甚的方法，暂时就这样吧。\n\nBTW, 这述代码中可以将struct{}先type成自定义None类型，这样代码就更具体美感了。嘿嘿。","slug":"/2014/11-14-0.html","published":1,"updated":"2015-06-19T16:09:05.000Z","comments":1,"photos":[],"link":"","_id":"ciiwjp30e002kof6g4hzf3wdl"},{"date":"2014-08-08T16:00:00.000Z","layout":"post","title":"编程语言的发展之路 — 读《代码的未来》","_content":"\n\n本书是Matz在《日经Linux》上连载的各期内容的合集，虽然内容有些部分重复，但是内容还是很丰富的，主题也比较鲜明，与国内的某些合集甩开太远。    \n\n通书下来，个人觉得最精华的还是第2章：编程语言的过去、现在和未来。Matz通过简单回顾编程语言的过去，着重分析现在和未来的发展。主要分为以下几类：**DSL，meta-programming，内存管理，异常处理，闭包**。     \n\n**DSL**，即特定领域语言，将几乎只有程序员的编程语言进化成符合具体领域业务的特定语言，而且该语言与自然语言类似，方便非编程人员也可用其进行编程，可以解决开发人员对业务透视程度不够，业务人员无能力进行编码的矛盾。回想还在前东家码程序时，由于是游戏工作室，经常出现小工具方便策划实现自己的想法，这几乎是与DSL方向不谋而合。做为攻城师，如何把自己从代码中解放出来，如何让非编程人员方便的进行编程工作也是一种能力啊。  \n\n**元编程**，即可以自己写程序的程序。身为苦逼码农，还记得需求一日一变的痛若吗？还记得数据库迁移时，代码大动的尴尬吗？请用元编程利器，让你一劳永逸，面对千变万化，不动任何代码就是完善支持。善哉，这才是程序员的理想生活。当然，元编程并不是所有语言都支持，当然上古语言Lisp可以说是其始祖，但是便于理解，还是举个Ruby的例子，如下：\n\n\trequire 'builder'\n\tbuilder = Builder::XmlMarkup.new\n\txml = builder.person { |b| \n\t     b.name(\"Jay\") \n\t     b.phone(\"123-123321\") \n\t} \n\t#=> <person><name>Jay</name><phone>123-123321</phone></person> \n\n代码中对person, name, phone标签是用方法调用实现的，但这些方法并不是Builder库所定义的。因为XML中的标签是任意定义的，不可能在Builder库中事先全部准备好所有方法，所以这就是元编程的力量。若要增加home标签，无须动Builder库的任何代码，只需直接调用home方法即可。完美生活啊。  \n\n**内存管理**。说到这个，不得不提业务说c/c++是如何难用，很大一部分是由于要开发者进行内存管理。虽然现代c++语言经过一定的封装可以做到不用自己进行内存管理，但是曾经坑害多少无知码农的阴影是不会这么轻易散去。所以，垃圾回收，将内存管理从程序员手上释放出来是巨大的福利。  \n\n**异常处理**。C代码中对各种异常返回值的判断，往往在程序中占有很大的比例，如下：  \n\n\tint main() \n\t{ \n\t     FILE* f = open(\"/path/to/file\"); \n\t     if (f == NULL) { \n\t        puts(\"file open failed\"); \n\t     } else { \n\t        puts(\"file open succeeded\"); \n\t    } \n\t    f.close(); \n\t    return 0; \n\t} \n\n当然，这里只是举个简单的例子，现实情况比这个糟糕太多。写一个并不复杂的业务，假设只需要10行代码，但是对异常情况的判断并且处理，往往占据了大量的代码量，也许从开始的10行渐渐臃肿到了100行。这不仅对编码人员造成了大量的工作量，而且对维护人员进行代码学习也是一种负担。若采用异常机制，很容量让编码人员只关注重要的逻辑，而不用一头淹没在异常处理代码中。上文的例子，同样实现一个Ruby版本：  \n\n\tbegin\n\t    open(\"path/to/file\", \"r\") do |f| \n\t    puts\"file open succeed\"\n\tend\n\trescue\n\t    puts\"file open failed\"\n\tend\n\t\n**闭包**，含有“包含”的意思。如其名称，闭包就是将数据包含在函数内，与面向对象正好相反，面向对象是将数据的行为包含在数据内。对于闭包，我目前还没有体会到其带来的好处，当然是巨大的好处，值得做为编程语言未来发展的方法的好处，所以就先搁着，等到感受到其巨大力量再来补上。  ","source":"_posts/2014-08-09-2.md","raw":"---\ndate: 2014-08-09\nlayout: post\ntitle: 编程语言的发展之路 — 读《代码的未来》\npermalink: '/2014/08-09-2.html'\ncategories: 编程思维\ntags:\n- 元编程\n- 内存管理\n---\n\n\n本书是Matz在《日经Linux》上连载的各期内容的合集，虽然内容有些部分重复，但是内容还是很丰富的，主题也比较鲜明，与国内的某些合集甩开太远。    \n\n通书下来，个人觉得最精华的还是第2章：编程语言的过去、现在和未来。Matz通过简单回顾编程语言的过去，着重分析现在和未来的发展。主要分为以下几类：**DSL，meta-programming，内存管理，异常处理，闭包**。     \n\n**DSL**，即特定领域语言，将几乎只有程序员的编程语言进化成符合具体领域业务的特定语言，而且该语言与自然语言类似，方便非编程人员也可用其进行编程，可以解决开发人员对业务透视程度不够，业务人员无能力进行编码的矛盾。回想还在前东家码程序时，由于是游戏工作室，经常出现小工具方便策划实现自己的想法，这几乎是与DSL方向不谋而合。做为攻城师，如何把自己从代码中解放出来，如何让非编程人员方便的进行编程工作也是一种能力啊。  \n\n**元编程**，即可以自己写程序的程序。身为苦逼码农，还记得需求一日一变的痛若吗？还记得数据库迁移时，代码大动的尴尬吗？请用元编程利器，让你一劳永逸，面对千变万化，不动任何代码就是完善支持。善哉，这才是程序员的理想生活。当然，元编程并不是所有语言都支持，当然上古语言Lisp可以说是其始祖，但是便于理解，还是举个Ruby的例子，如下：\n\n\trequire 'builder'\n\tbuilder = Builder::XmlMarkup.new\n\txml = builder.person { |b| \n\t     b.name(\"Jay\") \n\t     b.phone(\"123-123321\") \n\t} \n\t#=> <person><name>Jay</name><phone>123-123321</phone></person> \n\n代码中对person, name, phone标签是用方法调用实现的，但这些方法并不是Builder库所定义的。因为XML中的标签是任意定义的，不可能在Builder库中事先全部准备好所有方法，所以这就是元编程的力量。若要增加home标签，无须动Builder库的任何代码，只需直接调用home方法即可。完美生活啊。  \n\n**内存管理**。说到这个，不得不提业务说c/c++是如何难用，很大一部分是由于要开发者进行内存管理。虽然现代c++语言经过一定的封装可以做到不用自己进行内存管理，但是曾经坑害多少无知码农的阴影是不会这么轻易散去。所以，垃圾回收，将内存管理从程序员手上释放出来是巨大的福利。  \n\n**异常处理**。C代码中对各种异常返回值的判断，往往在程序中占有很大的比例，如下：  \n\n\tint main() \n\t{ \n\t     FILE* f = open(\"/path/to/file\"); \n\t     if (f == NULL) { \n\t        puts(\"file open failed\"); \n\t     } else { \n\t        puts(\"file open succeeded\"); \n\t    } \n\t    f.close(); \n\t    return 0; \n\t} \n\n当然，这里只是举个简单的例子，现实情况比这个糟糕太多。写一个并不复杂的业务，假设只需要10行代码，但是对异常情况的判断并且处理，往往占据了大量的代码量，也许从开始的10行渐渐臃肿到了100行。这不仅对编码人员造成了大量的工作量，而且对维护人员进行代码学习也是一种负担。若采用异常机制，很容量让编码人员只关注重要的逻辑，而不用一头淹没在异常处理代码中。上文的例子，同样实现一个Ruby版本：  \n\n\tbegin\n\t    open(\"path/to/file\", \"r\") do |f| \n\t    puts\"file open succeed\"\n\tend\n\trescue\n\t    puts\"file open failed\"\n\tend\n\t\n**闭包**，含有“包含”的意思。如其名称，闭包就是将数据包含在函数内，与面向对象正好相反，面向对象是将数据的行为包含在数据内。对于闭包，我目前还没有体会到其带来的好处，当然是巨大的好处，值得做为编程语言未来发展的方法的好处，所以就先搁着，等到感受到其巨大力量再来补上。  ","slug":"/2014/08-09-2.html","published":1,"updated":"2015-06-19T16:09:05.000Z","comments":1,"photos":[],"link":"","_id":"ciiwjp30h002oof6gmfa99n4w"},{"date":"2014-08-08T16:00:00.000Z","layout":"post","title":"如何用lua实现面向对象","_content":"\n\nlua作为一门非面向对象的轻量级语言，如何才能方便的用面向对象的方法来进行编程呢？\n\n首先,编程范型对面向对象编程（OOP）是如何定义的呢？**通常，OOP被理解为一种将程序分解为封装数据及相关操作的模块而进行的编程方式**。有别于其他编程方式，OOP中的与某些数据类型相关的一系列操作都被有机地封装到该数据类型当中，而非散放于其外，因而**OPP中的数据类型不仅有着状态，还有着相关的操作**。（来自wikipedia）\n\n以一言蔽之，就是数据中包含对数据的操作行为。如此甚好，在lua中只要有**强力类型table**即实现了。\n\n    -- 定义table类型\n    point = { }\n     \n    -- 在table中增加x, y两个数据\n    point.x = 3\n    point.y = 4\n     \n    -- 在table中增加magnitude方法\n    point.magnitude = function ()\n        return math.sqrt(point.x^2 + point.y^2)\n    end\n     \n    -- 调用point中方法处理数据\n    print(point.magnitude())\n\n确实，数据的行为被封装在table类型point中了，但是，这看上去也太不专业了，我们不能这么没追求是吧。而且，继承呢，多态呢？完全没有面向对象的影子嘛。模仿也要有模仿的样子嘛。\n\n当然，这并不是我们可以接受的版本。在讲解可用版本之前，先来解释下lua中的一大利器–metatable。先来看其官方定义：**metatable用来定义原始值在特定操作下的行为**。你可以通过在metatable中的特定域设一值来改变拥有这个metatable的值的指定操作行为。举例来说，当一个非数字的值作加法操作的时候，Lua会检查它的metatable中的“__add“域中是否有一个函数，如果有这么一个函数的，Lua调用这个函数来执行一次加法（来自lua中文手册）。人们说，“光说不练，假把式”，所以show the code(加法改用add方法)。\n\n    -- 定义table point\n    point = { }\n    function point:add(p)\n        self.x = self.x + p.x \n        self.y = self.y + p.y \n    end\n     \n    -- 定义table point_a和point_b\n    point_a = { x = 1, y = 2 }\n    point_b = { x = 2, y = 1 }\n     \n    -- 对point_a设置元表\n    setmetatable(point_a, { __index = point })\n     \n    -- 调用point_a的add方法，由于point_a为没有add方法，所以向其元表point中查询，发现有add方法，调用之\n    point_a:add(point_b)\n     \n    -- 打印调用add方法后的point_a\n    print(point_a.x, point_a.y)\n\n这里定义了一个table point，其包含add方法，并将其设置为point_a的元表。当调用point_a的add方法时，首在在point_a中寻找add方法，但是point_a中并没有add方法，所以再次在point_a的元表，即point中寻找add方法并进行调用。\n\n在一个table中找不到某个方法，就向其元表中寻找。这个特性不就如同面向对象中子类方法找不到时，在其父类中寻找。既然如此，那么利用Lua的metatable，很容易就实现类似面向对象的功能。\n\n首先，定义一个全局的Class做为“类的关键字”。\n\n    -- Object为所有对象的上级\n    Object = { }\n     \n    -- 创建现有对象副本的方法\n    function Object:clone()\n        local object = { }\n        for k, v in pairs(self) do\n            object[k] = v\n        end\n     \n        setmetatable(object, { __index = self })\n     \n        return object\n    end\n     \n    -- 允许类似基于类编程的用法\n    function Object:new(...)\n        local object = { }\n     \n        setmetatable(object, { __index = self })\n     \n        object:initialize(...)\n     \n        return object\n    end\n     \n    function Object:initialize(...)\n        -- do nothing \n    end\n     \n    -- 定义Class原型\n    Class = Object:new()\n\n里面定义了一个名为Object的table, 然后在该table中分别定义了clone(),new(…)和initialize(…)三个方法。\n\n首先看clone方法，该方法对Object自身制作了一份copy，同时又将Object自身作为copy对象的元表的__index域的值。这样，当copy对象对某一变量或者方法进行索引时，并且发现copy对象并不包含索引对象时，就再次对被copy对象进行索引。如此便可实现上文中metatable.lua文件中的功能。\n\n然后看new方法。该方法中定义一个object table, 并对其进行初始化操作后直接返回。\n\n最后，直接定义Class原型，作为“类关键字”，方便以后调用。\n\n定义完”Class关键字”后，实现类似面向对象的编程就非常简单了。直接附上经典示例。\n\n    require 'lua/class'\n     \n    -- 定义Point类\n    Point = Class:new()\n     \n    -- 定义Point类的初始化方法\n    function Point:initialize(x, y)\n        self.x = x\n        self.y = y\n    end\n     \n    -- 定义Point类的距离方法\n    function Point:magnitude()\n        return math.sqrt(self.x^2 + self.y^2)\n    end\n     \n    -- 打印point(3, 4)的距离\n    print(Point:new(3, 4):magnitude())\n\n\n    require 'lua/point'\n     \n    -- 定义Point3D类, 该类继承自Point类\n    Point3D = Point:clone()\n     \n    -- 定义Point3D类的初始化方法\n    function Point3D:initialize(x, y, z)\n        Point.initialize(self, x, y)\n        self.z = z\n    end\n     \n    -- 定义Point3D类的距离方法\n    function Point3D:magnitude()\n        return math.sqrt(self.x^2 + self.y^2 + self.z^2)\n    end\n     \n    -- 打印point(1, 2, 3)的距离\n    print(Point3D:new(1, 2, 3):magnitude())\n\n**[REFERENCE]**    \n\n* wikipedia    \n* lua中文手册    \n* 代码的未来    ","source":"_posts/2014-08-09-1.md","raw":"---\ndate: 2014-08-09\nlayout: post\ntitle: 如何用lua实现面向对象\npermalink: '/2014/08-09-1.html'\ncategories:\n- lua\ntags:\n- 面向对象\n---\n\n\nlua作为一门非面向对象的轻量级语言，如何才能方便的用面向对象的方法来进行编程呢？\n\n首先,编程范型对面向对象编程（OOP）是如何定义的呢？**通常，OOP被理解为一种将程序分解为封装数据及相关操作的模块而进行的编程方式**。有别于其他编程方式，OOP中的与某些数据类型相关的一系列操作都被有机地封装到该数据类型当中，而非散放于其外，因而**OPP中的数据类型不仅有着状态，还有着相关的操作**。（来自wikipedia）\n\n以一言蔽之，就是数据中包含对数据的操作行为。如此甚好，在lua中只要有**强力类型table**即实现了。\n\n    -- 定义table类型\n    point = { }\n     \n    -- 在table中增加x, y两个数据\n    point.x = 3\n    point.y = 4\n     \n    -- 在table中增加magnitude方法\n    point.magnitude = function ()\n        return math.sqrt(point.x^2 + point.y^2)\n    end\n     \n    -- 调用point中方法处理数据\n    print(point.magnitude())\n\n确实，数据的行为被封装在table类型point中了，但是，这看上去也太不专业了，我们不能这么没追求是吧。而且，继承呢，多态呢？完全没有面向对象的影子嘛。模仿也要有模仿的样子嘛。\n\n当然，这并不是我们可以接受的版本。在讲解可用版本之前，先来解释下lua中的一大利器–metatable。先来看其官方定义：**metatable用来定义原始值在特定操作下的行为**。你可以通过在metatable中的特定域设一值来改变拥有这个metatable的值的指定操作行为。举例来说，当一个非数字的值作加法操作的时候，Lua会检查它的metatable中的“__add“域中是否有一个函数，如果有这么一个函数的，Lua调用这个函数来执行一次加法（来自lua中文手册）。人们说，“光说不练，假把式”，所以show the code(加法改用add方法)。\n\n    -- 定义table point\n    point = { }\n    function point:add(p)\n        self.x = self.x + p.x \n        self.y = self.y + p.y \n    end\n     \n    -- 定义table point_a和point_b\n    point_a = { x = 1, y = 2 }\n    point_b = { x = 2, y = 1 }\n     \n    -- 对point_a设置元表\n    setmetatable(point_a, { __index = point })\n     \n    -- 调用point_a的add方法，由于point_a为没有add方法，所以向其元表point中查询，发现有add方法，调用之\n    point_a:add(point_b)\n     \n    -- 打印调用add方法后的point_a\n    print(point_a.x, point_a.y)\n\n这里定义了一个table point，其包含add方法，并将其设置为point_a的元表。当调用point_a的add方法时，首在在point_a中寻找add方法，但是point_a中并没有add方法，所以再次在point_a的元表，即point中寻找add方法并进行调用。\n\n在一个table中找不到某个方法，就向其元表中寻找。这个特性不就如同面向对象中子类方法找不到时，在其父类中寻找。既然如此，那么利用Lua的metatable，很容易就实现类似面向对象的功能。\n\n首先，定义一个全局的Class做为“类的关键字”。\n\n    -- Object为所有对象的上级\n    Object = { }\n     \n    -- 创建现有对象副本的方法\n    function Object:clone()\n        local object = { }\n        for k, v in pairs(self) do\n            object[k] = v\n        end\n     \n        setmetatable(object, { __index = self })\n     \n        return object\n    end\n     \n    -- 允许类似基于类编程的用法\n    function Object:new(...)\n        local object = { }\n     \n        setmetatable(object, { __index = self })\n     \n        object:initialize(...)\n     \n        return object\n    end\n     \n    function Object:initialize(...)\n        -- do nothing \n    end\n     \n    -- 定义Class原型\n    Class = Object:new()\n\n里面定义了一个名为Object的table, 然后在该table中分别定义了clone(),new(…)和initialize(…)三个方法。\n\n首先看clone方法，该方法对Object自身制作了一份copy，同时又将Object自身作为copy对象的元表的__index域的值。这样，当copy对象对某一变量或者方法进行索引时，并且发现copy对象并不包含索引对象时，就再次对被copy对象进行索引。如此便可实现上文中metatable.lua文件中的功能。\n\n然后看new方法。该方法中定义一个object table, 并对其进行初始化操作后直接返回。\n\n最后，直接定义Class原型，作为“类关键字”，方便以后调用。\n\n定义完”Class关键字”后，实现类似面向对象的编程就非常简单了。直接附上经典示例。\n\n    require 'lua/class'\n     \n    -- 定义Point类\n    Point = Class:new()\n     \n    -- 定义Point类的初始化方法\n    function Point:initialize(x, y)\n        self.x = x\n        self.y = y\n    end\n     \n    -- 定义Point类的距离方法\n    function Point:magnitude()\n        return math.sqrt(self.x^2 + self.y^2)\n    end\n     \n    -- 打印point(3, 4)的距离\n    print(Point:new(3, 4):magnitude())\n\n\n    require 'lua/point'\n     \n    -- 定义Point3D类, 该类继承自Point类\n    Point3D = Point:clone()\n     \n    -- 定义Point3D类的初始化方法\n    function Point3D:initialize(x, y, z)\n        Point.initialize(self, x, y)\n        self.z = z\n    end\n     \n    -- 定义Point3D类的距离方法\n    function Point3D:magnitude()\n        return math.sqrt(self.x^2 + self.y^2 + self.z^2)\n    end\n     \n    -- 打印point(1, 2, 3)的距离\n    print(Point3D:new(1, 2, 3):magnitude())\n\n**[REFERENCE]**    \n\n* wikipedia    \n* lua中文手册    \n* 代码的未来    ","slug":"/2014/08-09-1.html","published":1,"updated":"2015-06-19T16:09:05.000Z","comments":1,"photos":[],"link":"","_id":"ciiwjp30k002vof6gmoliiwak"},{"date":"2014-08-08T16:00:00.000Z","layout":"post","title":"高效使用I/O","_content":"\n\n网络编程中，遇到最多而且必定会遇到的就是I/O了。那么，如何正确使用I/O模型，使程序能高效率运行呢?首先，我们要了解下具体有哪些I/O模型。\n\n**I/O模型**  \n基本I/O模型一般有同步和异步，阻塞和非阻塞，**基本可以分为阻塞型，非阻塞型，多路复用型和异步型4类**。\n\n**阻塞型**  \n阻塞型即最简单使用read(2)等方法。由于read(2)方法是阻塞型函数，当程序使用read(2)向输入读取数据时，如果没有任何数据读取，则read(2)函数就会阻塞，直到输入中有数据可读并读出为止。如图2中简单程序，用read(2)实现阻塞型输入操作。\n\n\tvoid read_input(int fd, void* data)\n\t{\n\t     char buf[BUFSIZ];\n\t     int n;\n\t \n\t     n = read(fd, buf, BUFSIZ);\n\t     if (n < 0)      return -1;  /* failed */\n\t     if (n == 0) return 0;       /* EOF */\n\t     process(fd, buf, n);      /* success */\n\t \n\t     return 1;\n\t}\n\n图2中代码向输入读取最多BUFSIZ长度的数据，如果read(2)返回<0, 则read(2)调用失败，可能为遇到中断信号等错误，如果read(2)返回==0，则为读到文件尾，在网络通信中即对端关闭了socket连接。如果返回其他值，则说明read(2)读取输入正常，且读取n长度的数据。但是，如果输入数据大于读取的最大长度BUFSIZ时，read(2)返回BUFSIZ长度，剩下的数据等待下次read(2)进行读取。当然，这里可能出现这样的情况，输入数据正好等于BUFSIZ长度时，read(2)也返回BUFSIZ值，这时就无法判断输入数据到底还有没有剩下，只能等待下次read(2)调用时才得认证。\n\n阻塞型模型必须循环调用read(2)以保证当有输入数据时，程序能得到这些数据。因为阻塞型模型无法知晓何时有数据可读，而且有多少数据也无从知道。在常见的网络编程中，并发存在成千上万个socket连接是很正常的现象，而阻塞型模型对每一个连接都要循环调用read(2)函数以保证每一个连接上有数据可读时能及时准备读取，这样就不得不开启N个线程（进程）进行read(2)调用，而且当大量空闲连接存在时，大量线程阻塞在read(2)上，显然这不是一个可行的方案。\n\n可见，阻塞型模型并不是现代网络编程可以采用的网络模型。\n\n**非阻塞型**  \n非阻塞型，依旧调用read(2)等方法。但不同的是，read(2)并不会阻塞，而是立即返回。若该连接的fd被设置为O_NONBLOCK时，则read(2)表现就会略有不同。当内核有数据可读取时，则返回读取的数据，返回数据的规则和阻塞型中read(2)相同；但是当内核没有数据可读时，read(2)并不会一直阻塞直到有数据可读，而是立即返回EAGAIN或者EWOULDBLOCK。具体情况见图3中代码。\n\n\tvoid read_input(int fd, void*data)\n\t{\n\t     char buf[BUFSIZ];\n\t     int n;\n\t \n\t     // 由于read(2)最多只能读取BUFSIZ数据，所以循环读取至无数据为止\n\t     for ( ; ; ) {\n\t          n = read(fd, buf, BUFSIZ);\n\t          if (n < 0) {\n\t               // 事先设置fd为O_NONBLOCK，所以当无数据可读时，返回error\n\t               if (errno == EAGAIN || errno == EWOULDBLOCK) {\n\t                    return 1;\n\t               }\n\t               return -1;\n\t          }\n\t          else if (n == 0) {\n\t               // 对端关闭连接\n\t               return 0;\n\t          }\n\t          else {\n\t               // 数据已读取，处理\n\t               process(fd, buf, n);\n\t          }\n\t     }\n\t}\n\n图3中代码，事先对连接fd设置O_NONBLOCK（代码中无体现），所以当调用read(2)时，若内核中无数据可读时，则直接返回fail(值为-1)， 同时设置错误码为EAGAIN或者EWOULDBLOCK。同样，若返回0则表示对端可能关闭了相应的连接，现也没有数据过来了，而当返回>0时，则接收数据正常，但同样无法保证数据已读取完毕。所以，代码中采用循环读取数据，由于当内核中无数据可读时，read(2)也会立即返回，并对错误码进行置位，如此可判断数据已读取完毕。综上所述图3中代码不会对程序造成阻塞，而且也读取数据时也不会因为数据长度超过BUFSZIZ而造成读取不完整，可见，与阻塞型相比，非阻塞型解决了调用read(2)阻塞和数据可能读取不完整的问题，但是同样，在现代服务器动辄上万连接的情况下，开启同样数据线程并定时读取的方法并不可行。\n\n**多路复用型**  \n无论是阻塞型和非阻塞型，两都均不适用于现代服务器。若是出现一位管家，当fd上有数据可读时，再通知应用程序，那不是很方便。这时，多路复用就登场了。目前支持多路复用的系统调用包括select, poll, epoll, kqueue等。\n\n说到这位管家，那就不得不说明下这管家有两种型号，分别对应在事件监视中同步的工作形态，即边沿触发和电平触发。这本来是在机械领域的两个概念，边沿触发是指只在状态变化的瞬间发出通知，而电平触发是指在状态发生变化的整个过程中都持续发出通知，具体可自行google。而在网络编程中，边沿触发和电平触发又是如何体现的呢？边沿触发，只在数据到达的瞬间产生通知，即每次数据到达只会通知一次，具体读取还是不读取，就要看应用程序了。而电平触发，只有内核缓冲区中有数据，它就会持续通知应用程序，多么敬业的一位管家啊。当然，在效率上，边沿触发还是占有绝对的优势。  \n下面举下select的例子，伪代码如图4。\n\n\tint fd_socket = socket(...);     // 监听新连接socket\n\tbind(...);\n\tlisten(...);\n\t \n\tint fd_in[MAX];     // 监听已连接socket\n\t \n\tfd_set fs;\n\t \n\twhile(1){\n\t  FD_ZERO(fs...);\n\t  // 对所有已连接socket进行监听\n\t  for_each(fd_in) {\n\t       FD_SET(fd, fs);\n\t  }\n\t  // 对接收新连接socket进行监听\n\t  FD_SET(fd_socket, fs);\n\t \n\t  // 若没有任何fd可读，则阻塞\n\t  select(...);\n\t \n\t  if(FD_ISSET(fd_socket...)) {\n\t        accept(...);\n\t    }\n\t \n\t  if(FD_ISSET(fd_stdin...)) {\n\t        read(...);\n\t  }\n\t}\n\n这里，select总管所有可能有数据可读的fd, 并阻塞调用直到至少有一个fd可读。当然，读者可能觉得该代码中有个小问题，就是之前描述过的read(2)数据读取不完全的情况。当然，这是个必须考虑的问题。但是select只支持电平触发，所以read(2)未读取完全，下次调用select时内核也会继续通知该fd可读，所以理论上是不会出现数据读取不完整的情况，但是由于要等到下次循环时才能读取数据，对性能有追求的情况下，依然还是可以对fd设置O_NONBLOCK，循环读取fd直到读取完毕为止。当然，在边沿触发情况下（epoll可设置），则必须使用O_NONBLOCK读取完全，否则有可能出现数据读取不完整的情况。  \n当然非阻塞型非常适合现代服务器的编写，即不会造成大量线程阻塞，也不会需要成千上万的线程对每一个连接进行数据读取，这不得不说多路复用真是个好管家。\n\n**异步型**  \n若是采用异步模型，则必须使用异步接口I/O接口了。异步模型可以说是最理想的网络模型，因为CPU只是在有必要的时候参与，对CPU的利用没有一点浪费。当然，若是采用异步模型，直接采用异步接口进行编程就可以了，这里就不再赘述。","source":"_posts/2014-08-09-0.md","raw":"---\ndate: 2014-08-09\nlayout: post\ntitle: 高效使用I/O\npermalink: '/2014/08-09-0.html'\ncategories:\n- 服务器编程\ntags:\n- 网络I/O\n---\n\n\n网络编程中，遇到最多而且必定会遇到的就是I/O了。那么，如何正确使用I/O模型，使程序能高效率运行呢?首先，我们要了解下具体有哪些I/O模型。\n\n**I/O模型**  \n基本I/O模型一般有同步和异步，阻塞和非阻塞，**基本可以分为阻塞型，非阻塞型，多路复用型和异步型4类**。\n\n**阻塞型**  \n阻塞型即最简单使用read(2)等方法。由于read(2)方法是阻塞型函数，当程序使用read(2)向输入读取数据时，如果没有任何数据读取，则read(2)函数就会阻塞，直到输入中有数据可读并读出为止。如图2中简单程序，用read(2)实现阻塞型输入操作。\n\n\tvoid read_input(int fd, void* data)\n\t{\n\t     char buf[BUFSIZ];\n\t     int n;\n\t \n\t     n = read(fd, buf, BUFSIZ);\n\t     if (n < 0)      return -1;  /* failed */\n\t     if (n == 0) return 0;       /* EOF */\n\t     process(fd, buf, n);      /* success */\n\t \n\t     return 1;\n\t}\n\n图2中代码向输入读取最多BUFSIZ长度的数据，如果read(2)返回<0, 则read(2)调用失败，可能为遇到中断信号等错误，如果read(2)返回==0，则为读到文件尾，在网络通信中即对端关闭了socket连接。如果返回其他值，则说明read(2)读取输入正常，且读取n长度的数据。但是，如果输入数据大于读取的最大长度BUFSIZ时，read(2)返回BUFSIZ长度，剩下的数据等待下次read(2)进行读取。当然，这里可能出现这样的情况，输入数据正好等于BUFSIZ长度时，read(2)也返回BUFSIZ值，这时就无法判断输入数据到底还有没有剩下，只能等待下次read(2)调用时才得认证。\n\n阻塞型模型必须循环调用read(2)以保证当有输入数据时，程序能得到这些数据。因为阻塞型模型无法知晓何时有数据可读，而且有多少数据也无从知道。在常见的网络编程中，并发存在成千上万个socket连接是很正常的现象，而阻塞型模型对每一个连接都要循环调用read(2)函数以保证每一个连接上有数据可读时能及时准备读取，这样就不得不开启N个线程（进程）进行read(2)调用，而且当大量空闲连接存在时，大量线程阻塞在read(2)上，显然这不是一个可行的方案。\n\n可见，阻塞型模型并不是现代网络编程可以采用的网络模型。\n\n**非阻塞型**  \n非阻塞型，依旧调用read(2)等方法。但不同的是，read(2)并不会阻塞，而是立即返回。若该连接的fd被设置为O_NONBLOCK时，则read(2)表现就会略有不同。当内核有数据可读取时，则返回读取的数据，返回数据的规则和阻塞型中read(2)相同；但是当内核没有数据可读时，read(2)并不会一直阻塞直到有数据可读，而是立即返回EAGAIN或者EWOULDBLOCK。具体情况见图3中代码。\n\n\tvoid read_input(int fd, void*data)\n\t{\n\t     char buf[BUFSIZ];\n\t     int n;\n\t \n\t     // 由于read(2)最多只能读取BUFSIZ数据，所以循环读取至无数据为止\n\t     for ( ; ; ) {\n\t          n = read(fd, buf, BUFSIZ);\n\t          if (n < 0) {\n\t               // 事先设置fd为O_NONBLOCK，所以当无数据可读时，返回error\n\t               if (errno == EAGAIN || errno == EWOULDBLOCK) {\n\t                    return 1;\n\t               }\n\t               return -1;\n\t          }\n\t          else if (n == 0) {\n\t               // 对端关闭连接\n\t               return 0;\n\t          }\n\t          else {\n\t               // 数据已读取，处理\n\t               process(fd, buf, n);\n\t          }\n\t     }\n\t}\n\n图3中代码，事先对连接fd设置O_NONBLOCK（代码中无体现），所以当调用read(2)时，若内核中无数据可读时，则直接返回fail(值为-1)， 同时设置错误码为EAGAIN或者EWOULDBLOCK。同样，若返回0则表示对端可能关闭了相应的连接，现也没有数据过来了，而当返回>0时，则接收数据正常，但同样无法保证数据已读取完毕。所以，代码中采用循环读取数据，由于当内核中无数据可读时，read(2)也会立即返回，并对错误码进行置位，如此可判断数据已读取完毕。综上所述图3中代码不会对程序造成阻塞，而且也读取数据时也不会因为数据长度超过BUFSZIZ而造成读取不完整，可见，与阻塞型相比，非阻塞型解决了调用read(2)阻塞和数据可能读取不完整的问题，但是同样，在现代服务器动辄上万连接的情况下，开启同样数据线程并定时读取的方法并不可行。\n\n**多路复用型**  \n无论是阻塞型和非阻塞型，两都均不适用于现代服务器。若是出现一位管家，当fd上有数据可读时，再通知应用程序，那不是很方便。这时，多路复用就登场了。目前支持多路复用的系统调用包括select, poll, epoll, kqueue等。\n\n说到这位管家，那就不得不说明下这管家有两种型号，分别对应在事件监视中同步的工作形态，即边沿触发和电平触发。这本来是在机械领域的两个概念，边沿触发是指只在状态变化的瞬间发出通知，而电平触发是指在状态发生变化的整个过程中都持续发出通知，具体可自行google。而在网络编程中，边沿触发和电平触发又是如何体现的呢？边沿触发，只在数据到达的瞬间产生通知，即每次数据到达只会通知一次，具体读取还是不读取，就要看应用程序了。而电平触发，只有内核缓冲区中有数据，它就会持续通知应用程序，多么敬业的一位管家啊。当然，在效率上，边沿触发还是占有绝对的优势。  \n下面举下select的例子，伪代码如图4。\n\n\tint fd_socket = socket(...);     // 监听新连接socket\n\tbind(...);\n\tlisten(...);\n\t \n\tint fd_in[MAX];     // 监听已连接socket\n\t \n\tfd_set fs;\n\t \n\twhile(1){\n\t  FD_ZERO(fs...);\n\t  // 对所有已连接socket进行监听\n\t  for_each(fd_in) {\n\t       FD_SET(fd, fs);\n\t  }\n\t  // 对接收新连接socket进行监听\n\t  FD_SET(fd_socket, fs);\n\t \n\t  // 若没有任何fd可读，则阻塞\n\t  select(...);\n\t \n\t  if(FD_ISSET(fd_socket...)) {\n\t        accept(...);\n\t    }\n\t \n\t  if(FD_ISSET(fd_stdin...)) {\n\t        read(...);\n\t  }\n\t}\n\n这里，select总管所有可能有数据可读的fd, 并阻塞调用直到至少有一个fd可读。当然，读者可能觉得该代码中有个小问题，就是之前描述过的read(2)数据读取不完全的情况。当然，这是个必须考虑的问题。但是select只支持电平触发，所以read(2)未读取完全，下次调用select时内核也会继续通知该fd可读，所以理论上是不会出现数据读取不完整的情况，但是由于要等到下次循环时才能读取数据，对性能有追求的情况下，依然还是可以对fd设置O_NONBLOCK，循环读取fd直到读取完毕为止。当然，在边沿触发情况下（epoll可设置），则必须使用O_NONBLOCK读取完全，否则有可能出现数据读取不完整的情况。  \n当然非阻塞型非常适合现代服务器的编写，即不会造成大量线程阻塞，也不会需要成千上万的线程对每一个连接进行数据读取，这不得不说多路复用真是个好管家。\n\n**异步型**  \n若是采用异步模型，则必须使用异步接口I/O接口了。异步模型可以说是最理想的网络模型，因为CPU只是在有必要的时候参与，对CPU的利用没有一点浪费。当然，若是采用异步模型，直接采用异步接口进行编程就可以了，这里就不再赘述。","slug":"/2014/08-09-0.html","published":1,"updated":"2015-06-19T16:09:05.000Z","comments":1,"photos":[],"link":"","_id":"ciiwjp30m0030of6gtpskodso"},{"date":"2014-07-02T16:00:00.000Z","layout":"post","title":"时间都去哪了","_content":"\n\n“我有太多的事要做，但却没有足够的时间。”  \n“为什么我每天都忙的不可开交，有些人却一切井井有条?”  \n“每次周末我都计划了一堆事，看书，运动，见朋友，但每次却都没有完成。”  \n……\n\n这些曾经困扰我的问题，现在似乎已全都不存在了。因为我懂得了，时间是整理出来的。鲁迅先生说“时间就像海绵里的水，只要愿意挤，总还是有的”。\n\n为什么会想做的事情太多，而时间太少？其实并不是这样的，也许你想做的事情并不多，其实你的时间也并不少，只是你的时间花在了不该花的地方。每次面对你杂乱无章的桌面，你是不是都无动于衷？你有多久没整理电脑里的文件了？没错，时间花错了地。当你要做某件事时，是不是总是要花点时间去寻找东西？既然如此，定时整理，让杂乱的生活离你远去，你的时间就会增多，你再也不会觉得时间不够了。\n\n你是否一直觉得自己很拖拉，是位不折不扣的拖延症患者？如果你不了解什么是拖延症，请移步[《拖延心理学》](http://book.douban.com/subject/4180711/)。对于拖延，我只想说，你拖延不拖延，事情就在那里，不会多，也不会少。所以，马上“治愈”拖延症，说干就干，do it right now!\n\n时间最大的杀手事实上是不断打断你的环境。电话，email, IM工具，同事聊天等等，这些每天不间断地扼杀你的时间。也许你会认为，收个email, 说几句话也占用不了几分钟时间，那么你就错了。如果做事时不断被打断，那么进入[Flow](http://en.wikipedia.org/wiki/Flow_\\(psychology\\))（心流，俗称神驰）就几乎不可能，而效率最大的时刻就是进入Flow的阶段。另外，当你收了一封email，你心里有个小人就会说，浏览会网页吧，反正也花不了多少时间。然后，你就去浏览下今天的新闻，看看天气如何，当你回到现实时，又到了吃饭的时间了，糟了，我事还没干呢！\n\n“为什么加班的总是我？” 我每天白天一直在忙，晚上还要加班，事情总是干不完似的。那么，请你想想，你一天中有多少会，每次开会又花多少时间。开会的时候，是不是都在讨论相关的事。有没有在会上拉家常？另外，有没有每天被email所淹没，大量的时间花在收email, 回email上？\n\n最后，给你的时间加把劲。多用用你手边的高科技产品，随时记录将要做的事，必要的按时提醒，“科技是以人为本”的，学会善用它们。","source":"_posts/2014-07-03-0.md","raw":"---\ndate: 2014-07-03\nlayout: post\ntitle: 时间都去哪了\npermalink: '/2014/07-03-0.html'\ncategories:\n- 杂感\ntags:\n---\n\n\n“我有太多的事要做，但却没有足够的时间。”  \n“为什么我每天都忙的不可开交，有些人却一切井井有条?”  \n“每次周末我都计划了一堆事，看书，运动，见朋友，但每次却都没有完成。”  \n……\n\n这些曾经困扰我的问题，现在似乎已全都不存在了。因为我懂得了，时间是整理出来的。鲁迅先生说“时间就像海绵里的水，只要愿意挤，总还是有的”。\n\n为什么会想做的事情太多，而时间太少？其实并不是这样的，也许你想做的事情并不多，其实你的时间也并不少，只是你的时间花在了不该花的地方。每次面对你杂乱无章的桌面，你是不是都无动于衷？你有多久没整理电脑里的文件了？没错，时间花错了地。当你要做某件事时，是不是总是要花点时间去寻找东西？既然如此，定时整理，让杂乱的生活离你远去，你的时间就会增多，你再也不会觉得时间不够了。\n\n你是否一直觉得自己很拖拉，是位不折不扣的拖延症患者？如果你不了解什么是拖延症，请移步[《拖延心理学》](http://book.douban.com/subject/4180711/)。对于拖延，我只想说，你拖延不拖延，事情就在那里，不会多，也不会少。所以，马上“治愈”拖延症，说干就干，do it right now!\n\n时间最大的杀手事实上是不断打断你的环境。电话，email, IM工具，同事聊天等等，这些每天不间断地扼杀你的时间。也许你会认为，收个email, 说几句话也占用不了几分钟时间，那么你就错了。如果做事时不断被打断，那么进入[Flow](http://en.wikipedia.org/wiki/Flow_\\(psychology\\))（心流，俗称神驰）就几乎不可能，而效率最大的时刻就是进入Flow的阶段。另外，当你收了一封email，你心里有个小人就会说，浏览会网页吧，反正也花不了多少时间。然后，你就去浏览下今天的新闻，看看天气如何，当你回到现实时，又到了吃饭的时间了，糟了，我事还没干呢！\n\n“为什么加班的总是我？” 我每天白天一直在忙，晚上还要加班，事情总是干不完似的。那么，请你想想，你一天中有多少会，每次开会又花多少时间。开会的时候，是不是都在讨论相关的事。有没有在会上拉家常？另外，有没有每天被email所淹没，大量的时间花在收email, 回email上？\n\n最后，给你的时间加把劲。多用用你手边的高科技产品，随时记录将要做的事，必要的按时提醒，“科技是以人为本”的，学会善用它们。","slug":"/2014/07-03-0.html","published":1,"updated":"2015-06-19T16:09:05.000Z","comments":1,"photos":[],"link":"","_id":"ciiwjp30o0034of6gds9i8tha"},{"date":"2013-07-27T16:00:00.000Z","layout":"post","title":"openGL学习（四） -- 颜色","_content":"\n\n**1 RGBA和颜色索引模式**  \n--------------------\n**RGB显示模式**：在此模式下，硬件为R、G、B和A成分保留一定数量的位平面（每种成分位平面数量并不一定相同）。像素可以显示的不同颜色的数量取决于位平面的数量以及硬件是如何解释这些位平面的。不同颜色的数量不能超过2的N次方，其中N是位平面的数量。  \n\n有些图形硬件使用**抖动**来增加可以显示的颜色数量。假定系统分别只有1个位来表示R、G、B，这样一共可以显示8种颜色：黑、白、红、蓝、绿、黄、青和洋红。现有一种颜色粉红色，这种颜色并不在系统可以显示的8种颜色中，那么系统如何实现显示呢。图形硬件仍然采用棋盘模式的方法，用红色和白色交替对像素进行着色。如果眼睛距离屏幕足够远，不能看到单独的像素，这块区域看上去就是粉红色的，那就是红色和白色的均值。但是，如果是从帧缓冲区读取像素信息，所得到的是实际的红色和白色的像素值，因为帧缓冲区中不存在“粉红色”。  \n\n如果分别用8位来表示R、G和B值，即使不借助抖动也可以创建高质量的图像。但是，并不是说，如果计算机具有24位的位平面，就可以不需要使用抖动了。例如，如果是在双缓冲模式下运行，位平面可能被分成两组，每组12位，这样每种颜色成分实际上只有4位。在许多情况下，如果不使用抖动，每种分4位的颜色是无法产生令人满意的效果的。  \n可以用GL_DITHER为参数调用glEnable( )或glDisable( )函数，分别启用或禁用抖动功能。**注意，和其他许多特性不同，抖动在默认情况下是启用的**。\n\n**颜色索引模式**:在颜色索引模式下，OpenGL使用一个颜色映射表（或颜色查找表），类似于使用调色板来混合颜料，准备根据颜色编号来绘制场景。颜色映射表的大小是由专用的硬件决定的。\n\n**2 在RGBA和颜色索引模式中进行选择**  \n--------------------\n应该根据可用的硬件和应用程序的要求来选择使用RGBA模式还是颜色索引模式。在绝大多数系统中，RGBA模式可以显示的颜色数量要远远多于颜色索引模式。另外，对于有些效果（如着色、光照、纹理贴图和雾），RGBA模式能够提供更大的灵活性。  \n\n一般而言，应该尽可能使用RGBA模式。RGBA模式可以在纹理贴图中使用，并且在使用光照、着色、雾和抗锯齿功能时更为灵活。\n\n**3 指定颜色和着色模型**  \n--------------------\nOpenGL维护一种当前颜色（在RGBA模式下）或一个当前颜色索引（在颜色索引模式下）。一般每个物体都是用当前颜色（或当前颜色索引）绘制的，除非使用了一些更为复杂的着色模型，例如光照和纹理贴图。  \n\n在RGBA模式下，使用glColor*( )函数选择一种当前颜色。在颜色索引模式下，可以使用glIndex*( )函数选择一个单值颜色索引，把它作为当前的颜色索引。  \n\n直线或填充多边形可以用一种颜色进行绘制（**单调着色**），也可以用多种颜色进行绘制（**平滑着色**，也称Gouraud着色）。可以用glShadeModel( )函数指定所需的着色模型。在单调着色模型下，整个图元的颜色就是它任何一个顶点的颜色。在平滑着色模型下，每个顶点都是单独进行处理的。如果图元是直线，线段的颜色将根据两个顶点的颜色进行均匀插值。如果图元是多边形，多边形的内部颜色是所有顶点颜色的均匀插值。","source":"_posts/2013-07-28-0.md","raw":"---\ndate: 2013-07-28\nlayout: post\ntitle: openGL学习（四） -- 颜色\npermalink: '/2013/07-28-0.html'\ncategories:\n- 游戏开发\ntags:\n- openGL\n---\n\n\n**1 RGBA和颜色索引模式**  \n--------------------\n**RGB显示模式**：在此模式下，硬件为R、G、B和A成分保留一定数量的位平面（每种成分位平面数量并不一定相同）。像素可以显示的不同颜色的数量取决于位平面的数量以及硬件是如何解释这些位平面的。不同颜色的数量不能超过2的N次方，其中N是位平面的数量。  \n\n有些图形硬件使用**抖动**来增加可以显示的颜色数量。假定系统分别只有1个位来表示R、G、B，这样一共可以显示8种颜色：黑、白、红、蓝、绿、黄、青和洋红。现有一种颜色粉红色，这种颜色并不在系统可以显示的8种颜色中，那么系统如何实现显示呢。图形硬件仍然采用棋盘模式的方法，用红色和白色交替对像素进行着色。如果眼睛距离屏幕足够远，不能看到单独的像素，这块区域看上去就是粉红色的，那就是红色和白色的均值。但是，如果是从帧缓冲区读取像素信息，所得到的是实际的红色和白色的像素值，因为帧缓冲区中不存在“粉红色”。  \n\n如果分别用8位来表示R、G和B值，即使不借助抖动也可以创建高质量的图像。但是，并不是说，如果计算机具有24位的位平面，就可以不需要使用抖动了。例如，如果是在双缓冲模式下运行，位平面可能被分成两组，每组12位，这样每种颜色成分实际上只有4位。在许多情况下，如果不使用抖动，每种分4位的颜色是无法产生令人满意的效果的。  \n可以用GL_DITHER为参数调用glEnable( )或glDisable( )函数，分别启用或禁用抖动功能。**注意，和其他许多特性不同，抖动在默认情况下是启用的**。\n\n**颜色索引模式**:在颜色索引模式下，OpenGL使用一个颜色映射表（或颜色查找表），类似于使用调色板来混合颜料，准备根据颜色编号来绘制场景。颜色映射表的大小是由专用的硬件决定的。\n\n**2 在RGBA和颜色索引模式中进行选择**  \n--------------------\n应该根据可用的硬件和应用程序的要求来选择使用RGBA模式还是颜色索引模式。在绝大多数系统中，RGBA模式可以显示的颜色数量要远远多于颜色索引模式。另外，对于有些效果（如着色、光照、纹理贴图和雾），RGBA模式能够提供更大的灵活性。  \n\n一般而言，应该尽可能使用RGBA模式。RGBA模式可以在纹理贴图中使用，并且在使用光照、着色、雾和抗锯齿功能时更为灵活。\n\n**3 指定颜色和着色模型**  \n--------------------\nOpenGL维护一种当前颜色（在RGBA模式下）或一个当前颜色索引（在颜色索引模式下）。一般每个物体都是用当前颜色（或当前颜色索引）绘制的，除非使用了一些更为复杂的着色模型，例如光照和纹理贴图。  \n\n在RGBA模式下，使用glColor*( )函数选择一种当前颜色。在颜色索引模式下，可以使用glIndex*( )函数选择一个单值颜色索引，把它作为当前的颜色索引。  \n\n直线或填充多边形可以用一种颜色进行绘制（**单调着色**），也可以用多种颜色进行绘制（**平滑着色**，也称Gouraud着色）。可以用glShadeModel( )函数指定所需的着色模型。在单调着色模型下，整个图元的颜色就是它任何一个顶点的颜色。在平滑着色模型下，每个顶点都是单独进行处理的。如果图元是直线，线段的颜色将根据两个顶点的颜色进行均匀插值。如果图元是多边形，多边形的内部颜色是所有顶点颜色的均匀插值。","slug":"/2013/07-28-0.html","published":1,"updated":"2015-06-19T16:09:05.000Z","comments":1,"photos":[],"link":"","_id":"ciiwjp30q0037of6gvchi421i"},{"date":"2013-07-26T16:00:00.000Z","layout":"post","title":"openGL学习（三）-- 视图","_content":"\n\n计算机图形的要点就是创建三维物体的二维图像（图像必须是二维的，因为它是在平面的屏幕上显示的）。我们要避免考虑屏幕上的像素是如何绘制的，而是要尽量在三维空间中想象物体的形状。\n\n本章主要介绍如何使用OpenGL完成如下任务：如何在三维空间中设置模型的位置和方向，以及如何确定观察者的位置（也是在三维空间中），最后能够准确地判断屏幕上所显示的图像。\n\n把一个物体的三维坐标变换为屏幕上的像素坐标，需要完成如下步骤：\n\n1. 变换包括模型、视图和投影操作，它们是由矩阵乘法表示的。这些操作包括旋转、移动、缩放、反射、正投影和透视投影等。一般情况下，在绘制场景时需要组合使用几种变换。\n2. 由于场景是在一个矩形窗口中渲染的，因此位于窗口之外的物体（或者物体的一部分）必须裁剪掉。在三维计算机图像中，裁剪就是丢弃位于裁剪平面之外的物体。\n3. 最后，经过了变换的坐标和屏幕像素之间必须建立对应关系。这个过程称为视口(viewport)变换。\n\n**1 简介：用照相机打比方**\n-----------------------\n产生目标场景视图的变换过程类似于用照相机进行拍照。\n\n1. 把照相机固定在三角架上，并让它对准场景（视图变换）。\n2. 对场景进行安排，使各个物体在照片中的位置是我们所希望的（模型变换）。\n3. 选择照相机镜头（广角镜头，标准镜头还是长焦镜头），并调整放大倍数（投影变换）。\n4. 确定最终照片的大小。例如，我们很可能需要把它放大（视口变换）。\n\n以下具体介绍各方面：  \n首先是**视图变换**。通常在指定视图变换之前，需要使用glLoadIdentity( )函数把当前矩阵(current matrix)设置为单位矩阵。这个步骤是非常有必要的，因为绝大多数变换是把当前矩阵与指定的矩阵相乘，然后把结果指定为当前矩阵。如果没有通过加载单位矩阵来清除当前矩阵，它所进行的变换实际上是把当前的变换与上一次变换进行了组合。虽然有些情况下，确实需要这样的操作，但是更多情况下，还是需要清除当前矩阵。  \n\n使用gluLookAt( )函数指定了视图变换。如gluLookAt(0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0)，若用照相机作比喻，则把照相机放在(0, 0, 5)的位置，把镜头瞄准(0, 0, 0)，并把朝上向量指定为(0, 1, 0)。如果没有调用gluLookAt( )函数，则照相机就被设置为默认的位置和方向。在默认情况下，照相机位于原点，指向Z轴的负方向，朝上向量为(0, 1, 0)。\n\n其次是**模型变换**。使用模型变换的目的是设置模型的位置和方向。例如，可以对模型进行旋转、移动和缩放，或者联合应用这些种操作。如模型变换函数glScalef(1.0, 3.0, 1.0)就是将模型y轴尺寸放大3倍。\n\n第三是**投影变换**。这种变换的目的是确定视野（或视景体），并因此确定哪些物体位于视野之内以及它们能够看到的程度。另外，投影变换还决定了物体是如何投影到屏幕上的。OpenGL提供了两种基本类型的投影，即透视投影（perspective projection）和正投影（orthographic projection）。透视投影类似于我们日常生活看到的景象。如果想创建现实感比较强的图像，就需要选择透视投影。而正投影直接映射到屏幕上，而不影响它们的相对大小，一般用于建筑和CAD应用程序中。\n\n与视图 / 模型变换一样，在设置投影变换之前，需要首先调用glMatrixMode(GL_PROJECTION)把当前矩阵指定为用于投影变换，再使用glLoadIdentity( )对当前的投影矩阵进行初始化。\n\n最后是**视口变换**。视口指定了场景在屏幕上所占据的区域，因此可以把视口变换看成是定义了最终经过处理的照片的大小和位置，如照片是否应该放大或者缩小。用glViewPort( )函数进行视口变换。\n\n视图变换、模型变换、投影变换和视口变换这四种变换一般将视图变换和模型变换分为一组，然后就剩下的再分为一组。视图变换和模型变换两种变换割裂开来是没有意义的。因为可以移动照相机（使用视图变换）来对准物体，也可以移动这个物体（模型变换）达到相同效果。而投影变换和视口变换则共同决定了场景是如何映射到计算机屏幕的。投影变换指定了映射的发生机制，而视口变换则决定了场景所映射的有效屏幕区域的形状。\n\n**2 视图变换和模型变换**\n----------------------\n注意，在执行模型或视图变换之前，必须以GL_MODELVIEW为参数调用glMatrixMode( )函数。\n\n视图变换和模型变换都是用一个4*4的矩阵表示的。每个后续的glMultMatrix*( )函数或变换函数把一个新的4*4的M与当前的模型视图C相乘，产生结果矩阵CM。最后，每个与当前的模型视图矩阵相乘。这个过程意味着程序所调用的最后一个变换函数实际上是首先应用于顶点的：CMv.\n\n如下面的代码序列，它使用3个变换绘制了1个点：\n\n\tglMatrixMode(GL_MODEVIEW);\n\tglLoadIdentity( );\n\tglMultMatrixf(N); /* apply transformation N */\n\tglMultMatrixf(M); /* apply transformation M */\n\tglMultMatrixf(L); /* apply transformation L */\n\tglBegin(GL_POINTS);\n\tglVertedx3f(v); /* draw transformed vertex v */\n\tglEnd( );\n\n在上述代码中，模型视图矩阵按顺序分别包含了I、N、NM，最后是NML，其中I表示单位矩阵。经过变换的顶点是NMLv。因此，顶点变换就是N(M(Lv))。所以，顶点v的变换是按照代码中相反的顺序发生的。\n\n在OpenGL中 ，有三个函数用于执行模型变换，分别为glTranslate*( )，glRotate*( )和glScale*( )。这三个函数都 相当于产生一个适当的移动、旋转或缩放矩阵，然后以这个矩阵作为参数调用glMultMatrix*( )。但是，使用这3个函数可能比使用glMultMatrix*( )速度更快，因为OpenGL会自动计算矩阵，一般来说比自己写的性能更高。\n\n而视图变换一般也是由移动和旋转组成的，即glTranslate*( )和glRotate*( )。为了在最终图像或照片上实现某种场景组合，可以移动照相机，也可以从相反的方向移动所有的物体。因此，一个按照逆时针方向旋转物体的模型变换相当于一个按顺时针方向旋转照相机的视图变换。**最后，要记住视图变换函数必须在调用任何模型变换函数之前调用，以确何首先作用于物体的是模型变换**。当然，除了直接使用移动和旋转函数之外，也可以使用工具函数gluLookAt( )实现视图变换，事实上一般也采用工具函数进行视图变换。\n\n**3 投影变换**\n--------------\n所谓投影变换就是定义投影矩阵用于对场景中的顶点进行变换。在调用手投影变换函数之前，必须首先进行以下操作：\n\n\tglMatrixMode(GL_PROJECTION);\n\tglLoadIdentity( );\n\n这样，接下来的变换函数将影响的是投影矩阵。由于每个投影变换函数都完整地描述了一个特定的变换，因此一般并不需要把投影变换与其他变换进行组合。\n\n投影变换的目的是定义一个视景体。视景体有两种用途。**首先，视景体决定了一个物体是如何映射到屏幕上的（即通过透视投影还是正投影）。其次，视影体定义了哪些物体（或物体的一部分）被裁剪到最终的图像之外**。\n\n投影变换分为两种，透视投影和正投影。\n\n透视投影方法常用于动画、视觉模拟以及其他要求某种程度的现实感的应用领域，因为它和我们在日常生活中观察事物的方式相同。该投影方法可以用glFrustum( )函数或者gluPerspective( )进行。\n\n正投影方法常用于建筑蓝图的计算机辅助设计（CAD）的应用程序。如果没有其他变换，投影的方向就与z轴平行，观察点的方向直接朝向z轴的负方向。该投影方法可以用glOrtho( )函数或者gluOrtho2D( )函数进行。\n\n**4 视口变换**\n--------------\n视口变换对应于选择被冲洗相片的大小这个阶段。我们希望照片像钱包一样大还是像海报一样大？在计算机图形中，视口是一个矩形的窗口区域，图像就是在这个区域中绘制的。\n\n在屏幕上打开窗口的是由窗口系统而不是OpenGL负责的。但是，在默认情况下，视口被设置为占据打开窗口的整个像素矩形。可以使用glViewPort( )函数选择一个更小的绘图区域。例如可以对窗口进行划分，在同一个窗口中显示分割屏幕的效果，以显示多个视图。\n\n使用glViewport( )函数进行视口变换，在默认情况下，礼品的初始值是(0, 0, winWidth, winHeight)，其中winWidth和winHeight分别为窗口的宽和高。\n\n**视口的纵横比一般和视景体的纵横比相同。如果这两个纵横比不同，当图像投影到视口时就会变形**。\n\n视口变换期间同时在做另一件事，那就是进行尝试坐标的编码（以后存储在尝试缓冲区中）。可以使用glDepthRange( )函数对z值进行缩放。**注意的是，与x和y窗口坐标不同，在OpenGL中，z坐标总是被认为位于0.0到1.0范围之间**。\n\n**4 操纵矩阵堆栈**\n------------------\n当我们对模型视图矩阵和投影矩阵进行创建、加载和乘法操作时，每一个操作针对的矩阵实际上是各自矩阵堆栈最顶部的那个元素，即栈顶的矩阵。换种说法就是，当前矩阵就是位于堆栈顶部的矩阵。\n\n可以采用glPushMatrix( )和glPopMatrix( )函数进行矩阵堆栈操作（包换模型视图矩阵和投影矩阵）。事实上，**glPushMatrix( )**表示“记住自己的位置”，即把当前堆栈中所有矩阵都下压一级。这个函数复制当前的顶部矩阵，并把它压到堆栈中。因此，刚调用完glPushMatrix( )函数时，堆栈最顶部的两个矩阵内容相同。而**glPopMatrix( )**表示“回到原来的位置”，即把堆栈顶部的矩阵弹出堆栈，销毁被弹出矩阵的内容。堆栈原先的第二个矩阵成为顶部矩阵。\n\n使用矩阵堆栈的效率要高于使用单独的堆栈，尤其是堆栈是用硬件实现时。压入一个矩阵时，并不需要把当前矩阵复制到主进程，并且硬件有可能一次能够复制多个矩阵元素。有时候，我们可能想在矩阵底部保存一个单位矩阵，以避免征象调用glLoadIdentity( )。\n\n**5 其他裁剪平面**  \n----------------\n除了视景体的6个裁剪平面（左、右、底、顶、近和远），还可以另外再指定最多可达6个的其他裁剪平面，对视景体进一步限制。这些裁剪平面可以用于删除场景中的无关物体，如我们可能只想显示一个物体的剖面视图。","source":"_posts/2013-07-27-0.md","raw":"---\ndate: 2013-07-27\nlayout: post\ntitle: openGL学习（三）-- 视图\npermalink: '/2013/07-27-0.html'\ncategories:\n- 游戏开发\ntags:\n- openGL\n---\n\n\n计算机图形的要点就是创建三维物体的二维图像（图像必须是二维的，因为它是在平面的屏幕上显示的）。我们要避免考虑屏幕上的像素是如何绘制的，而是要尽量在三维空间中想象物体的形状。\n\n本章主要介绍如何使用OpenGL完成如下任务：如何在三维空间中设置模型的位置和方向，以及如何确定观察者的位置（也是在三维空间中），最后能够准确地判断屏幕上所显示的图像。\n\n把一个物体的三维坐标变换为屏幕上的像素坐标，需要完成如下步骤：\n\n1. 变换包括模型、视图和投影操作，它们是由矩阵乘法表示的。这些操作包括旋转、移动、缩放、反射、正投影和透视投影等。一般情况下，在绘制场景时需要组合使用几种变换。\n2. 由于场景是在一个矩形窗口中渲染的，因此位于窗口之外的物体（或者物体的一部分）必须裁剪掉。在三维计算机图像中，裁剪就是丢弃位于裁剪平面之外的物体。\n3. 最后，经过了变换的坐标和屏幕像素之间必须建立对应关系。这个过程称为视口(viewport)变换。\n\n**1 简介：用照相机打比方**\n-----------------------\n产生目标场景视图的变换过程类似于用照相机进行拍照。\n\n1. 把照相机固定在三角架上，并让它对准场景（视图变换）。\n2. 对场景进行安排，使各个物体在照片中的位置是我们所希望的（模型变换）。\n3. 选择照相机镜头（广角镜头，标准镜头还是长焦镜头），并调整放大倍数（投影变换）。\n4. 确定最终照片的大小。例如，我们很可能需要把它放大（视口变换）。\n\n以下具体介绍各方面：  \n首先是**视图变换**。通常在指定视图变换之前，需要使用glLoadIdentity( )函数把当前矩阵(current matrix)设置为单位矩阵。这个步骤是非常有必要的，因为绝大多数变换是把当前矩阵与指定的矩阵相乘，然后把结果指定为当前矩阵。如果没有通过加载单位矩阵来清除当前矩阵，它所进行的变换实际上是把当前的变换与上一次变换进行了组合。虽然有些情况下，确实需要这样的操作，但是更多情况下，还是需要清除当前矩阵。  \n\n使用gluLookAt( )函数指定了视图变换。如gluLookAt(0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0)，若用照相机作比喻，则把照相机放在(0, 0, 5)的位置，把镜头瞄准(0, 0, 0)，并把朝上向量指定为(0, 1, 0)。如果没有调用gluLookAt( )函数，则照相机就被设置为默认的位置和方向。在默认情况下，照相机位于原点，指向Z轴的负方向，朝上向量为(0, 1, 0)。\n\n其次是**模型变换**。使用模型变换的目的是设置模型的位置和方向。例如，可以对模型进行旋转、移动和缩放，或者联合应用这些种操作。如模型变换函数glScalef(1.0, 3.0, 1.0)就是将模型y轴尺寸放大3倍。\n\n第三是**投影变换**。这种变换的目的是确定视野（或视景体），并因此确定哪些物体位于视野之内以及它们能够看到的程度。另外，投影变换还决定了物体是如何投影到屏幕上的。OpenGL提供了两种基本类型的投影，即透视投影（perspective projection）和正投影（orthographic projection）。透视投影类似于我们日常生活看到的景象。如果想创建现实感比较强的图像，就需要选择透视投影。而正投影直接映射到屏幕上，而不影响它们的相对大小，一般用于建筑和CAD应用程序中。\n\n与视图 / 模型变换一样，在设置投影变换之前，需要首先调用glMatrixMode(GL_PROJECTION)把当前矩阵指定为用于投影变换，再使用glLoadIdentity( )对当前的投影矩阵进行初始化。\n\n最后是**视口变换**。视口指定了场景在屏幕上所占据的区域，因此可以把视口变换看成是定义了最终经过处理的照片的大小和位置，如照片是否应该放大或者缩小。用glViewPort( )函数进行视口变换。\n\n视图变换、模型变换、投影变换和视口变换这四种变换一般将视图变换和模型变换分为一组，然后就剩下的再分为一组。视图变换和模型变换两种变换割裂开来是没有意义的。因为可以移动照相机（使用视图变换）来对准物体，也可以移动这个物体（模型变换）达到相同效果。而投影变换和视口变换则共同决定了场景是如何映射到计算机屏幕的。投影变换指定了映射的发生机制，而视口变换则决定了场景所映射的有效屏幕区域的形状。\n\n**2 视图变换和模型变换**\n----------------------\n注意，在执行模型或视图变换之前，必须以GL_MODELVIEW为参数调用glMatrixMode( )函数。\n\n视图变换和模型变换都是用一个4*4的矩阵表示的。每个后续的glMultMatrix*( )函数或变换函数把一个新的4*4的M与当前的模型视图C相乘，产生结果矩阵CM。最后，每个与当前的模型视图矩阵相乘。这个过程意味着程序所调用的最后一个变换函数实际上是首先应用于顶点的：CMv.\n\n如下面的代码序列，它使用3个变换绘制了1个点：\n\n\tglMatrixMode(GL_MODEVIEW);\n\tglLoadIdentity( );\n\tglMultMatrixf(N); /* apply transformation N */\n\tglMultMatrixf(M); /* apply transformation M */\n\tglMultMatrixf(L); /* apply transformation L */\n\tglBegin(GL_POINTS);\n\tglVertedx3f(v); /* draw transformed vertex v */\n\tglEnd( );\n\n在上述代码中，模型视图矩阵按顺序分别包含了I、N、NM，最后是NML，其中I表示单位矩阵。经过变换的顶点是NMLv。因此，顶点变换就是N(M(Lv))。所以，顶点v的变换是按照代码中相反的顺序发生的。\n\n在OpenGL中 ，有三个函数用于执行模型变换，分别为glTranslate*( )，glRotate*( )和glScale*( )。这三个函数都 相当于产生一个适当的移动、旋转或缩放矩阵，然后以这个矩阵作为参数调用glMultMatrix*( )。但是，使用这3个函数可能比使用glMultMatrix*( )速度更快，因为OpenGL会自动计算矩阵，一般来说比自己写的性能更高。\n\n而视图变换一般也是由移动和旋转组成的，即glTranslate*( )和glRotate*( )。为了在最终图像或照片上实现某种场景组合，可以移动照相机，也可以从相反的方向移动所有的物体。因此，一个按照逆时针方向旋转物体的模型变换相当于一个按顺时针方向旋转照相机的视图变换。**最后，要记住视图变换函数必须在调用任何模型变换函数之前调用，以确何首先作用于物体的是模型变换**。当然，除了直接使用移动和旋转函数之外，也可以使用工具函数gluLookAt( )实现视图变换，事实上一般也采用工具函数进行视图变换。\n\n**3 投影变换**\n--------------\n所谓投影变换就是定义投影矩阵用于对场景中的顶点进行变换。在调用手投影变换函数之前，必须首先进行以下操作：\n\n\tglMatrixMode(GL_PROJECTION);\n\tglLoadIdentity( );\n\n这样，接下来的变换函数将影响的是投影矩阵。由于每个投影变换函数都完整地描述了一个特定的变换，因此一般并不需要把投影变换与其他变换进行组合。\n\n投影变换的目的是定义一个视景体。视景体有两种用途。**首先，视景体决定了一个物体是如何映射到屏幕上的（即通过透视投影还是正投影）。其次，视影体定义了哪些物体（或物体的一部分）被裁剪到最终的图像之外**。\n\n投影变换分为两种，透视投影和正投影。\n\n透视投影方法常用于动画、视觉模拟以及其他要求某种程度的现实感的应用领域，因为它和我们在日常生活中观察事物的方式相同。该投影方法可以用glFrustum( )函数或者gluPerspective( )进行。\n\n正投影方法常用于建筑蓝图的计算机辅助设计（CAD）的应用程序。如果没有其他变换，投影的方向就与z轴平行，观察点的方向直接朝向z轴的负方向。该投影方法可以用glOrtho( )函数或者gluOrtho2D( )函数进行。\n\n**4 视口变换**\n--------------\n视口变换对应于选择被冲洗相片的大小这个阶段。我们希望照片像钱包一样大还是像海报一样大？在计算机图形中，视口是一个矩形的窗口区域，图像就是在这个区域中绘制的。\n\n在屏幕上打开窗口的是由窗口系统而不是OpenGL负责的。但是，在默认情况下，视口被设置为占据打开窗口的整个像素矩形。可以使用glViewPort( )函数选择一个更小的绘图区域。例如可以对窗口进行划分，在同一个窗口中显示分割屏幕的效果，以显示多个视图。\n\n使用glViewport( )函数进行视口变换，在默认情况下，礼品的初始值是(0, 0, winWidth, winHeight)，其中winWidth和winHeight分别为窗口的宽和高。\n\n**视口的纵横比一般和视景体的纵横比相同。如果这两个纵横比不同，当图像投影到视口时就会变形**。\n\n视口变换期间同时在做另一件事，那就是进行尝试坐标的编码（以后存储在尝试缓冲区中）。可以使用glDepthRange( )函数对z值进行缩放。**注意的是，与x和y窗口坐标不同，在OpenGL中，z坐标总是被认为位于0.0到1.0范围之间**。\n\n**4 操纵矩阵堆栈**\n------------------\n当我们对模型视图矩阵和投影矩阵进行创建、加载和乘法操作时，每一个操作针对的矩阵实际上是各自矩阵堆栈最顶部的那个元素，即栈顶的矩阵。换种说法就是，当前矩阵就是位于堆栈顶部的矩阵。\n\n可以采用glPushMatrix( )和glPopMatrix( )函数进行矩阵堆栈操作（包换模型视图矩阵和投影矩阵）。事实上，**glPushMatrix( )**表示“记住自己的位置”，即把当前堆栈中所有矩阵都下压一级。这个函数复制当前的顶部矩阵，并把它压到堆栈中。因此，刚调用完glPushMatrix( )函数时，堆栈最顶部的两个矩阵内容相同。而**glPopMatrix( )**表示“回到原来的位置”，即把堆栈顶部的矩阵弹出堆栈，销毁被弹出矩阵的内容。堆栈原先的第二个矩阵成为顶部矩阵。\n\n使用矩阵堆栈的效率要高于使用单独的堆栈，尤其是堆栈是用硬件实现时。压入一个矩阵时，并不需要把当前矩阵复制到主进程，并且硬件有可能一次能够复制多个矩阵元素。有时候，我们可能想在矩阵底部保存一个单位矩阵，以避免征象调用glLoadIdentity( )。\n\n**5 其他裁剪平面**  \n----------------\n除了视景体的6个裁剪平面（左、右、底、顶、近和远），还可以另外再指定最多可达6个的其他裁剪平面，对视景体进一步限制。这些裁剪平面可以用于删除场景中的无关物体，如我们可能只想显示一个物体的剖面视图。","slug":"/2013/07-27-0.html","published":1,"updated":"2015-06-19T16:09:05.000Z","comments":1,"photos":[],"link":"","_id":"ciiwjp30t003cof6gbahic1i5"},{"date":"2013-07-16T16:00:00.000Z","layout":"post","title":"openGL学习（二）-- 状态管理和绘制几何物体","_content":"\n\n在最高抽象层次上，有3种绘图是最基本的：**消除窗口，绘制几何图形，以及绘制光栅对象**(包括二维图像、位图和字体)。这里先介绍如何消除以及如何绘制几何物体，包括点、直接和平面多边形。\n\n**1　绘图工具箱**\n-----------------\n首先就是清除窗口。在计算机中，保存图片的内存通常被计算机所绘制的前一幅图像所填充，因此在绘制新场景之前，一般需要把它清除为某种背景颜色(具体为何种颜色为应用场景所定，若下一幅图像为全屏，则不清除窗口也可以，因为全屏的图像把上一幅图像全部遮住了)。\n\n这里这个问题，为什么在绘图之前清除窗口？如果画一个适当颜色的矩形，让它足够大，则和清除窗口的效果不是一样吗？但是清除窗口具有几点优势：\n\n1. 清除窗口函数(glClear( ))的效率可能远远高于普通的绘图函数；\n2. OpenGL允许程序员任意设置坐标系统、观察位置和观察方向。因此判定这个用于清除窗口的矩形的大小和位置可能非常困难；\n3.　除了屏幕上显示和像素颜色的缓冲区之外，还包括一些别的缓冲区（如深度缓冲区），而glClear( )命令可以清除按照任意形式组合的方式清除相应缓冲区，如glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT)命令直接方便地清除颜色缓冲区和深度缓冲区。\n\n其次就是指定颜色。在OpenGL，物体的开关与它的颜色无关。当一个特定的几何物体被绘制时，它是根据当前指定的方案进行绘制的。因此，OpenGL程序员首先设置颜色或者颜色方案（如用红色绘制所有的物体，又如物体由蓝色的塑料制成，有一盏黄色的聚光灯从某个方向对准物体表面的某个点），在这种颜色或者颜色方案被修改之前，所有的物体都用这种颜色或者颜色方案进行绘制。\n\n第三就是强制完成绘图操作。绝大多数的现代图像系统都可以看成是一条装配线（如福特汽车的汽车装配线）。在高端架构的计算机中，每一种操作都是由不同的硬件执行的。在这种情况下，如果CPU在发出下一条绘图命令之前还要等待前一条命令的完成，这无疑失去了流水装配线的强大优势。另外，应用程序可能在不同计算机上运行（主程序在一台称为客户机的计算机上，绘图结果则在另一台服务机上查看），它们之间每条绘图命令都是通过网络发送。通常客户机会把一组命令收集到一个网络包中，然后再将它们一起发送。但遗憾的是，如果这个网络包未填满，则它会一直等待下去，其结果就是在服务机上永远看不到绘图结果。\n\n因此，OpenGL提供了强制完成绘图操作glFlush( )。程序员应该在每个帧或者每个场景的最后添加一个glFlush( )调用。注意，这个操作并不等待绘图完成，它只是强制绘图命令开始执行。如果需要执行一些同步性的任务，以必需等待图形硬件或者网络提示帧缓冲区的绘图已经完成，则可以使用glFinish( )操作。\n\n最后就是坐标系统工具箱。绘图一定要设置一个坐标系。以下为简单地定义了一个2维坐标系：\n\n\tvoid reshape(int w, int h)\n\t{\n\t\tglViewport(0, 0, (GLsizei)w, (GLsizei)h);\n\t\tglMatrixMode(GL_PROJECTION);\n\t\tglLoadIdentity();\n\t\tgluOrtho2D(0.0, (GLdouble)w, 0.0, (GLdouble)h);\n\t}\n\n其定义了一个如屏幕相同像素的2维坐标系，原点(0, 0)在屏幕在左下角，屏幕右上角为点(w, h)。\n\n**2　描述点、直线和多边形**\n--------------------------\n　　OpenGL绘图都是由几个简单的几何图元构成的，如点、直线、多边形。而这几个简单的几何图元最终又是根据它们的顶点(vertex)来描述的。\n\n**3　基本状态管理**\n------------------\n　　OpenGL具有状态机特性，它维护了许多状态和状态变量，如光照、纹理、隐藏表面消除、雾以及其他影响物体外观的状态。在默认情况下，这些状态的大部分是处于不活动状态的，因为如果激活这些状态，OpenGL的渲染开销就会大大增大。因此，程序员应该按需对这些状态进行打开或者关闭。\n\n**4 　显示点、直线和多边形**\n--------------------------\n　　首先探讨一下点的细节。默认情况下，点被画成屏幕上的一个像素。当然，可以使用glPointSize( )控制被渲染点的大小。如果在抗锯齿功能被禁用的情况（默认）下，带小数的宽度值将四舍五入为整型值，在屏幕上所绘制的是对齐的正方形像素区域。如果启用了抗锯齿功能，则屏幕上绘制的将是一个圆形的区域，非整型的宽度值并不会四舍五入。\n\n　　其次就是直线的细节。OpenGL下的直线并不是数学中的直线，实际上为数学概念中的线段。默认情况下直线的宽度为1个像素，可以通过glLineWidth( )对直线宽度进行设置。注意，在未使用抗锯齿功能的情况下，直线的的宽度并不是根据与直线垂直的方便进行测量的。实际上，如果直接斜率的绝对值小于1.0，它是根据y轴的方向进行测量的。否则，它就根据x轴的方向进行测量。而在抗锯齿情况下，就是按照特定的宽度渲染一个填充多边形。\n\n　　然后就是多边形的细节。按照约定，多边形的顶点默认以逆时针顺序出现在屏幕上，通常称为“正面”。当然我们可以利用glFrontFace( )将顺时针方向的表面被认为是正面。另外，在默认情况下，填充多边形是用实心模式绘制的，我们可能利用glPolygonStipple( )将填充方式设定为32*32的点画模式(有点像印章)。\n\n**5　法线向量**\n---------------\n法线向量(简称法线)是一条垂直于某个表面的方向向量。物体的法线微量定义了它的表面在空间中的方向。具体地说，定义了它相对于光源的方向。OpenGL使用法线向量确定这个物体的各个顶点所接收的光照。在OpenGL中，除了之外，不能为多边形的其他地方分配法线。\n\n**6　顶点数组**\n--------------\nOpenGL提供了一些顶点数组函数，允许只用少数几个数组指定大量的顶点相关的数据，并用少量函数调用（与顶点数组的数量相仿）访问这些数据。\n把数据放在顶点数组中可以提高应用程序的性能。使用顶点数组可以减少函数调用的次数，从而提高性能。另外，使用顶点数组还可以避免共享顶点的冗余处理。\n使用顶点数据对几何图形进行渲染需要3个步骤:\n\n* 步骤一，启用数组。\n* 步骤二，指定数组的数据。\n* 步骤三，解引用和渲染。\n\n**7　缓冲区对象**\n----------------\n在许多OpenGL操作中，我们都向OpenGL发送一大块数据，例如向它传递需要处理的顶点数组数据。传输这种数据可能非常简单，如把数据从系统的内存中复制到图形卡。但是，由于OpenGL是按照客户机－服务器模式设计的，在OpenGL需要数据的任何时候，都必须把数据从客户机传输到服务器。如果数据并没有修改，或者客户机和服务器位于不同的计算机（分布式渲染），数据的传输可能会比较缓慢，或者是冗余的。\n\n所以，OpenGL在1.5开始，增加了缓冲区对象（buffer object），允许应用程序显式地指定把哪些数据存储在图形服务器中。\n\n* 第一、创建缓冲区对象。建议使用glGenBuffers( )接口让OpenGL分配标志符，以保证避免重复使用已被使用的缓冲区对象标识符，从而消除无意修改数据的风险。\n* 第二、激活缓冲区对象。激活缓冲区对象，首先需要将它绑定。绑定缓冲区对象表示选择未来的操作（对数据进行初始化或者使用缓冲区对象进行渲染）将影响到哪个缓冲区对象。\n* 第三、用数据分配和初始化缓冲区对象。具体情况参见glBufferData接口。\n* 第四、更新缓冲区对象的数据值。有两种方法可以更新存储在缓冲区对象中的数据。\n\n第一种方法假设我们已经在应用程序的一个缓冲区中准备了相同类型的数据。glBufferSubData( )将用我们提供的数据替换被绑定缓冲区对象的一些数据子集。\n\n第二种方法允许我们更灵活地选择需要更新的数据。即使用glMapBuffer( )返回一个指向缓冲区对象的指针，可以对这块内在进行修改更新缓冲区对象的数据。更新完毕后使用glUnmapBuffer( )取消对这个缓冲区的映射。\n\n注意，glMapBuffer( )提供了对缓冲区对象中包含的整个数据集合的访问。如果需要修改缓冲区中的大多数数据，这种方法很有用，但如果有一个很大的缓冲区并且只需要更新很小的一部分值，这种方法效率很低。在这种情况下，则使用glMapBufferRange( )效率更高。它允许只修改所需的范围内的数据值。\n\n* 第五，在缓冲区对象之间的复制数据。在OpenGL3.1之前，欲完成数据从一个缓冲区对象复制到别一个缓冲区对象，则必须分为两步走：首先将数据从缓冲区对象复制到应用程序的内存中，然后通过绑定到新的对象，现使用glBufferData( )初始化新的数据或者用glBufferSubData( )等方法更新缓冲区对象数据。显然这样做不是很优美，所以在3.1引入的glCopyBufferSubData( )接口直接将缓冲区对象A中的数据copy到缓冲区对象B中。\n\n* 第六，清除缓冲区对象。对缓冲区对象的操作完成之后，调用glDeleteBuffers( )接口对缓冲区对象进行清除。\n\n**8　顶点数组对象**\n------------------\n随着程序的增大并且使用更多的模型，在每个帧的多组顶点数组之间切换将不可避免。根据为每个顶点使用多少个顶点属性，你对glVertexPointer( )这样的函数的调用次数可能变得很大。因此，应该采用顶点数组对象提高效率。顶点数组对象捆绑了调用的集合，以设置顶点数据的状态。在初始化之后，可以通过单次调用在不同的数组集合之间快速修改。创建过程如下：\n\n首先，创建一个顶点数组对象。利用glGenvertexArrays( )函数。\n\n其次，初始化新的对象，并且把要使用的顶点数组数据的集合与单个已分配的对象关联起来。利用gBindVertexArray( )函数。\n\n这里不得不说顶点数组对象（VAO）和顶点缓冲对象（VBO）的区别。A Vertex Array Object (VAO) is an OpenGL Object that encapsulates all of the state needed to specify vertex data (with one minor exception noted below). They define the format of the vertex data as well as the sources for the vertex arrays. Note that VAOs do not contain the arrays themselves; the arrays are stored in Buffer Objects. The VAOs simply reference already existing buffer objects. OTHERWISE, A Vertex Buffer Object (VBO) is a Buffer Object which is used as the source for vertex array data.\n\n**9　属性组**\n-------------\nOpenGL可以设置或者查询一个单独的状态或状态变量。也可以用一个命令保存或恢复一组相关的状态变量的值。一般而言，使用这些函数，获取、保存和恢 复状态值的速度会更快一点。有些状态值可能是由硬件维护的，访问它们的开销可能较大。另外，如果是在远程客户机上进行操作，在获取、保存和恢复属性时，它们都要通过网络传输。但是，OpenGL实现可以把属性堆栈保存在服务器上，从而避免不必要的网络延迟。\n\n**10　创建多边形表面模型的一些提示**\n----------------------------------\n用多边形近似模拟法创建多边形表面模型是一项艺术，经验是均可替代的。下面是一些创建多边形表面模型的一些技巧：\n\n* 使多边形的方向（环绕）保持一致。\n* 对表面进行细分时，要密切注意那些非三角形的多边形。由于OpenGL可能无法正确地渲染非平面多边形，所有非三角形的多边形要保证其在同一平面。\n* 在显示速度和图像质量之间总存在一种权衡关系。理想的做法是向多边形细分函数提供一个参数，表示细分所达到的精度。如果物体距离距离较远，可以使用较为粗糙的的细分，另外，在进行细分时，在表面相对较平的区域，可以使用较大的多边形，而在曲率很大的表面部分，应该使用很小的多边形。\n* 为了实现高质量的图像，在轮廓边缘进行更精细的划分显然要比在表面内部进行精细划分的效果更好。\n* 如果想创建一个闭合的表面，确保闭合环的起点和终点使用完全相同的坐标，不然可能因为数值的四舍五入而产生有缺口的环。","source":"_posts/2013-07-17-0.md","raw":"---\ndate: 2013-07-17\nlayout: post\ntitle: openGL学习（二）-- 状态管理和绘制几何物体\npermalink: '/2013/07-17-0.html'\ncategories:\n- 游戏开发\ntags:\n- openGL\n---\n\n\n在最高抽象层次上，有3种绘图是最基本的：**消除窗口，绘制几何图形，以及绘制光栅对象**(包括二维图像、位图和字体)。这里先介绍如何消除以及如何绘制几何物体，包括点、直接和平面多边形。\n\n**1　绘图工具箱**\n-----------------\n首先就是清除窗口。在计算机中，保存图片的内存通常被计算机所绘制的前一幅图像所填充，因此在绘制新场景之前，一般需要把它清除为某种背景颜色(具体为何种颜色为应用场景所定，若下一幅图像为全屏，则不清除窗口也可以，因为全屏的图像把上一幅图像全部遮住了)。\n\n这里这个问题，为什么在绘图之前清除窗口？如果画一个适当颜色的矩形，让它足够大，则和清除窗口的效果不是一样吗？但是清除窗口具有几点优势：\n\n1. 清除窗口函数(glClear( ))的效率可能远远高于普通的绘图函数；\n2. OpenGL允许程序员任意设置坐标系统、观察位置和观察方向。因此判定这个用于清除窗口的矩形的大小和位置可能非常困难；\n3.　除了屏幕上显示和像素颜色的缓冲区之外，还包括一些别的缓冲区（如深度缓冲区），而glClear( )命令可以清除按照任意形式组合的方式清除相应缓冲区，如glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT)命令直接方便地清除颜色缓冲区和深度缓冲区。\n\n其次就是指定颜色。在OpenGL，物体的开关与它的颜色无关。当一个特定的几何物体被绘制时，它是根据当前指定的方案进行绘制的。因此，OpenGL程序员首先设置颜色或者颜色方案（如用红色绘制所有的物体，又如物体由蓝色的塑料制成，有一盏黄色的聚光灯从某个方向对准物体表面的某个点），在这种颜色或者颜色方案被修改之前，所有的物体都用这种颜色或者颜色方案进行绘制。\n\n第三就是强制完成绘图操作。绝大多数的现代图像系统都可以看成是一条装配线（如福特汽车的汽车装配线）。在高端架构的计算机中，每一种操作都是由不同的硬件执行的。在这种情况下，如果CPU在发出下一条绘图命令之前还要等待前一条命令的完成，这无疑失去了流水装配线的强大优势。另外，应用程序可能在不同计算机上运行（主程序在一台称为客户机的计算机上，绘图结果则在另一台服务机上查看），它们之间每条绘图命令都是通过网络发送。通常客户机会把一组命令收集到一个网络包中，然后再将它们一起发送。但遗憾的是，如果这个网络包未填满，则它会一直等待下去，其结果就是在服务机上永远看不到绘图结果。\n\n因此，OpenGL提供了强制完成绘图操作glFlush( )。程序员应该在每个帧或者每个场景的最后添加一个glFlush( )调用。注意，这个操作并不等待绘图完成，它只是强制绘图命令开始执行。如果需要执行一些同步性的任务，以必需等待图形硬件或者网络提示帧缓冲区的绘图已经完成，则可以使用glFinish( )操作。\n\n最后就是坐标系统工具箱。绘图一定要设置一个坐标系。以下为简单地定义了一个2维坐标系：\n\n\tvoid reshape(int w, int h)\n\t{\n\t\tglViewport(0, 0, (GLsizei)w, (GLsizei)h);\n\t\tglMatrixMode(GL_PROJECTION);\n\t\tglLoadIdentity();\n\t\tgluOrtho2D(0.0, (GLdouble)w, 0.0, (GLdouble)h);\n\t}\n\n其定义了一个如屏幕相同像素的2维坐标系，原点(0, 0)在屏幕在左下角，屏幕右上角为点(w, h)。\n\n**2　描述点、直线和多边形**\n--------------------------\n　　OpenGL绘图都是由几个简单的几何图元构成的，如点、直线、多边形。而这几个简单的几何图元最终又是根据它们的顶点(vertex)来描述的。\n\n**3　基本状态管理**\n------------------\n　　OpenGL具有状态机特性，它维护了许多状态和状态变量，如光照、纹理、隐藏表面消除、雾以及其他影响物体外观的状态。在默认情况下，这些状态的大部分是处于不活动状态的，因为如果激活这些状态，OpenGL的渲染开销就会大大增大。因此，程序员应该按需对这些状态进行打开或者关闭。\n\n**4 　显示点、直线和多边形**\n--------------------------\n　　首先探讨一下点的细节。默认情况下，点被画成屏幕上的一个像素。当然，可以使用glPointSize( )控制被渲染点的大小。如果在抗锯齿功能被禁用的情况（默认）下，带小数的宽度值将四舍五入为整型值，在屏幕上所绘制的是对齐的正方形像素区域。如果启用了抗锯齿功能，则屏幕上绘制的将是一个圆形的区域，非整型的宽度值并不会四舍五入。\n\n　　其次就是直线的细节。OpenGL下的直线并不是数学中的直线，实际上为数学概念中的线段。默认情况下直线的宽度为1个像素，可以通过glLineWidth( )对直线宽度进行设置。注意，在未使用抗锯齿功能的情况下，直线的的宽度并不是根据与直线垂直的方便进行测量的。实际上，如果直接斜率的绝对值小于1.0，它是根据y轴的方向进行测量的。否则，它就根据x轴的方向进行测量。而在抗锯齿情况下，就是按照特定的宽度渲染一个填充多边形。\n\n　　然后就是多边形的细节。按照约定，多边形的顶点默认以逆时针顺序出现在屏幕上，通常称为“正面”。当然我们可以利用glFrontFace( )将顺时针方向的表面被认为是正面。另外，在默认情况下，填充多边形是用实心模式绘制的，我们可能利用glPolygonStipple( )将填充方式设定为32*32的点画模式(有点像印章)。\n\n**5　法线向量**\n---------------\n法线向量(简称法线)是一条垂直于某个表面的方向向量。物体的法线微量定义了它的表面在空间中的方向。具体地说，定义了它相对于光源的方向。OpenGL使用法线向量确定这个物体的各个顶点所接收的光照。在OpenGL中，除了之外，不能为多边形的其他地方分配法线。\n\n**6　顶点数组**\n--------------\nOpenGL提供了一些顶点数组函数，允许只用少数几个数组指定大量的顶点相关的数据，并用少量函数调用（与顶点数组的数量相仿）访问这些数据。\n把数据放在顶点数组中可以提高应用程序的性能。使用顶点数组可以减少函数调用的次数，从而提高性能。另外，使用顶点数组还可以避免共享顶点的冗余处理。\n使用顶点数据对几何图形进行渲染需要3个步骤:\n\n* 步骤一，启用数组。\n* 步骤二，指定数组的数据。\n* 步骤三，解引用和渲染。\n\n**7　缓冲区对象**\n----------------\n在许多OpenGL操作中，我们都向OpenGL发送一大块数据，例如向它传递需要处理的顶点数组数据。传输这种数据可能非常简单，如把数据从系统的内存中复制到图形卡。但是，由于OpenGL是按照客户机－服务器模式设计的，在OpenGL需要数据的任何时候，都必须把数据从客户机传输到服务器。如果数据并没有修改，或者客户机和服务器位于不同的计算机（分布式渲染），数据的传输可能会比较缓慢，或者是冗余的。\n\n所以，OpenGL在1.5开始，增加了缓冲区对象（buffer object），允许应用程序显式地指定把哪些数据存储在图形服务器中。\n\n* 第一、创建缓冲区对象。建议使用glGenBuffers( )接口让OpenGL分配标志符，以保证避免重复使用已被使用的缓冲区对象标识符，从而消除无意修改数据的风险。\n* 第二、激活缓冲区对象。激活缓冲区对象，首先需要将它绑定。绑定缓冲区对象表示选择未来的操作（对数据进行初始化或者使用缓冲区对象进行渲染）将影响到哪个缓冲区对象。\n* 第三、用数据分配和初始化缓冲区对象。具体情况参见glBufferData接口。\n* 第四、更新缓冲区对象的数据值。有两种方法可以更新存储在缓冲区对象中的数据。\n\n第一种方法假设我们已经在应用程序的一个缓冲区中准备了相同类型的数据。glBufferSubData( )将用我们提供的数据替换被绑定缓冲区对象的一些数据子集。\n\n第二种方法允许我们更灵活地选择需要更新的数据。即使用glMapBuffer( )返回一个指向缓冲区对象的指针，可以对这块内在进行修改更新缓冲区对象的数据。更新完毕后使用glUnmapBuffer( )取消对这个缓冲区的映射。\n\n注意，glMapBuffer( )提供了对缓冲区对象中包含的整个数据集合的访问。如果需要修改缓冲区中的大多数数据，这种方法很有用，但如果有一个很大的缓冲区并且只需要更新很小的一部分值，这种方法效率很低。在这种情况下，则使用glMapBufferRange( )效率更高。它允许只修改所需的范围内的数据值。\n\n* 第五，在缓冲区对象之间的复制数据。在OpenGL3.1之前，欲完成数据从一个缓冲区对象复制到别一个缓冲区对象，则必须分为两步走：首先将数据从缓冲区对象复制到应用程序的内存中，然后通过绑定到新的对象，现使用glBufferData( )初始化新的数据或者用glBufferSubData( )等方法更新缓冲区对象数据。显然这样做不是很优美，所以在3.1引入的glCopyBufferSubData( )接口直接将缓冲区对象A中的数据copy到缓冲区对象B中。\n\n* 第六，清除缓冲区对象。对缓冲区对象的操作完成之后，调用glDeleteBuffers( )接口对缓冲区对象进行清除。\n\n**8　顶点数组对象**\n------------------\n随着程序的增大并且使用更多的模型，在每个帧的多组顶点数组之间切换将不可避免。根据为每个顶点使用多少个顶点属性，你对glVertexPointer( )这样的函数的调用次数可能变得很大。因此，应该采用顶点数组对象提高效率。顶点数组对象捆绑了调用的集合，以设置顶点数据的状态。在初始化之后，可以通过单次调用在不同的数组集合之间快速修改。创建过程如下：\n\n首先，创建一个顶点数组对象。利用glGenvertexArrays( )函数。\n\n其次，初始化新的对象，并且把要使用的顶点数组数据的集合与单个已分配的对象关联起来。利用gBindVertexArray( )函数。\n\n这里不得不说顶点数组对象（VAO）和顶点缓冲对象（VBO）的区别。A Vertex Array Object (VAO) is an OpenGL Object that encapsulates all of the state needed to specify vertex data (with one minor exception noted below). They define the format of the vertex data as well as the sources for the vertex arrays. Note that VAOs do not contain the arrays themselves; the arrays are stored in Buffer Objects. The VAOs simply reference already existing buffer objects. OTHERWISE, A Vertex Buffer Object (VBO) is a Buffer Object which is used as the source for vertex array data.\n\n**9　属性组**\n-------------\nOpenGL可以设置或者查询一个单独的状态或状态变量。也可以用一个命令保存或恢复一组相关的状态变量的值。一般而言，使用这些函数，获取、保存和恢 复状态值的速度会更快一点。有些状态值可能是由硬件维护的，访问它们的开销可能较大。另外，如果是在远程客户机上进行操作，在获取、保存和恢复属性时，它们都要通过网络传输。但是，OpenGL实现可以把属性堆栈保存在服务器上，从而避免不必要的网络延迟。\n\n**10　创建多边形表面模型的一些提示**\n----------------------------------\n用多边形近似模拟法创建多边形表面模型是一项艺术，经验是均可替代的。下面是一些创建多边形表面模型的一些技巧：\n\n* 使多边形的方向（环绕）保持一致。\n* 对表面进行细分时，要密切注意那些非三角形的多边形。由于OpenGL可能无法正确地渲染非平面多边形，所有非三角形的多边形要保证其在同一平面。\n* 在显示速度和图像质量之间总存在一种权衡关系。理想的做法是向多边形细分函数提供一个参数，表示细分所达到的精度。如果物体距离距离较远，可以使用较为粗糙的的细分，另外，在进行细分时，在表面相对较平的区域，可以使用较大的多边形，而在曲率很大的表面部分，应该使用很小的多边形。\n* 为了实现高质量的图像，在轮廓边缘进行更精细的划分显然要比在表面内部进行精细划分的效果更好。\n* 如果想创建一个闭合的表面，确保闭合环的起点和终点使用完全相同的坐标，不然可能因为数值的四舍五入而产生有缺口的环。","slug":"/2013/07-17-0.html","published":1,"updated":"2015-06-19T16:09:05.000Z","comments":1,"photos":[],"link":"","_id":"ciiwjp30v003fof6g3j7xwp2x"},{"date":"2013-07-14T16:00:00.000Z","layout":"post","title":"自省一则","_content":"\n\n一个人在某一方面的层次分为4层，即**不知道自己不知道，知道自己不知道，知道自己知道，不知道自己知道**。虽然很绕，但细细想来，还是很有道理的。而小猿自认为自己目前处在第二层，即知道自己不知道，所以也偶尔发奋努力下，但通常是三天打鱼，两天晒网了。所以在成就系统里至今也没有什么拿得出手的。最近小猿拜读了Andy Hunt的[《程序员思维修炼——开发认知潜能的九堂课》](http://book.douban.com/subject/5372651/)，读后思维万纤（其实是被打了鸡血，顿时兴奋无比），也准备对自己重新定位下。\n\n说到定位，Andy向我们展现了[Dreyfus模型](http://en.wikipedia.org/wiki/Dreyfus_model_of_skill_acquisition)，它分为5个阶段：**新手->高级新手->胜任者->精通者->专家**。这个历程也是任何人在任何方面从新手成为专家的必经之路。每个在低层次阶段的人都渴望成为高层次阶段的人（除没有进取心的人以外），但遗憾的是，在任何一方面80%的人都只能是新手（其实小猿觉得远远超过，最起码95%以上）。比如，小猿会fix bug，但不会fix computer，会骑自行车，但不会修自行车，会煮饭，但不会烧菜。小猿360行，只会做code monkey。所以说，我们绝大部分人都是新手。\n\n新手在该领域经验很少或者根本没有经验。所以**新手工作时，他需要的是规则与指令**。如果没有一个明确的规则，新手不知道应该做什么，而且出错的时候，他们非常容易慌乱。没有一个既定的目标与规则，如“当X发生时，请执行Y”，那么新手将不知所措。\n\n而高级新手则并不需要规则，他们可以独自尝试完成任务，但是只能根据过去的经验去完成任务，**缺乏全局思维**，有时候仍难以解决问题。\n\n新手与高级新手终究是newer范畴，需要一位导师带着，对其发出任务指令或者为其掌舵，让它们顺利启程与航行。而经历了新手与高级新手两个阶段，我们将迎来胜任者阶段。故名思义，所谓胜任者，即是对任务胜任的人。他们可以独立解决自己遇到的问题，并开始考虑如何解决新的问题，当然也可以指导新手，甚至可以寻求与利用专家的意见，并顺利完成相应的任务。虽然胜任者能够解决问题，但是他们**缺乏足够的能力进行反思与自我纠正**。\n\n而胜任者有能力从专家或者书本中获得经验，并且进行自我纠正，使自身对该方向技能的掌握程度更进一步时，他们就进入了精通者阶段。精通者能够纠正以往不好的表现，反思以前是如何做的，并修正其做法，期望下一次表现得更好。他们**形成了一条反馈线路，这次的经历将会做为下次的输入，并且影响下次的结果表现**。\n\n当然，一个技能领域的顶峰就是成为该方面的专家。**专家是各个领域知识和信息的主要来源**，他们是整个行业的风向标。所以，小猿认为非专家的人对专家的关注是十分有必要的。如果想在这一行混，却对这行的信息了解甚少，那还混个P啊（Sorry，激动了下）。\n\n扯了这么多，小猿对自己的定位目前徘徊在胜任者，而且对精通者遥不可及。一方面，精通确实不易；另一方面，小猿虽然看了一些专家的书（经验），但对其转换成自己生产力的能力还不足。经常说“知易行难”，“理论与实践是有差距的”，确实，小猿给自己下定义：本人目前处于而且将长期处于coding的胜任者阶段，并坚持向精通者进发的目标不动摇，最终实现专家的梦想！","source":"_posts/2013-07-15-0.md","raw":"---\ndate: 2013-07-15\nlayout: post\ntitle: 自省一则\npermalink: '/2013/07-15-0.html'\ncategories:\n- 杂感\ntags:\n---\n\n\n一个人在某一方面的层次分为4层，即**不知道自己不知道，知道自己不知道，知道自己知道，不知道自己知道**。虽然很绕，但细细想来，还是很有道理的。而小猿自认为自己目前处在第二层，即知道自己不知道，所以也偶尔发奋努力下，但通常是三天打鱼，两天晒网了。所以在成就系统里至今也没有什么拿得出手的。最近小猿拜读了Andy Hunt的[《程序员思维修炼——开发认知潜能的九堂课》](http://book.douban.com/subject/5372651/)，读后思维万纤（其实是被打了鸡血，顿时兴奋无比），也准备对自己重新定位下。\n\n说到定位，Andy向我们展现了[Dreyfus模型](http://en.wikipedia.org/wiki/Dreyfus_model_of_skill_acquisition)，它分为5个阶段：**新手->高级新手->胜任者->精通者->专家**。这个历程也是任何人在任何方面从新手成为专家的必经之路。每个在低层次阶段的人都渴望成为高层次阶段的人（除没有进取心的人以外），但遗憾的是，在任何一方面80%的人都只能是新手（其实小猿觉得远远超过，最起码95%以上）。比如，小猿会fix bug，但不会fix computer，会骑自行车，但不会修自行车，会煮饭，但不会烧菜。小猿360行，只会做code monkey。所以说，我们绝大部分人都是新手。\n\n新手在该领域经验很少或者根本没有经验。所以**新手工作时，他需要的是规则与指令**。如果没有一个明确的规则，新手不知道应该做什么，而且出错的时候，他们非常容易慌乱。没有一个既定的目标与规则，如“当X发生时，请执行Y”，那么新手将不知所措。\n\n而高级新手则并不需要规则，他们可以独自尝试完成任务，但是只能根据过去的经验去完成任务，**缺乏全局思维**，有时候仍难以解决问题。\n\n新手与高级新手终究是newer范畴，需要一位导师带着，对其发出任务指令或者为其掌舵，让它们顺利启程与航行。而经历了新手与高级新手两个阶段，我们将迎来胜任者阶段。故名思义，所谓胜任者，即是对任务胜任的人。他们可以独立解决自己遇到的问题，并开始考虑如何解决新的问题，当然也可以指导新手，甚至可以寻求与利用专家的意见，并顺利完成相应的任务。虽然胜任者能够解决问题，但是他们**缺乏足够的能力进行反思与自我纠正**。\n\n而胜任者有能力从专家或者书本中获得经验，并且进行自我纠正，使自身对该方向技能的掌握程度更进一步时，他们就进入了精通者阶段。精通者能够纠正以往不好的表现，反思以前是如何做的，并修正其做法，期望下一次表现得更好。他们**形成了一条反馈线路，这次的经历将会做为下次的输入，并且影响下次的结果表现**。\n\n当然，一个技能领域的顶峰就是成为该方面的专家。**专家是各个领域知识和信息的主要来源**，他们是整个行业的风向标。所以，小猿认为非专家的人对专家的关注是十分有必要的。如果想在这一行混，却对这行的信息了解甚少，那还混个P啊（Sorry，激动了下）。\n\n扯了这么多，小猿对自己的定位目前徘徊在胜任者，而且对精通者遥不可及。一方面，精通确实不易；另一方面，小猿虽然看了一些专家的书（经验），但对其转换成自己生产力的能力还不足。经常说“知易行难”，“理论与实践是有差距的”，确实，小猿给自己下定义：本人目前处于而且将长期处于coding的胜任者阶段，并坚持向精通者进发的目标不动摇，最终实现专家的梦想！","slug":"/2013/07-15-0.html","published":1,"updated":"2015-06-19T16:09:05.000Z","comments":1,"photos":[],"link":"","_id":"ciiwjp30y003iof6ga3yqhix7"},{"date":"2013-06-28T16:00:00.000Z","layout":"post","title":"openGL学习（一）-- 简介","_content":"\n\n**1　什么是OpenGL, 它能够做什么，不能够做什么？**\n--------------------------------------------\nOpenGL是图形硬件的一种软件接口。OpenGL包含700多个函数（OpenGL3.0），这些函数可以用于指定物体和操作，创建交互式的三维应用程序。但OpenGL并未包含用于执行窗口任务或者获取用户输入之类的函数，也不提供用于描述三维物体模型的高级函数，如汽车。身体的某个部分、飞机等。OpenGL只包含一些为数不多的基本几何图元，如点、直线和多边形。\n\n**2　OpenGL对场景中图像进行渲染时所执行的主要图形操作。**\n--------------------------------------------------\n\n1. 根据几何图元(点、直线、多边形和位图)创建形状，从而建立物体的数学描述；\n2. 在三维空间中排列物体、并选择观察复合场景的视角；\n3. 计算所有物体的颜色。这个计算过程可以由着色器来执行，也可以使用OpenGL的预编程算法在其内部执行(固定功能的管线)\n4. 光栅化(rasterization)，即把物体的数学描述以及与物体相关的颜色信息转换为屏幕上的像素。\n\n**3　OpenGL的状态机特性。**\n------------------------\nOpenGL是一个状态机，可以对它的各种状态进行设置，直抒到再次修改它们。如当前颜色就是一种状态，若当前颜色为红色，则绘制出的所有物体都将是红色，直到下次修改OpenGL的颜色状态为止。另外，许多表示模式的状态可以用glEnable()和glDisable()启用或者禁用。\n\n**4　OpenGL渲染管线：展示一个用于处理几何和图像数据的典型操作序列。**\n--------------------------------------------------------------\n![渲染管线](/img/2013-06-29-0.png \"渲染管线\")\n\nOpenGL渲染管线分为两条路，一为几何数据（顶点、直接和多边形）处理，二为像素数据（像素、图像和位图）处理。\n\n**5　OpenGL如何实现动画？**\n--------------------------\n在电影院里，屏幕上的运动画面是通过拍摄大量的图片，然后以每秒24帧的频率把它们投影到屏幕上来实现的。而OpenGL实现动画也如此。如以下代码：\n\n\topen_window();\n\tfor (i = 0; i < 1000000; +=i) {\n\t     clear_the_window();\n\t     draw_frame(i);\n\t     wait_untile_a_24th_of_a_second_is_over();\n\t}\n\n但是这个方法仅仅局限于clear_the_window( )和draw_frame( )方法在1/24秒内完成，若这两个操作所需时间大于1/24秒，则动画就显得不平滑。所以绝大多数OpenGL实现提供双缓冲（包括硬件或者软件），即提供两个完整的颜色缓冲区。于是过程就变成如下形式：\n\n\topen_window_in_double_buffer_mode();\n\tfor (i = 0; i < 1000000; +=i) {\n\t\tclear_the_window();\n\t\tdraw_frame(i);\n\t\tswap_the_buffers  ();\n\t}\n","source":"_posts/2013-06-29-0.md","raw":"---\ndate: 2013-06-29\nlayout: post\ntitle: openGL学习（一）-- 简介\npermalink: '/2013/06-29-0.html'\ncategories:\n- 游戏开发\ntags:\n- openGL\n---\n\n\n**1　什么是OpenGL, 它能够做什么，不能够做什么？**\n--------------------------------------------\nOpenGL是图形硬件的一种软件接口。OpenGL包含700多个函数（OpenGL3.0），这些函数可以用于指定物体和操作，创建交互式的三维应用程序。但OpenGL并未包含用于执行窗口任务或者获取用户输入之类的函数，也不提供用于描述三维物体模型的高级函数，如汽车。身体的某个部分、飞机等。OpenGL只包含一些为数不多的基本几何图元，如点、直线和多边形。\n\n**2　OpenGL对场景中图像进行渲染时所执行的主要图形操作。**\n--------------------------------------------------\n\n1. 根据几何图元(点、直线、多边形和位图)创建形状，从而建立物体的数学描述；\n2. 在三维空间中排列物体、并选择观察复合场景的视角；\n3. 计算所有物体的颜色。这个计算过程可以由着色器来执行，也可以使用OpenGL的预编程算法在其内部执行(固定功能的管线)\n4. 光栅化(rasterization)，即把物体的数学描述以及与物体相关的颜色信息转换为屏幕上的像素。\n\n**3　OpenGL的状态机特性。**\n------------------------\nOpenGL是一个状态机，可以对它的各种状态进行设置，直抒到再次修改它们。如当前颜色就是一种状态，若当前颜色为红色，则绘制出的所有物体都将是红色，直到下次修改OpenGL的颜色状态为止。另外，许多表示模式的状态可以用glEnable()和glDisable()启用或者禁用。\n\n**4　OpenGL渲染管线：展示一个用于处理几何和图像数据的典型操作序列。**\n--------------------------------------------------------------\n![渲染管线](/img/2013-06-29-0.png \"渲染管线\")\n\nOpenGL渲染管线分为两条路，一为几何数据（顶点、直接和多边形）处理，二为像素数据（像素、图像和位图）处理。\n\n**5　OpenGL如何实现动画？**\n--------------------------\n在电影院里，屏幕上的运动画面是通过拍摄大量的图片，然后以每秒24帧的频率把它们投影到屏幕上来实现的。而OpenGL实现动画也如此。如以下代码：\n\n\topen_window();\n\tfor (i = 0; i < 1000000; +=i) {\n\t     clear_the_window();\n\t     draw_frame(i);\n\t     wait_untile_a_24th_of_a_second_is_over();\n\t}\n\n但是这个方法仅仅局限于clear_the_window( )和draw_frame( )方法在1/24秒内完成，若这两个操作所需时间大于1/24秒，则动画就显得不平滑。所以绝大多数OpenGL实现提供双缓冲（包括硬件或者软件），即提供两个完整的颜色缓冲区。于是过程就变成如下形式：\n\n\topen_window_in_double_buffer_mode();\n\tfor (i = 0; i < 1000000; +=i) {\n\t\tclear_the_window();\n\t\tdraw_frame(i);\n\t\tswap_the_buffers  ();\n\t}\n","slug":"/2013/06-29-0.html","published":1,"updated":"2015-06-19T16:09:05.000Z","comments":1,"photos":[],"link":"","_id":"ciiwjp311003kof6g5ejxcdza"},{"date":"2013-06-22T16:00:00.000Z","layout":"post","title":"编程语言与编程思维杂感","_content":"\n\n**“编程语言不仅仅是一种技术，它更是一种思维。” －－ Paul Graham**\n\n以前经常看到这样的言论：“什么C/C++，Java, C#等等都是编程语言而已，实现你想法的工具，学好一门语言，以不变应万变，就算用其他语言也是差不多的，只是工具变了而已。”这样的说法真心有失偏颇。没错，什么语言都只是工具，但他们不仅仅是工具，也包含了用这种工具时候所形成的思维方式。\n\n“著名的语言学家Roman Jakobson曾用一句简单的名言指明了语言之间最关键的不同之处：语言之间的不同本质在于它们能够传达的信息，而不是它们不能传达的信息。这句名言告诉了我们解放我们母语潜能的关键所在：不同的语言用不同的方式影响我们的大脑思维，这并不是因为这种语言可以让我们这样思考问题，而是它在强迫你这样思考。”\n“当你的语言日常的强迫你去使用某些类型的信息进行说明，这会迫使你去留意那些使用其它种语言的人平时不会注意的某些细节和体验。因为这种说法的习惯是从小养成的，这种习惯已经成为大脑思维的习惯，超越了语言本身，直接影响了你的言行，感知，联想，感觉，记忆，以及世界观。”\n\nJokobson的名言同样也适合于编程语言界，不同语言对于程序员的思维要求并不是一样的。如C语言作为一门过程性语言，给予程序员的思维就是过程性的，先做什么，后做什么，任何一个步骤都是线性过程思维。而Java给我们带来的是一切均为对象的思维，当程序员码出任何一行代码之前所思考的是如何构成当前这个对象，该对象有何数据，有何处理这些数据的方法。所以，两种程序员码出来的代码是完全两种风格的。\n\nC和Java两种程序员码出来的代码当然是两种风格的，这有什么大惊小怪的。但是同样两位Java程序员码出来的Java代码也是风格各异，同样的工具，在不同思维的带领下，就会产生不同的结果。\n\n举个例子，有一棵Tree，遍历其结点，并进行打印各结点的值。\n\nExample 1:\n\n\tclass Tree {\n\tpublic:\n\t    Tree(const std::string& name, const std::vector<Tree*> children);\n\t    ~Tree();\n\t \n\t    void visit();\n\t \n\t    void visitAll();\n\t \n\t    std::string getName()const { return m_name; }\n\t \n\tprivate:\n\t    std::vector<Tree*> m_children;\n\t    std::string m_name;\n\t};\n\t \n\tTree::Tree(const std::string& name, const std::vector<Tree*> children)\n\t    : m_name(name),\n\t      m_children(children)\n\t{\n\t \n\t}\n\t \n\tTree::~Tree()\n\t{\n\t    for_each(m_children.begin(), m_children.end(), [](Tree* child){ delete child; });\n\t}\n\t \n\tvoid Tree::visit()\n\t{\n\t    std::cout << m_name << std::endl;\n\t}\n\t \n\tvoid Tree::visitAll(std::function<void(Tree*)> action)\n\t{\n\t    visit(action);\n\t \n\t    for (int i = 0; i < m_children.size(); ++i) {        m_children[i]->visitAll(action);\n\t    }\n\t}\n\t \n\tstatic Tree* constructTree()\n\t{\n\t    std::vector<Tree*> v;\n\t    std::vector<Tree*> emptyVector;\n\t    v.push_back(new Tree(\"left child\", emptyVector));\n\t    v.push_back(new Tree(\"right child\", emptyVector));\n\t \n\t    return new Tree(\"root\", v);\n\t}\n\t \n\tstatic void destructTree(Tree* t)\n\t{\n\t    delete t;\n\t}\n\t \n\tint main()\n\t{\n\t    Tree* root = constructTree();\n\t \n\t    root->visitAll();\n\t \n\t    destructTree(root);\n\t \n\t    return 0;\n\t}\n\n没错，上述实现方法的确可行，但是如果遍历每一个结点，具体的操作由客户(依然是程序员)来决定，那又如何？似乎思路被堵住了。奥秘如下：\n\nExample 2:\n\n\tclass Tree {\n\tpublic:\n\t    Tree(const std::string& name, const std::vector<Tree*> children);\n\t    ~Tree();\n\t \n\t    void visit(std::function<void(Tree*)> action);\n\t \n\t    void visitAll(std::function<void(Tree*)> action);\n\t \n\t    std::string getName()const { return m_name; }\n\t \n\tprivate:\n\t    std::vector<Tree*> m_children;\n\t    std::string m_name;\n\t};\n\t \n\tTree::Tree(const std::string& name, const std::vector<Tree*> children)\n\t    : m_name(name),\n\t      m_children(children)\n\t{\n\t \n\t}\n\t \n\tTree::~Tree()\n\t{\n\t    for_each(m_children.begin(), m_children.end(), [](Tree* child){ delete child; });\n\t}\n\t \n\tvoid Tree::visit(std::function<void(Tree*)> action)\n\t{\n\t    action(this);\n\t}\n\t \n\tvoid Tree::visitAll(std::function<void(Tree*)> action)\n\t{\n\t    visit(action);\n\t \n\t    for (int i = 0; i < m_children.size(); ++i) {        m_children[i]->visitAll(action);\n\t    }\n\t}\n\t \n\tstatic Tree* constructTree()\n\t{\n\t    std::vector<Tree*> v;\n\t    std::vector<Tree*> emptyVector;\n\t    v.push_back(new Tree(\"left child\", emptyVector));\n\t    v.push_back(new Tree(\"right child\", emptyVector));\n\t \n\t    return new Tree(\"root\", v);\n\t}\n\t \n\tstatic void destructTree(Tree* t)\n\t{\n\t    delete t;\n\t}\n\t \n\tint main()\n\t{\n\t    Tree* root = constructTree();\n\t \n\t    root->visitAll([](Tree* t) { std::cout << t->getName() << std::endl; });\n\t \n\t    destructTree(root);\n\t \n\t    return 0;\n\t}\n\n相当巧妙的思维，其实也是受一段ruby代码的启发，不同的程序语言的思维的启发。所以大神们说，每年至少学习一门新的编程语言是相当有道理的。当然我们学习它并不是为了把它使用在工作中（若是能使用那再好不过，因为实践是最好的老师），而是学习该语言随之而来的编程思维，如同简单的遍历Tree一样。\n\n最后，附上启发这篇怪文的Ruby源码。\n\n\tclass Tree\n\t    attr_accessor :children, :node_name\n\t \n\t    def initialize(name, children = [])\n\t        @children = children\n\t        @node_name = name\n\t    end\n\t \n\t    def visit_all(&block)\n\t        visit(&block)\n\t        children.each { |c| c.visit_all &block }\n\t    end\n\t \n\t    def visit(&block)\n\t        block.call self\n\t    end\n\tend\n\t \n\truby_tree = Tree.new(\"Ruby\",\n\t    [Tree.new(\"Reia\"),\n\t        Tree.new(\"MacRuby\")])\n\t \n\tputs \"Visiting a node\"\n\truby_tree.visit { |node| puts node.node_name }\n\t \n\tputs \"Visiting entire tree\"\n\truby_tree.visit_all { |node| puts node.node_name }","source":"_posts/2013-06-23-0.md","raw":"---\ndate: 2013-06-23\nlayout: post\ntitle: 编程语言与编程思维杂感\npermalink: '/2013/06-23-0.html'\ncategories: 编程思维\ntags:\n---\n\n\n**“编程语言不仅仅是一种技术，它更是一种思维。” －－ Paul Graham**\n\n以前经常看到这样的言论：“什么C/C++，Java, C#等等都是编程语言而已，实现你想法的工具，学好一门语言，以不变应万变，就算用其他语言也是差不多的，只是工具变了而已。”这样的说法真心有失偏颇。没错，什么语言都只是工具，但他们不仅仅是工具，也包含了用这种工具时候所形成的思维方式。\n\n“著名的语言学家Roman Jakobson曾用一句简单的名言指明了语言之间最关键的不同之处：语言之间的不同本质在于它们能够传达的信息，而不是它们不能传达的信息。这句名言告诉了我们解放我们母语潜能的关键所在：不同的语言用不同的方式影响我们的大脑思维，这并不是因为这种语言可以让我们这样思考问题，而是它在强迫你这样思考。”\n“当你的语言日常的强迫你去使用某些类型的信息进行说明，这会迫使你去留意那些使用其它种语言的人平时不会注意的某些细节和体验。因为这种说法的习惯是从小养成的，这种习惯已经成为大脑思维的习惯，超越了语言本身，直接影响了你的言行，感知，联想，感觉，记忆，以及世界观。”\n\nJokobson的名言同样也适合于编程语言界，不同语言对于程序员的思维要求并不是一样的。如C语言作为一门过程性语言，给予程序员的思维就是过程性的，先做什么，后做什么，任何一个步骤都是线性过程思维。而Java给我们带来的是一切均为对象的思维，当程序员码出任何一行代码之前所思考的是如何构成当前这个对象，该对象有何数据，有何处理这些数据的方法。所以，两种程序员码出来的代码是完全两种风格的。\n\nC和Java两种程序员码出来的代码当然是两种风格的，这有什么大惊小怪的。但是同样两位Java程序员码出来的Java代码也是风格各异，同样的工具，在不同思维的带领下，就会产生不同的结果。\n\n举个例子，有一棵Tree，遍历其结点，并进行打印各结点的值。\n\nExample 1:\n\n\tclass Tree {\n\tpublic:\n\t    Tree(const std::string& name, const std::vector<Tree*> children);\n\t    ~Tree();\n\t \n\t    void visit();\n\t \n\t    void visitAll();\n\t \n\t    std::string getName()const { return m_name; }\n\t \n\tprivate:\n\t    std::vector<Tree*> m_children;\n\t    std::string m_name;\n\t};\n\t \n\tTree::Tree(const std::string& name, const std::vector<Tree*> children)\n\t    : m_name(name),\n\t      m_children(children)\n\t{\n\t \n\t}\n\t \n\tTree::~Tree()\n\t{\n\t    for_each(m_children.begin(), m_children.end(), [](Tree* child){ delete child; });\n\t}\n\t \n\tvoid Tree::visit()\n\t{\n\t    std::cout << m_name << std::endl;\n\t}\n\t \n\tvoid Tree::visitAll(std::function<void(Tree*)> action)\n\t{\n\t    visit(action);\n\t \n\t    for (int i = 0; i < m_children.size(); ++i) {        m_children[i]->visitAll(action);\n\t    }\n\t}\n\t \n\tstatic Tree* constructTree()\n\t{\n\t    std::vector<Tree*> v;\n\t    std::vector<Tree*> emptyVector;\n\t    v.push_back(new Tree(\"left child\", emptyVector));\n\t    v.push_back(new Tree(\"right child\", emptyVector));\n\t \n\t    return new Tree(\"root\", v);\n\t}\n\t \n\tstatic void destructTree(Tree* t)\n\t{\n\t    delete t;\n\t}\n\t \n\tint main()\n\t{\n\t    Tree* root = constructTree();\n\t \n\t    root->visitAll();\n\t \n\t    destructTree(root);\n\t \n\t    return 0;\n\t}\n\n没错，上述实现方法的确可行，但是如果遍历每一个结点，具体的操作由客户(依然是程序员)来决定，那又如何？似乎思路被堵住了。奥秘如下：\n\nExample 2:\n\n\tclass Tree {\n\tpublic:\n\t    Tree(const std::string& name, const std::vector<Tree*> children);\n\t    ~Tree();\n\t \n\t    void visit(std::function<void(Tree*)> action);\n\t \n\t    void visitAll(std::function<void(Tree*)> action);\n\t \n\t    std::string getName()const { return m_name; }\n\t \n\tprivate:\n\t    std::vector<Tree*> m_children;\n\t    std::string m_name;\n\t};\n\t \n\tTree::Tree(const std::string& name, const std::vector<Tree*> children)\n\t    : m_name(name),\n\t      m_children(children)\n\t{\n\t \n\t}\n\t \n\tTree::~Tree()\n\t{\n\t    for_each(m_children.begin(), m_children.end(), [](Tree* child){ delete child; });\n\t}\n\t \n\tvoid Tree::visit(std::function<void(Tree*)> action)\n\t{\n\t    action(this);\n\t}\n\t \n\tvoid Tree::visitAll(std::function<void(Tree*)> action)\n\t{\n\t    visit(action);\n\t \n\t    for (int i = 0; i < m_children.size(); ++i) {        m_children[i]->visitAll(action);\n\t    }\n\t}\n\t \n\tstatic Tree* constructTree()\n\t{\n\t    std::vector<Tree*> v;\n\t    std::vector<Tree*> emptyVector;\n\t    v.push_back(new Tree(\"left child\", emptyVector));\n\t    v.push_back(new Tree(\"right child\", emptyVector));\n\t \n\t    return new Tree(\"root\", v);\n\t}\n\t \n\tstatic void destructTree(Tree* t)\n\t{\n\t    delete t;\n\t}\n\t \n\tint main()\n\t{\n\t    Tree* root = constructTree();\n\t \n\t    root->visitAll([](Tree* t) { std::cout << t->getName() << std::endl; });\n\t \n\t    destructTree(root);\n\t \n\t    return 0;\n\t}\n\n相当巧妙的思维，其实也是受一段ruby代码的启发，不同的程序语言的思维的启发。所以大神们说，每年至少学习一门新的编程语言是相当有道理的。当然我们学习它并不是为了把它使用在工作中（若是能使用那再好不过，因为实践是最好的老师），而是学习该语言随之而来的编程思维，如同简单的遍历Tree一样。\n\n最后，附上启发这篇怪文的Ruby源码。\n\n\tclass Tree\n\t    attr_accessor :children, :node_name\n\t \n\t    def initialize(name, children = [])\n\t        @children = children\n\t        @node_name = name\n\t    end\n\t \n\t    def visit_all(&block)\n\t        visit(&block)\n\t        children.each { |c| c.visit_all &block }\n\t    end\n\t \n\t    def visit(&block)\n\t        block.call self\n\t    end\n\tend\n\t \n\truby_tree = Tree.new(\"Ruby\",\n\t    [Tree.new(\"Reia\"),\n\t        Tree.new(\"MacRuby\")])\n\t \n\tputs \"Visiting a node\"\n\truby_tree.visit { |node| puts node.node_name }\n\t \n\tputs \"Visiting entire tree\"\n\truby_tree.visit_all { |node| puts node.node_name }","slug":"/2013/06-23-0.html","published":1,"updated":"2015-06-19T16:09:05.000Z","comments":1,"photos":[],"link":"","_id":"ciiwjp31b003nof6gckgwne0c"},{"date":"2013-06-21T16:00:00.000Z","layout":"post","title":"First-class Funciton's Cry","_content":"\nwhat’s First-class function? 没听过啊。小猿我也才前几天头一回听说。  \n直接引用wiki上的原话：In computer science, a programming language is said to have first-class functions if it treats functions ad first-class citizens. Specifically, this means the language supports passing functions as arguments to other functions, returning them as the values from other functions, and assigning them to variables or storing them in data structures.\n\nWhat? 这就是“**一等函数**”啊。以C/C++谋生的小猿感觉有点熟悉啊。这不就是函数指针吗？答案是：NO! 函数指针只是C/C++在其函数类型不是first-class object的情况下而所用的替代品。\n\n那First-class function到底有什么好处呢？说实话，小猿也说不清楚(水平太次)，只能用以 Lua VS C 简略说明下其不同之处，各位看官莫要见笑。\n\n**ROUND 1**\n-----------\n\nLua首先很轻松地支持高阶函数（什么是高阶函数，参见[wiki](http://en.wikipedia.org/wiki/Higher-order_function)）。\n\nlua版本：\n\n\t-- higher-order functions: passing functions as arguments\n\t-- @param f 函数\n\t-- @param t 函数f的参数\n\tlocal function map(f, t)\n\t    for k, v in ipairs(t) do\n\t        f(v)\n\t    end\n\tend\n\n哈哈，不就是如此嘛，C语言这位大神也可以轻松搞定：\n\nC版本：\n     \n\t// higher-order functions: passing functions as arguments\n\tvoid map(int (*f)(int), int arr[], int n)\n\t{\n\t    for (int i = 0; i < n; ++i) {\n\t        f(arr[i]);\n\t    }\n\t}\n\n**ROUND 2**\n-----------\n\nlua 轻松搞定匿名函数。\n\nlua版本：\n\n\t-- anonymous and nested functions\n\tmap(function(v) print(v) end, { 1, 2 }) -- function map is defined in ROUND 1\n\nC大神流了点汗，也使出相应招术。\n\nC版本：\n\n\t// not support anonymous and nested functions, have to bind it to a name instead\n\tint print(int v)\n\t{\n\t    printf(\"%d\", v);\n\t}\n\tint main()\n\t{\n\t    int arr = { 1, 2, 3 };\n\t    map(print, arr, sizeof(arr)/sizeof(int));\n\t    return 0;\n\t}\n\n**ROUND 3**\n-----------\n\nlua 使用[cloures](http://en.wikipedia.org/wiki/Closure_%28computer_science%29)绝招。\n\nlua版本：\n\n\t-- non-local variables and closures\n\tlocal function main()\n\t    local offset = 10\n\t    local function map(f, t)\n\t        for k, v in ipairs(t) do\n\t            f(v)\n\t        end\n\t    end\n\t    map(function(v) offset = offset + v print(offset) end, { 1, 2 })\n\tend\n\tmain()\n\nC虽然没有明显的吃亏，但已然快招架不住。\n\nC版本：\n\n\ttypedef struct {\n\t    void (*f) (int);\n\t    int* offset;\n\t} closure_t;\n\tvoid print(int v)\n\t{\n\t    printf(\"%d\\n\", v);\n\t}\n\tvoid map(closure_t closure, int arr[], int n)\n\t{\n\t    for (int i = 0; i < n; ++i) {\n\t        *(closure.offset) += arr[i];\n\t        closure.f(*(closure.offset));\n\t    }\n\t}\n\tint main()\n\t{\n\t    int offset = 10;\n\t    closure_t closure = { print, &offset };\n\t    int arr[] = { 1, 2 };\n\t    map(closure, arr, sizeof(arr) / sizeof(int));\n\t    return 0;\n\t}\n\n**ROUND 4:**\n-----------\n\nlua又使用一招返回函数:\n\nLua版本：\n\n\t-- higher-order functions: returning functions as reuslt\n\t-- Assigning functions to variables\n\tlocal function getPrintFunc()\n\t    local function myPrint(v)\n\t        print(v)\n\t    end\n\t    return myPrint\n\tend\n\tlocal func = getPrintFunc()\n\tfunc(1)\n\nC以它老江湖的经验接住了此招。\n\nC版本：\n\n\ttypedef void (*f)(int);\n\tvoid print(int v)\n\t{\n\t    printf(\"%d\\n\", v);\n\t}\n\tf getPrintFunc()\n\t{\n\t    return print;\n\t}\n\tint main()\n\t{\n\t    f func = getPrintFunc();\n\t    func(1);\n\t    return 0;\n\t}\n\n比武结束，当然以已之长攻他之短并不是十分光彩的事，但是这里也是为了说明理解First-class function的方便之处。其实First-class function在高阶函数中还是很有用的，当然实际工作中，如果用到闭包、匿名函数则其方便之处不言而喻。当然，具体情况还是具体分析，我们是辩证法的推崇者嘛。","source":"_posts/2013-06-22-0.md","raw":"---\ndate: 2013-06-22\nlayout: post\ntitle: First-class Funciton's Cry\npermalink: '/2013/06-22-0.html'\ncategories:\n- 编程思维\ntags:\n- 高阶函数 \n---\n\nwhat’s First-class function? 没听过啊。小猿我也才前几天头一回听说。  \n直接引用wiki上的原话：In computer science, a programming language is said to have first-class functions if it treats functions ad first-class citizens. Specifically, this means the language supports passing functions as arguments to other functions, returning them as the values from other functions, and assigning them to variables or storing them in data structures.\n\nWhat? 这就是“**一等函数**”啊。以C/C++谋生的小猿感觉有点熟悉啊。这不就是函数指针吗？答案是：NO! 函数指针只是C/C++在其函数类型不是first-class object的情况下而所用的替代品。\n\n那First-class function到底有什么好处呢？说实话，小猿也说不清楚(水平太次)，只能用以 Lua VS C 简略说明下其不同之处，各位看官莫要见笑。\n\n**ROUND 1**\n-----------\n\nLua首先很轻松地支持高阶函数（什么是高阶函数，参见[wiki](http://en.wikipedia.org/wiki/Higher-order_function)）。\n\nlua版本：\n\n\t-- higher-order functions: passing functions as arguments\n\t-- @param f 函数\n\t-- @param t 函数f的参数\n\tlocal function map(f, t)\n\t    for k, v in ipairs(t) do\n\t        f(v)\n\t    end\n\tend\n\n哈哈，不就是如此嘛，C语言这位大神也可以轻松搞定：\n\nC版本：\n     \n\t// higher-order functions: passing functions as arguments\n\tvoid map(int (*f)(int), int arr[], int n)\n\t{\n\t    for (int i = 0; i < n; ++i) {\n\t        f(arr[i]);\n\t    }\n\t}\n\n**ROUND 2**\n-----------\n\nlua 轻松搞定匿名函数。\n\nlua版本：\n\n\t-- anonymous and nested functions\n\tmap(function(v) print(v) end, { 1, 2 }) -- function map is defined in ROUND 1\n\nC大神流了点汗，也使出相应招术。\n\nC版本：\n\n\t// not support anonymous and nested functions, have to bind it to a name instead\n\tint print(int v)\n\t{\n\t    printf(\"%d\", v);\n\t}\n\tint main()\n\t{\n\t    int arr = { 1, 2, 3 };\n\t    map(print, arr, sizeof(arr)/sizeof(int));\n\t    return 0;\n\t}\n\n**ROUND 3**\n-----------\n\nlua 使用[cloures](http://en.wikipedia.org/wiki/Closure_%28computer_science%29)绝招。\n\nlua版本：\n\n\t-- non-local variables and closures\n\tlocal function main()\n\t    local offset = 10\n\t    local function map(f, t)\n\t        for k, v in ipairs(t) do\n\t            f(v)\n\t        end\n\t    end\n\t    map(function(v) offset = offset + v print(offset) end, { 1, 2 })\n\tend\n\tmain()\n\nC虽然没有明显的吃亏，但已然快招架不住。\n\nC版本：\n\n\ttypedef struct {\n\t    void (*f) (int);\n\t    int* offset;\n\t} closure_t;\n\tvoid print(int v)\n\t{\n\t    printf(\"%d\\n\", v);\n\t}\n\tvoid map(closure_t closure, int arr[], int n)\n\t{\n\t    for (int i = 0; i < n; ++i) {\n\t        *(closure.offset) += arr[i];\n\t        closure.f(*(closure.offset));\n\t    }\n\t}\n\tint main()\n\t{\n\t    int offset = 10;\n\t    closure_t closure = { print, &offset };\n\t    int arr[] = { 1, 2 };\n\t    map(closure, arr, sizeof(arr) / sizeof(int));\n\t    return 0;\n\t}\n\n**ROUND 4:**\n-----------\n\nlua又使用一招返回函数:\n\nLua版本：\n\n\t-- higher-order functions: returning functions as reuslt\n\t-- Assigning functions to variables\n\tlocal function getPrintFunc()\n\t    local function myPrint(v)\n\t        print(v)\n\t    end\n\t    return myPrint\n\tend\n\tlocal func = getPrintFunc()\n\tfunc(1)\n\nC以它老江湖的经验接住了此招。\n\nC版本：\n\n\ttypedef void (*f)(int);\n\tvoid print(int v)\n\t{\n\t    printf(\"%d\\n\", v);\n\t}\n\tf getPrintFunc()\n\t{\n\t    return print;\n\t}\n\tint main()\n\t{\n\t    f func = getPrintFunc();\n\t    func(1);\n\t    return 0;\n\t}\n\n比武结束，当然以已之长攻他之短并不是十分光彩的事，但是这里也是为了说明理解First-class function的方便之处。其实First-class function在高阶函数中还是很有用的，当然实际工作中，如果用到闭包、匿名函数则其方便之处不言而喻。当然，具体情况还是具体分析，我们是辩证法的推崇者嘛。","slug":"/2013/06-22-0.html","published":1,"updated":"2015-06-19T16:09:05.000Z","comments":1,"photos":[],"link":"","_id":"ciiwjp31d003pof6g6742vxkt"},{"date":"2013-03-24T16:00:00.000Z","layout":"post","title":"原地排序","_content":"\n\n**题目：**  \nGiven an unsorted array of size n containing objects with ids of 0 … n-1, sort the array in place and inlinear time. Assume that the objects contain large members such as binary data, so instantiating new copies of the objects is probibitively expensice.\n\n用另一种表达方式：有一串数字，5, 2, 6, 7, 4, 1, 8, 9, 0, 3, 用O(n)的时间复杂度来实现排序，当然只允许多分配少量临时变量。\n\n当然，如果有一般的排序算法，最快也就O(nlogn).　那么是否有更好的解决方法吗？由于题设的特殊性，当然有更好的方法。\n\n**Linus说，“Talk is cheep. Show me the code.” 所以直接上代码，show you the code!**\n\n\t#include \"stdio.h\"\n\t#include \"stdlib.h\"\n\t \n\tint* general_array(int len)\n\t{\n\t    int i;\n\t    int* array;\n\t \n\t    array = (int*)malloc(sizeof(int) * len);\n\t \n\t    for (i = 0; i < len; ++i) {\n\t        array[i] = i;\n\t    }\n\t \n\t    return array;\n\t}\n\t \n\tvoid swap(int* lhs, int* rhs)\n\t{\n\t    int tmp;\n\t \n\t    tmp = *lhs;\n\t    *lhs = *rhs;\n\t    *rhs = tmp;\n\t}\n\t \n\tvoid shuffle(int* array, int len)\n\t{\n\t    int i;\n\t \n\t    srand((int)time(NULL));\n\t \n\t    for (i = 0; i < len; ++i) {\n\t        swap(&array[rand()%len], &array[i]);\n\t    }\n\t}\n\t \n\tvoid print_array(int* array, int len)\n\t{\n\t    int i;\n\t \n\t    for (i = 0; i < len; ++i) {\n\t        printf(\"%d \", array[i]);\n\t    }\n\t    printf(\"\\n\");\n\t}\n\t \n\tvoid sort(int* array, int len)\n\t{\n\t    int i, count = 0;\n\t \n\t    for (i = 0; i < len; ++i) {\n\t        if (array[i] != i) {\n\t            swap(&array[i], &array[array[i]]);\n\t            ++count;\n\t        }\n\t    }\n\t \n\t    printf(\"%d\\n\", count);\n\t}\n\t \n\tint main()\n\t{\n\t    int arrayLen;\n\t    int* array;\n\t \n\t    arrayLen = 10;\n\t    array = general_array(arrayLen);\n\t \n\t    shuffle(array, arrayLen);\n\t    print_array(array, arrayLen);\n\t \n\t    sort(array, arrayLen);\n\t    print_array(array, arrayLen);\n\t \n\t    free(array);\n\t \n\t    return 0;\n\t}","source":"_posts/2013-03-25-0.md","raw":"---\ndate: 2013-03-25\nlayout: post\ntitle: 原地排序\npermalink: '/2013/03-25-0.html'\ncategories:\n- 算法\ntags:\n- 面试题\n- 排序\n---\n\n\n**题目：**  \nGiven an unsorted array of size n containing objects with ids of 0 … n-1, sort the array in place and inlinear time. Assume that the objects contain large members such as binary data, so instantiating new copies of the objects is probibitively expensice.\n\n用另一种表达方式：有一串数字，5, 2, 6, 7, 4, 1, 8, 9, 0, 3, 用O(n)的时间复杂度来实现排序，当然只允许多分配少量临时变量。\n\n当然，如果有一般的排序算法，最快也就O(nlogn).　那么是否有更好的解决方法吗？由于题设的特殊性，当然有更好的方法。\n\n**Linus说，“Talk is cheep. Show me the code.” 所以直接上代码，show you the code!**\n\n\t#include \"stdio.h\"\n\t#include \"stdlib.h\"\n\t \n\tint* general_array(int len)\n\t{\n\t    int i;\n\t    int* array;\n\t \n\t    array = (int*)malloc(sizeof(int) * len);\n\t \n\t    for (i = 0; i < len; ++i) {\n\t        array[i] = i;\n\t    }\n\t \n\t    return array;\n\t}\n\t \n\tvoid swap(int* lhs, int* rhs)\n\t{\n\t    int tmp;\n\t \n\t    tmp = *lhs;\n\t    *lhs = *rhs;\n\t    *rhs = tmp;\n\t}\n\t \n\tvoid shuffle(int* array, int len)\n\t{\n\t    int i;\n\t \n\t    srand((int)time(NULL));\n\t \n\t    for (i = 0; i < len; ++i) {\n\t        swap(&array[rand()%len], &array[i]);\n\t    }\n\t}\n\t \n\tvoid print_array(int* array, int len)\n\t{\n\t    int i;\n\t \n\t    for (i = 0; i < len; ++i) {\n\t        printf(\"%d \", array[i]);\n\t    }\n\t    printf(\"\\n\");\n\t}\n\t \n\tvoid sort(int* array, int len)\n\t{\n\t    int i, count = 0;\n\t \n\t    for (i = 0; i < len; ++i) {\n\t        if (array[i] != i) {\n\t            swap(&array[i], &array[array[i]]);\n\t            ++count;\n\t        }\n\t    }\n\t \n\t    printf(\"%d\\n\", count);\n\t}\n\t \n\tint main()\n\t{\n\t    int arrayLen;\n\t    int* array;\n\t \n\t    arrayLen = 10;\n\t    array = general_array(arrayLen);\n\t \n\t    shuffle(array, arrayLen);\n\t    print_array(array, arrayLen);\n\t \n\t    sort(array, arrayLen);\n\t    print_array(array, arrayLen);\n\t \n\t    free(array);\n\t \n\t    return 0;\n\t}","slug":"/2013/03-25-0.html","published":1,"updated":"2015-06-19T16:09:05.000Z","comments":1,"photos":[],"link":"","_id":"ciiwjp31g003tof6glknjiodk"},{"date":"2013-03-23T16:00:00.000Z","layout":"post","title":"Calling Convention on X86 -- Using C for Example","_content":"\n\n引用wikipedia上的定义：In computer science, a calling convention is a scheme for how subroutines receive parameters from their caller and how they return a result，即规定了子过程如何从它们的调用者那里取得参数并且返回结果的一种约定。它包含如下5点：\n\n1. 参数与返回值存放的位置，可以在寄存器中，也可以在调用栈中，又或者两种都有\n2. 向子过程传递参数的顺序，或者单个参数的部分。\n3. 调用前设置工作和调用后清理工作，如何在调用者与被调用者之间分配。\n4. 哪些寄存器可以直接被被调用者使用。\n5. 哪些寄存器可以被认为是volatile和或者non-volatile，若为volatile，则无需被调用者恢复。\n\n不同的的程序语言使用不同的调用约定，也可以运行在不同的平台之上，包括不同的CPU架构和不同的操作系统。正是如此，若整合用不同程序语言写的模块，或者调用不同程序语言所写的操作系统或者类库的API时可能会出现问题。正是由于存在这种问题，所以才有了调用约定的必要性。  \n\n通常，一种程序语言存在多种不同的调用约定，可以由编译器所规定，也可以出于优化的情况而由程序员所指定。而不同的CPU架构也有不同的调用约定，比如X86与ARM就有不同的数量的寄存器，当然在其平台上的调用约定也是不同的。\n\n这里我们先来了解一下X86架构的调用约定。  \n\nX86架构拥有几种不同的调用约定。但由于其寄存器数量较少，其调用约定通常将参数存放在调用栈上，将返回值(或者其地址)存放在寄存器中。当然还有一些调用约定将参数存放入寄存器中，这类调用约定对一些参数较少同时又是leaf-routies调用将会提高不少性能(invoked frequently)。\n\n一、调用者清理的调用约定：\n----------------------\n这类调用约定由调用者清理保存在栈上各个参数，典型如变参函数printf()。\n\n**1.　cdecl**  \ncdecl为C　declaration的缩写，是一种起源于C语言的调用约定。目前常用于X86架构上的多种编译器中，如VC的编译器就是默认cdecl为种调用约定。在该种调用约定中，子过程的参数被保存在栈上传递，整型返回值与内存地址通过EAX寄存器返回，浮点值则存入STO X87寄存器中返回。\n\n在C语言的上下文(content)中，函数的参数以从右到左的顺序压入栈中。看下面个段C语言代码：\n\n\tint callee(int, int, int);\n\t \n\tint caller(void)\n\t{\n\t    register int ret;\n\t \n\t\tret = callee(1, 2, 3);\n\t\tret += 5;\n\t\treturn ret;\n\t}\n\n在X86上，上述C语言代码将成为如下汇编(AT&T syntax):\n\n\t.globl  caller\n\tcaller:\n\tpushl   %ebp            ; 将上次保存栈顶压栈\n\tmovl    %esp, %ebp      ; 保存栈顶\n\tpushl   $3          \t; 参数压栈\n\tpushl   $2          \t; 参数压栈\n\tpushl   $1          \t; 参数压栈\n\tcall    callee          ; subroutines\n\taddl    $12, %esp       ; 退栈\n\taddl    $5, %eax        ; 将subrouties返回的值加常量5\n\tleave\n\tret\n\n研究以上汇编，可见参数是由调用者在调用完成后清理的。这里是简单的整型返回，那如果是复杂的Struct呢，寄存器放不下了！一些编译器将复杂Struct通过内存来返回。首先调用者分配一片内存然后将其地址当作隐藏的第一个参数传入子过程中，在子过程中处理这片内存，最后将这个地址返回。当然，这只是众多处理方法中的一种而已。\n\n二、被调用者清理的调用约定：  \n-----------------------------\n栈上的参数由被调用者来清理有一个前提，那就是在编译期间要明确有几个字节在栈上。因此，这类调用约定不适用于变参函数，如printf()。\n\n**1 pascal**  \n该调用约定是基于Pascal语言的调用约定，其参数压栈顺序为从左至右，在返回前由被调用者负责清理栈帧\n\n**2 stdcall**  \n该调用约定是pascal调用约定的变化版本，其参数从右至左压栈，然后由被调用者负责清理杠，返回值存入EAX寄存器中。stdcall调用约定为Win32 API的标准调用约定。\n\n**3 fastcall**  \n该调用约定没有标准化，故各编译器各有不同。其中经典的为将一个或者多个参数存放寄存器中，从而减少内存的读取。","source":"_posts/2013-03-24-0.md","raw":"---\ndate: 2013-03-24\nlayout: post\ntitle: Calling Convention on X86 -- Using C for Example\npermalink: '/2013/03-24-0.html'\ncategories:\n- c/c++\ntags:\n- 基础\n---\n\n\n引用wikipedia上的定义：In computer science, a calling convention is a scheme for how subroutines receive parameters from their caller and how they return a result，即规定了子过程如何从它们的调用者那里取得参数并且返回结果的一种约定。它包含如下5点：\n\n1. 参数与返回值存放的位置，可以在寄存器中，也可以在调用栈中，又或者两种都有\n2. 向子过程传递参数的顺序，或者单个参数的部分。\n3. 调用前设置工作和调用后清理工作，如何在调用者与被调用者之间分配。\n4. 哪些寄存器可以直接被被调用者使用。\n5. 哪些寄存器可以被认为是volatile和或者non-volatile，若为volatile，则无需被调用者恢复。\n\n不同的的程序语言使用不同的调用约定，也可以运行在不同的平台之上，包括不同的CPU架构和不同的操作系统。正是如此，若整合用不同程序语言写的模块，或者调用不同程序语言所写的操作系统或者类库的API时可能会出现问题。正是由于存在这种问题，所以才有了调用约定的必要性。  \n\n通常，一种程序语言存在多种不同的调用约定，可以由编译器所规定，也可以出于优化的情况而由程序员所指定。而不同的CPU架构也有不同的调用约定，比如X86与ARM就有不同的数量的寄存器，当然在其平台上的调用约定也是不同的。\n\n这里我们先来了解一下X86架构的调用约定。  \n\nX86架构拥有几种不同的调用约定。但由于其寄存器数量较少，其调用约定通常将参数存放在调用栈上，将返回值(或者其地址)存放在寄存器中。当然还有一些调用约定将参数存放入寄存器中，这类调用约定对一些参数较少同时又是leaf-routies调用将会提高不少性能(invoked frequently)。\n\n一、调用者清理的调用约定：\n----------------------\n这类调用约定由调用者清理保存在栈上各个参数，典型如变参函数printf()。\n\n**1.　cdecl**  \ncdecl为C　declaration的缩写，是一种起源于C语言的调用约定。目前常用于X86架构上的多种编译器中，如VC的编译器就是默认cdecl为种调用约定。在该种调用约定中，子过程的参数被保存在栈上传递，整型返回值与内存地址通过EAX寄存器返回，浮点值则存入STO X87寄存器中返回。\n\n在C语言的上下文(content)中，函数的参数以从右到左的顺序压入栈中。看下面个段C语言代码：\n\n\tint callee(int, int, int);\n\t \n\tint caller(void)\n\t{\n\t    register int ret;\n\t \n\t\tret = callee(1, 2, 3);\n\t\tret += 5;\n\t\treturn ret;\n\t}\n\n在X86上，上述C语言代码将成为如下汇编(AT&T syntax):\n\n\t.globl  caller\n\tcaller:\n\tpushl   %ebp            ; 将上次保存栈顶压栈\n\tmovl    %esp, %ebp      ; 保存栈顶\n\tpushl   $3          \t; 参数压栈\n\tpushl   $2          \t; 参数压栈\n\tpushl   $1          \t; 参数压栈\n\tcall    callee          ; subroutines\n\taddl    $12, %esp       ; 退栈\n\taddl    $5, %eax        ; 将subrouties返回的值加常量5\n\tleave\n\tret\n\n研究以上汇编，可见参数是由调用者在调用完成后清理的。这里是简单的整型返回，那如果是复杂的Struct呢，寄存器放不下了！一些编译器将复杂Struct通过内存来返回。首先调用者分配一片内存然后将其地址当作隐藏的第一个参数传入子过程中，在子过程中处理这片内存，最后将这个地址返回。当然，这只是众多处理方法中的一种而已。\n\n二、被调用者清理的调用约定：  \n-----------------------------\n栈上的参数由被调用者来清理有一个前提，那就是在编译期间要明确有几个字节在栈上。因此，这类调用约定不适用于变参函数，如printf()。\n\n**1 pascal**  \n该调用约定是基于Pascal语言的调用约定，其参数压栈顺序为从左至右，在返回前由被调用者负责清理栈帧\n\n**2 stdcall**  \n该调用约定是pascal调用约定的变化版本，其参数从右至左压栈，然后由被调用者负责清理杠，返回值存入EAX寄存器中。stdcall调用约定为Win32 API的标准调用约定。\n\n**3 fastcall**  \n该调用约定没有标准化，故各编译器各有不同。其中经典的为将一个或者多个参数存放寄存器中，从而减少内存的读取。","slug":"/2013/03-24-0.html","published":1,"updated":"2015-06-19T16:09:05.000Z","comments":1,"photos":[],"link":"","_id":"ciiwjp31j003xof6gbh99uje7"},{"date":"2012-09-08T16:00:00.000Z","layout":"post","title":"观察者模式(Observer Pattern)","_content":"\n\n[观察者模式(Observer patten)](http://en.wikipedia.org/wiki/Observer_pattern)，**定义了对象之间的一对多依赖，这样一来一个对象改变状态时，它的所有依赖者都会收到通知并自动更新**。\n\n它在现实生活中也非常常见，如报纸、杂志的订阅关系。比如Bob向报社订阅了《程序员》，《程序员》供应商就将Bob加入订阅者的表格中。每次新的《程序 员》一出版，就会通知Bob：新一期《程序员》出版了，并同时将《程序员》送到Bob手中。过了半年，Bob不想再订阅《程序员》了，因了他订阅了 ipad版的。这时，《程序员》供应商就将Bob从订阅者表格中删除。以后每月新一期《程序员》出版时，就不再通知Bob，并送杂志到他手中了。\n\n没错，这就是观察者模式，并不复杂。很多地方都用到这个模式，如著名的[MVC(Model-View-controler)](http://en.wikipedia.org/wiki/Model%E2%80%93view%E2%80%93controller)中重要的部分就是观察者模式，而Swing中也存在着观察者模式的实现。\n\n下面，我们具体来分析一下这个强大的观察者模式。\n\n观察者模式可以分为主题(Subject)和观察者(Observer)。主题其实就是被观察者对象，就如上面杂志订阅中的杂志社，而观察者就是各个订阅 者。杂志社可以将新的订阅者加入订阅者列表中，也可以加老是订阅者从订阅者列表中删除，所以主题类也拥有这两种能力，即拥有 registerObserver( )和removeObserver( )方法(方法名称仅仅是名称而已，可用其他)。而且，杂志社可以通知各个订阅者新杂志到了，所以主题类也有相应的方法：notifObservers( )。而观察者呢？杂志社通知订阅都有新的杂志到了，订阅者就有相应的动作，或阅读，或送人。当然，观察者类则有update( )方法与之对应。对应的UML图如下：\n\n![UML图](/img/2012-09-09-0.png \"UML图\")\n\n那么，这个观察者模式有什么好处呢？**观察者模式提供了一种对象设计，让主题和观察者之间松耦合**(还记得学校里老师教的“强内聚，松耦合”吗)。\n\n在主题方，它对观察者基本不知道任何详情，只知道观察者实现了某个接口，其他具体细节一概不知，如具体类是什么，有多少种方法，各种方法内又做了什么。主 题只要维护好自己的观察者列表和其他数据，在新的观察者申请加入时，将其加入列表；在理的观察者申请退出时，将其从列表中删除；在自己的数据更新时，依次 通知各个观察者，即调用它们的update方法(上段中update方法)。如果主题类增加维护数据时，已有的观察者们都无须更新代码，因为这只与主题类 相关，这就是松耦合的威力。\n\n在观察者方，它只关心所观察对象(即主题类)推送过来的更新消息，取得自己感兴趣的数据，做自己相应的动作，而无需知道被观察者(主题)具体有多少观察 者，有多少数据，或者是肥是瘦。而如果不想观察这个主题，则调用主题remove方法将自己从主题的观察者列表中删除，不影响该主题和其他观察者。\n\n可见，改变主题或者观察者的任何一方都不会影响另一方，这就是松耦合。\n\n附[《Head First 设计模式》](http://book.douban.com/subject/2243615/)中相应章节源代码，以更方便理解观察者模式。Java中Observable类与Observer类就是相应的被观察者(主题类)与观察者:\n\n\tpackage com.Observor;  \n\t \n\tpublic interface DisplayEmlement {  \n\t    public void display();  \n\t}\n\n------------------------------\n\n\tpackage com.Observor;  \n\t \n\timport java.util.Observable;  \n\t \n\tpublic class WeatherData extends Observable {  \n\t    private float temperature;  \n\t    private float humidity;  \n\t    private float pressure;  \n\t \n\t    public void measurementChanged() {  \n\t        setChanged();  \n\t        notifyObservers();  \n\t    }  \n\t \n\t    public void setMeasurements(float temperature, float humidigy, float pressure) {  \n\t        this.temperature = temperature;  \n\t        this.humidity = humidigy;  \n\t        this.pressure = pressure;  \n\t        measurementChanged();  \n\t    }  \n\t \n\t    public float getTemperature() {  \n\t        return temperature;  \n\t    }  \n\t \n\t    public float getHumidity() {  \n\t        return humidity;  \n\t    }  \n\t \n\t    public float getPressure() {  \n\t        return pressure;  \n\t    }  \n\t}\n\n------------------------------\n\n\tpackage com.Observor;  \n\t \n\timport java.util.Observable;  \n\timport java.util.Observer;  \n\t \n\tpublic class CurrentConditionsDisplay implements Observer, DisplayEmlement {  \n\t    Observable observable;  \n\t    private float temerature;  \n\t    private float humidity;  \n\t \n\t    public CurrentConditionsDisplay(Observable observable) {  \n\t        this.observable = observable;  \n\t        observable.addObserver(this);  \n\t    }  \n\t \n\t    @Override \n\t    public void display() {  \n\t        // TODO Auto-generated method stub  \n\t        System.out.println(\"Current conditions: \" + temerature + \"F degrees and \" + humidity + \"% humidity\");  \n\t    }  \n\t \n\t    @Override \n\t    public void update(Observable arg0, Object arg1) {  \n\t        // TODO Auto-generated method stub  \n\t        if (arg0 instanceof WeatherData) {  \n\t            WeatherData weatherData = (WeatherData)arg0;  \n\t            this.temerature = weatherData.getTemperature();  \n\t            this.humidity = weatherData.getHumidity();  \n\t            display();  \n\t        }  \n\t    }  \n\t \n\t}\n\n---------------------------------\n\n\tpackage com.Observor;  \n\t \n\timport java.util.Observable;  \n\timport java.util.Observer;  \n\t \n\tpublic class ForecastDisplay implements Observer, DisplayEmlement {  \n\t    private float  currentPressure = 29.92f;  \n\t    private float lastPressure;  \n\t \n\t    public ForecastDisplay(Observable observable) {  \n\t        observable.addObserver(this);  \n\t    }  \n\t \n\t    @Override \n\t    public void display() {  \n\t        // TODO Auto-generated method stub  \n\t        System.out.println(\"lastPressure: \" + lastPressure + \" curPressure:\" + currentPressure);  \n\t    }  \n\t \n\t    @Override \n\t    public void update(Observable o, Object arg) {  \n\t        // TODO Auto-generated method stub  \n\t        if (o instanceof WeatherData) {  \n\t            lastPressure = currentPressure;  \n\t            currentPressure = ((WeatherData) o).getPressure();  \n\t        }  \n\t        display();  \n\t    }  \n\t \n\t}\n\n---------------------------\n\n\tpackage com.Observor;  \n\t \n\tpublic class WeatherStation {  \n\t \n\t    public static void main(String[] args) {  \n\t        WeatherData weatherData = new WeatherData();  \n\t \n\t        CurrentConditionsDisplay currentDisplay = new CurrentConditionsDisplay(weatherData);  \n\t        ForecastDisplay forecastDisplay = new ForecastDisplay(weatherData);  \n\t        weatherData.setMeasurements(80, 90, 100);  // 数字乱来的哦  \n\t        weatherData.setMeasurements(1, 2, 3);  \n\t        weatherData.setMeasurements(11, 22, 33);  \n\t    }  \n\t}\n","source":"_posts/2012-09-09-0.md","raw":"---\ndate: 2012-09-09\nlayout: post\ntitle: 观察者模式(Observer Pattern)\npermalink: '/2012/09-09-0.html'\ncategories:\n- 设计模式\ntags:\n- 设计\n---\n\n\n[观察者模式(Observer patten)](http://en.wikipedia.org/wiki/Observer_pattern)，**定义了对象之间的一对多依赖，这样一来一个对象改变状态时，它的所有依赖者都会收到通知并自动更新**。\n\n它在现实生活中也非常常见，如报纸、杂志的订阅关系。比如Bob向报社订阅了《程序员》，《程序员》供应商就将Bob加入订阅者的表格中。每次新的《程序 员》一出版，就会通知Bob：新一期《程序员》出版了，并同时将《程序员》送到Bob手中。过了半年，Bob不想再订阅《程序员》了，因了他订阅了 ipad版的。这时，《程序员》供应商就将Bob从订阅者表格中删除。以后每月新一期《程序员》出版时，就不再通知Bob，并送杂志到他手中了。\n\n没错，这就是观察者模式，并不复杂。很多地方都用到这个模式，如著名的[MVC(Model-View-controler)](http://en.wikipedia.org/wiki/Model%E2%80%93view%E2%80%93controller)中重要的部分就是观察者模式，而Swing中也存在着观察者模式的实现。\n\n下面，我们具体来分析一下这个强大的观察者模式。\n\n观察者模式可以分为主题(Subject)和观察者(Observer)。主题其实就是被观察者对象，就如上面杂志订阅中的杂志社，而观察者就是各个订阅 者。杂志社可以将新的订阅者加入订阅者列表中，也可以加老是订阅者从订阅者列表中删除，所以主题类也拥有这两种能力，即拥有 registerObserver( )和removeObserver( )方法(方法名称仅仅是名称而已，可用其他)。而且，杂志社可以通知各个订阅者新杂志到了，所以主题类也有相应的方法：notifObservers( )。而观察者呢？杂志社通知订阅都有新的杂志到了，订阅者就有相应的动作，或阅读，或送人。当然，观察者类则有update( )方法与之对应。对应的UML图如下：\n\n![UML图](/img/2012-09-09-0.png \"UML图\")\n\n那么，这个观察者模式有什么好处呢？**观察者模式提供了一种对象设计，让主题和观察者之间松耦合**(还记得学校里老师教的“强内聚，松耦合”吗)。\n\n在主题方，它对观察者基本不知道任何详情，只知道观察者实现了某个接口，其他具体细节一概不知，如具体类是什么，有多少种方法，各种方法内又做了什么。主 题只要维护好自己的观察者列表和其他数据，在新的观察者申请加入时，将其加入列表；在理的观察者申请退出时，将其从列表中删除；在自己的数据更新时，依次 通知各个观察者，即调用它们的update方法(上段中update方法)。如果主题类增加维护数据时，已有的观察者们都无须更新代码，因为这只与主题类 相关，这就是松耦合的威力。\n\n在观察者方，它只关心所观察对象(即主题类)推送过来的更新消息，取得自己感兴趣的数据，做自己相应的动作，而无需知道被观察者(主题)具体有多少观察 者，有多少数据，或者是肥是瘦。而如果不想观察这个主题，则调用主题remove方法将自己从主题的观察者列表中删除，不影响该主题和其他观察者。\n\n可见，改变主题或者观察者的任何一方都不会影响另一方，这就是松耦合。\n\n附[《Head First 设计模式》](http://book.douban.com/subject/2243615/)中相应章节源代码，以更方便理解观察者模式。Java中Observable类与Observer类就是相应的被观察者(主题类)与观察者:\n\n\tpackage com.Observor;  \n\t \n\tpublic interface DisplayEmlement {  \n\t    public void display();  \n\t}\n\n------------------------------\n\n\tpackage com.Observor;  \n\t \n\timport java.util.Observable;  \n\t \n\tpublic class WeatherData extends Observable {  \n\t    private float temperature;  \n\t    private float humidity;  \n\t    private float pressure;  \n\t \n\t    public void measurementChanged() {  \n\t        setChanged();  \n\t        notifyObservers();  \n\t    }  \n\t \n\t    public void setMeasurements(float temperature, float humidigy, float pressure) {  \n\t        this.temperature = temperature;  \n\t        this.humidity = humidigy;  \n\t        this.pressure = pressure;  \n\t        measurementChanged();  \n\t    }  \n\t \n\t    public float getTemperature() {  \n\t        return temperature;  \n\t    }  \n\t \n\t    public float getHumidity() {  \n\t        return humidity;  \n\t    }  \n\t \n\t    public float getPressure() {  \n\t        return pressure;  \n\t    }  \n\t}\n\n------------------------------\n\n\tpackage com.Observor;  \n\t \n\timport java.util.Observable;  \n\timport java.util.Observer;  \n\t \n\tpublic class CurrentConditionsDisplay implements Observer, DisplayEmlement {  \n\t    Observable observable;  \n\t    private float temerature;  \n\t    private float humidity;  \n\t \n\t    public CurrentConditionsDisplay(Observable observable) {  \n\t        this.observable = observable;  \n\t        observable.addObserver(this);  \n\t    }  \n\t \n\t    @Override \n\t    public void display() {  \n\t        // TODO Auto-generated method stub  \n\t        System.out.println(\"Current conditions: \" + temerature + \"F degrees and \" + humidity + \"% humidity\");  \n\t    }  \n\t \n\t    @Override \n\t    public void update(Observable arg0, Object arg1) {  \n\t        // TODO Auto-generated method stub  \n\t        if (arg0 instanceof WeatherData) {  \n\t            WeatherData weatherData = (WeatherData)arg0;  \n\t            this.temerature = weatherData.getTemperature();  \n\t            this.humidity = weatherData.getHumidity();  \n\t            display();  \n\t        }  \n\t    }  \n\t \n\t}\n\n---------------------------------\n\n\tpackage com.Observor;  \n\t \n\timport java.util.Observable;  \n\timport java.util.Observer;  \n\t \n\tpublic class ForecastDisplay implements Observer, DisplayEmlement {  \n\t    private float  currentPressure = 29.92f;  \n\t    private float lastPressure;  \n\t \n\t    public ForecastDisplay(Observable observable) {  \n\t        observable.addObserver(this);  \n\t    }  \n\t \n\t    @Override \n\t    public void display() {  \n\t        // TODO Auto-generated method stub  \n\t        System.out.println(\"lastPressure: \" + lastPressure + \" curPressure:\" + currentPressure);  \n\t    }  \n\t \n\t    @Override \n\t    public void update(Observable o, Object arg) {  \n\t        // TODO Auto-generated method stub  \n\t        if (o instanceof WeatherData) {  \n\t            lastPressure = currentPressure;  \n\t            currentPressure = ((WeatherData) o).getPressure();  \n\t        }  \n\t        display();  \n\t    }  \n\t \n\t}\n\n---------------------------\n\n\tpackage com.Observor;  \n\t \n\tpublic class WeatherStation {  \n\t \n\t    public static void main(String[] args) {  \n\t        WeatherData weatherData = new WeatherData();  \n\t \n\t        CurrentConditionsDisplay currentDisplay = new CurrentConditionsDisplay(weatherData);  \n\t        ForecastDisplay forecastDisplay = new ForecastDisplay(weatherData);  \n\t        weatherData.setMeasurements(80, 90, 100);  // 数字乱来的哦  \n\t        weatherData.setMeasurements(1, 2, 3);  \n\t        weatherData.setMeasurements(11, 22, 33);  \n\t    }  \n\t}\n","slug":"/2012/09-09-0.html","published":1,"updated":"2015-06-19T16:09:05.000Z","comments":1,"photos":[],"link":"","_id":"ciiwjp31m0041of6gvzobzhdp"},{"date":"2012-09-01T16:00:00.000Z","layout":"post","title":"策略模式(Strategy Pattern)","_content":"\n\n学习Object Oriented(OO)也有段时间了，但一直没有学习Pattern Design方面的东西，感觉使用OO的时候完全不给力啊。So, balabala……..\n\nSorry，扯了一点废话。\n\nStrategy Pattern，在WikiPedia中解释为：a particularsoftware design pattern, whereby algorithms can be selected at runtime. 也就是说，Strategy Pattern在运行时能够改变算法的一种设计模式。那么，这个算法是什么呢？这里的算法，指的是Object的行为，比如一个Duck，它拥有Fly的行为，但是运行时改变算法，使其can’t Fly。这就是Strategy Pattern的优势所在。当然，《Head First 设计模式》中对它也有定义：定义了算法族，分别封装起来，让它们之间可以互相替换，此模式让算法的变化独立于使用算法的客户。\n\nOK,我们以《Head First 设计模式》中的例子来说明。\n\n我们要设计以下两个类，MallarDuck(绿头鸭)和RedheadDuck(红头鸭)。既然都是Duck(鸭)，会OO的人都会想到－－inherit(继承)。那这两种鸭子有什么共有的特性，我们可以将它们抽象出来放入一个父类Duck中呢。哦，它们都会quack，还有swim!于是，有了下面的设计：\n\n![UML图](/img/2012-09-02-0.png \"UML图\")\n\n嗯，看起来不错的样子。但是过了一天，老板(产品经理，又或者其他**，你明白的)说，我们要新的功能，MallardDuck和RedheadDuck都要有fly( )的行为！嗯，不怕，OO的好处来了。只要在Duck类中新加入fly( )行为，这下所有的子类都有fly( )的行为了，一切OK！\n\n![UML图](/img/2012-09-02-1.png \"UML图\")\n\n等等，让我想想，真的OK吗？第3天，**（who?）又说，我们仅有MallardDuck与RedheadDuck太少了，我们需要一个RubberDuck ! OK，so easy。\n\n![UML图](/img/2012-09-02-2.png \"UML图\")\n\nHold on ! RubberDuck好像不会飞啊。但是为什么RubberDuck有fly( )这个行为！那也行，好吧，在RubberDuck中覆盖fly( )方法，但是什么也不做吧。\n\n\tclass RubberDuck extend Duck {\n\t    ......\n\t    @override\n\t    public fly() {\n\t        // do nothing\n\t    }\n\t    ......\n\t}\n\n看上去还成。但是如果不止增加RubberDuck呢，还有ModelDuck， 以及**Duck, balabala……..那不是每个类都要覆盖fly( )方法？你怎么知道只有fly( )方法。要是**Duck不会swim呢（我们假设有这样一种Duck）？OMG，我的OO呢，说好的方便呢？\n\n嘿，谁说没有好方法。且看：\n\n![UML图](/img/2012-09-02-3.png \"UML图\")\n\n这下，谁看要什么方法就让它有吧，想要fly( )方法，就实现Flyable这个接口；想要quack方法，就实现Quackable接口。Oh, No ! 这不是N多代码重复吗！MallardDuck与RedheadDuck的fly( )方法是一样的啊，说好的代码复用呢？\n\n等等，好像灵感又来了！代码复用？参考Duck类的做法不就行了！\n\n![UML图](/img/2012-09-02-4.png \"UML图\")\n\nOh, 终于告一段落了，这样就可以了！再等等！什么，还有？！学习OO的时候，前人都告诫说：少用继承，多用组合。似乎继承过多了。。。还是多重的。。。那再修改！\n\n![UML图](/img/2012-09-02-5.png \"UML图\")\n\n这么修改，还增加了一个功能：运行时可以替换Object的行为啊，组合果然是个good choice !\n\n其实，最后一个版本就是刚开始就提到的Strategy Pattern， 真是“千呼万唤始出来”啊。\n\n另外，附上最终的Java代码，让我们更好的理解它。\n\nDuck.java:\n\n\t// Duck.java\n\tpublic abstract class Duck {\n\t \n\t    FlyBehavior flyBehavior;\n\t    QuackBehavior quackBehavior;\n\t \n\t    public Duck() {\n\t \n\t    }\n\t \n\t    public abstract void display();\n\t \n\t    public void performFly(){\n\t        flyBehavior.fly();\n\t    }\n\t \n\t   public void performQuack() {\n\t        quackBehavior.quack();\n\t   }\n\t \n\t   public void swim() {\n\t       System.out.println(\"All ducks float, even decoys!\");\n\t   }\n\t \n\t    public void setFlyBehavior(FlyBehavior fb) {\n\t        flyBehavior = fb;\n\t    }\n\t \n\t    public void setQuackBehavior(QuackBehavior qb) {\n\t        uackBehavior = qb;\n\t    }\n\t}\n\nFlyBehavior.java:\n\n\t// FlyBehavio.java\n\tpublic interface FlyBehavior {\n\t    public void fly();\n\t}\n \nFlyWithWings.java:\n\n\t// FlyWithWings\n\tpublic class FlyWithWings implements FlyBehavior {\n\t \n\t    @Override\n\t    public void fly() {\n\t        // TODO Auto-generated method stub\n\t        System.out.println(\"I'am flying!\");\n\t    }\n\t \n\t}\n\nFlyNoWay.java:\n\n\t// FlyNoWay.java\n\tpublic class FlyNoWay implements FlyBehavior {\n\t \n\t    @Override\n\t    public void fly() {\n\t        // TODO Auto-generated method stub\n\t        System.out.println(\"I can't fly!\");\n\t    }\n\t \n\t}\n\nFlyRockedPowered.java:\n\n\t// FlyRockedPowered\n\tpublic class FlyRockedPowered implements FlyBehavior {\n\t \n\t    @Override\n\t    public void fly() {\n\t        // TODO Auto-generated method stub\n\t        System.out.println(\"I' am flying with a rocked!\");\n\t    }\n\t \n\t}\n\nQuackBehavior.java:\n\n\t// QuackBehavior.java\n\tpublic interface QuackBehavior {\n\t    public void quack();\n\t}\n\nQuack.java\n\n\t// Quack.java\n\tpublic class Quack implements QuackBehavior {\n\t \n\t    @Override\n\t    public void quack() {\n\t        // TODO Auto-generated method stub\n\t        System.out.println(\"Quack\");\n\t    }\n\t \n\t}\n\nMuteQuack.java\n\n\t// QuackBehavior.java\n\tpublic class MuteQuack implements QuackBehavior {\n\t \n\t    @Override\n\t    public void quack() {\n\t        // TODO Auto-generated method stub\n\t        System.out.println(\"<< Silence >>\");\n\t    }\n\t \n\t}\n\nSqueak.java\n\n\t// Squeak.java\n\tpublic class Squeak implements QuackBehavior {\n\t \n\t    @Override\n\t    public void quack() {\n\t         // TODO Auto-generated method stub\n\t         System.out.println(\"Squeak\");\n\t    }\n\t \n\t}\n\nMallardDuck.java:\n\n\t// MallardDuck\n\tpublic class MallardDuck extends Duck {\n\t \n\t    public MallardDuck() {\n\t        quackBehavior = new Quack();\n\t        flyBehavior = new FlyWithWings();\n\t    }\n\t \n\t    @Override\n\t    public void display() {\n\t        // TODO Auto-generated method stub\n\t        System.out.println(\"I'm a real Mallard duck\");\n\t    }\n\t \n\t}\n\nModelDuck.java:\n\n\t// ModelDuck\n\tpublic class ModelDuck extends Duck {\n\t \n\t    ModelDuck() {\n\t         flyBehavior = new FlyNoWay();\n\t         quackBehavior = new Quack();\n\t    }\n\t \n\t    @Override\n\t    public void display() {\n\t        // TODO Auto-generated method stub\n\t        System.out.println(\"I'm a model duck!\");\n\t    }\n\t \n\t}\n\nTest.java\n\n\t// Test.java\n\tpublic class Test {\n\t \n\t    /**\n\t    * @param args\n\t    */\n\t    public static void main(String[] args) {\n\t        // TODO Auto-generated method stub\n\t        Duck mallard = new MallardDuck();\n\t        mallard.performFly();\n\t        mallard.performQuack();\n\t \n\t        System.out.println(\"------------------- now, change the duck! --------------------\");\n\t \n\t        Duck model = new ModelDuck();\n\t        model.performFly();\n\t        System.out.println(\"------------------- now, set rocked on the model! --------------------\");\n\t        model.setFlyBehavior(new FlyRockedPowered());\n\t        model.performFly();\n\t    }\n\t \n\t}","source":"_posts/2012-09-02-0.md","raw":"---\ndate: 2012-09-02\nlayout: post\ntitle: 策略模式(Strategy Pattern)\npermalink: '/2012/09-02-0.html'\ncategories:\n- 设计模式\ntags:\n- 设计\n---\n\n\n学习Object Oriented(OO)也有段时间了，但一直没有学习Pattern Design方面的东西，感觉使用OO的时候完全不给力啊。So, balabala……..\n\nSorry，扯了一点废话。\n\nStrategy Pattern，在WikiPedia中解释为：a particularsoftware design pattern, whereby algorithms can be selected at runtime. 也就是说，Strategy Pattern在运行时能够改变算法的一种设计模式。那么，这个算法是什么呢？这里的算法，指的是Object的行为，比如一个Duck，它拥有Fly的行为，但是运行时改变算法，使其can’t Fly。这就是Strategy Pattern的优势所在。当然，《Head First 设计模式》中对它也有定义：定义了算法族，分别封装起来，让它们之间可以互相替换，此模式让算法的变化独立于使用算法的客户。\n\nOK,我们以《Head First 设计模式》中的例子来说明。\n\n我们要设计以下两个类，MallarDuck(绿头鸭)和RedheadDuck(红头鸭)。既然都是Duck(鸭)，会OO的人都会想到－－inherit(继承)。那这两种鸭子有什么共有的特性，我们可以将它们抽象出来放入一个父类Duck中呢。哦，它们都会quack，还有swim!于是，有了下面的设计：\n\n![UML图](/img/2012-09-02-0.png \"UML图\")\n\n嗯，看起来不错的样子。但是过了一天，老板(产品经理，又或者其他**，你明白的)说，我们要新的功能，MallardDuck和RedheadDuck都要有fly( )的行为！嗯，不怕，OO的好处来了。只要在Duck类中新加入fly( )行为，这下所有的子类都有fly( )的行为了，一切OK！\n\n![UML图](/img/2012-09-02-1.png \"UML图\")\n\n等等，让我想想，真的OK吗？第3天，**（who?）又说，我们仅有MallardDuck与RedheadDuck太少了，我们需要一个RubberDuck ! OK，so easy。\n\n![UML图](/img/2012-09-02-2.png \"UML图\")\n\nHold on ! RubberDuck好像不会飞啊。但是为什么RubberDuck有fly( )这个行为！那也行，好吧，在RubberDuck中覆盖fly( )方法，但是什么也不做吧。\n\n\tclass RubberDuck extend Duck {\n\t    ......\n\t    @override\n\t    public fly() {\n\t        // do nothing\n\t    }\n\t    ......\n\t}\n\n看上去还成。但是如果不止增加RubberDuck呢，还有ModelDuck， 以及**Duck, balabala……..那不是每个类都要覆盖fly( )方法？你怎么知道只有fly( )方法。要是**Duck不会swim呢（我们假设有这样一种Duck）？OMG，我的OO呢，说好的方便呢？\n\n嘿，谁说没有好方法。且看：\n\n![UML图](/img/2012-09-02-3.png \"UML图\")\n\n这下，谁看要什么方法就让它有吧，想要fly( )方法，就实现Flyable这个接口；想要quack方法，就实现Quackable接口。Oh, No ! 这不是N多代码重复吗！MallardDuck与RedheadDuck的fly( )方法是一样的啊，说好的代码复用呢？\n\n等等，好像灵感又来了！代码复用？参考Duck类的做法不就行了！\n\n![UML图](/img/2012-09-02-4.png \"UML图\")\n\nOh, 终于告一段落了，这样就可以了！再等等！什么，还有？！学习OO的时候，前人都告诫说：少用继承，多用组合。似乎继承过多了。。。还是多重的。。。那再修改！\n\n![UML图](/img/2012-09-02-5.png \"UML图\")\n\n这么修改，还增加了一个功能：运行时可以替换Object的行为啊，组合果然是个good choice !\n\n其实，最后一个版本就是刚开始就提到的Strategy Pattern， 真是“千呼万唤始出来”啊。\n\n另外，附上最终的Java代码，让我们更好的理解它。\n\nDuck.java:\n\n\t// Duck.java\n\tpublic abstract class Duck {\n\t \n\t    FlyBehavior flyBehavior;\n\t    QuackBehavior quackBehavior;\n\t \n\t    public Duck() {\n\t \n\t    }\n\t \n\t    public abstract void display();\n\t \n\t    public void performFly(){\n\t        flyBehavior.fly();\n\t    }\n\t \n\t   public void performQuack() {\n\t        quackBehavior.quack();\n\t   }\n\t \n\t   public void swim() {\n\t       System.out.println(\"All ducks float, even decoys!\");\n\t   }\n\t \n\t    public void setFlyBehavior(FlyBehavior fb) {\n\t        flyBehavior = fb;\n\t    }\n\t \n\t    public void setQuackBehavior(QuackBehavior qb) {\n\t        uackBehavior = qb;\n\t    }\n\t}\n\nFlyBehavior.java:\n\n\t// FlyBehavio.java\n\tpublic interface FlyBehavior {\n\t    public void fly();\n\t}\n \nFlyWithWings.java:\n\n\t// FlyWithWings\n\tpublic class FlyWithWings implements FlyBehavior {\n\t \n\t    @Override\n\t    public void fly() {\n\t        // TODO Auto-generated method stub\n\t        System.out.println(\"I'am flying!\");\n\t    }\n\t \n\t}\n\nFlyNoWay.java:\n\n\t// FlyNoWay.java\n\tpublic class FlyNoWay implements FlyBehavior {\n\t \n\t    @Override\n\t    public void fly() {\n\t        // TODO Auto-generated method stub\n\t        System.out.println(\"I can't fly!\");\n\t    }\n\t \n\t}\n\nFlyRockedPowered.java:\n\n\t// FlyRockedPowered\n\tpublic class FlyRockedPowered implements FlyBehavior {\n\t \n\t    @Override\n\t    public void fly() {\n\t        // TODO Auto-generated method stub\n\t        System.out.println(\"I' am flying with a rocked!\");\n\t    }\n\t \n\t}\n\nQuackBehavior.java:\n\n\t// QuackBehavior.java\n\tpublic interface QuackBehavior {\n\t    public void quack();\n\t}\n\nQuack.java\n\n\t// Quack.java\n\tpublic class Quack implements QuackBehavior {\n\t \n\t    @Override\n\t    public void quack() {\n\t        // TODO Auto-generated method stub\n\t        System.out.println(\"Quack\");\n\t    }\n\t \n\t}\n\nMuteQuack.java\n\n\t// QuackBehavior.java\n\tpublic class MuteQuack implements QuackBehavior {\n\t \n\t    @Override\n\t    public void quack() {\n\t        // TODO Auto-generated method stub\n\t        System.out.println(\"<< Silence >>\");\n\t    }\n\t \n\t}\n\nSqueak.java\n\n\t// Squeak.java\n\tpublic class Squeak implements QuackBehavior {\n\t \n\t    @Override\n\t    public void quack() {\n\t         // TODO Auto-generated method stub\n\t         System.out.println(\"Squeak\");\n\t    }\n\t \n\t}\n\nMallardDuck.java:\n\n\t// MallardDuck\n\tpublic class MallardDuck extends Duck {\n\t \n\t    public MallardDuck() {\n\t        quackBehavior = new Quack();\n\t        flyBehavior = new FlyWithWings();\n\t    }\n\t \n\t    @Override\n\t    public void display() {\n\t        // TODO Auto-generated method stub\n\t        System.out.println(\"I'm a real Mallard duck\");\n\t    }\n\t \n\t}\n\nModelDuck.java:\n\n\t// ModelDuck\n\tpublic class ModelDuck extends Duck {\n\t \n\t    ModelDuck() {\n\t         flyBehavior = new FlyNoWay();\n\t         quackBehavior = new Quack();\n\t    }\n\t \n\t    @Override\n\t    public void display() {\n\t        // TODO Auto-generated method stub\n\t        System.out.println(\"I'm a model duck!\");\n\t    }\n\t \n\t}\n\nTest.java\n\n\t// Test.java\n\tpublic class Test {\n\t \n\t    /**\n\t    * @param args\n\t    */\n\t    public static void main(String[] args) {\n\t        // TODO Auto-generated method stub\n\t        Duck mallard = new MallardDuck();\n\t        mallard.performFly();\n\t        mallard.performQuack();\n\t \n\t        System.out.println(\"------------------- now, change the duck! --------------------\");\n\t \n\t        Duck model = new ModelDuck();\n\t        model.performFly();\n\t        System.out.println(\"------------------- now, set rocked on the model! --------------------\");\n\t        model.setFlyBehavior(new FlyRockedPowered());\n\t        model.performFly();\n\t    }\n\t \n\t}","slug":"/2012/09-02-0.html","published":1,"updated":"2015-06-19T16:09:05.000Z","comments":1,"photos":[],"link":"","_id":"ciiwjp31p0045of6g23ekbapx"},{"date":"2011-12-14T16:00:00.000Z","layout":"post","title":"序对的一种过程性表示","_content":"\n\n考虑这样一个问题，设计一个数据结构，使其表示有理数。\n\nSo easy!\n\n\ttypedef struct rat{  \n\t int num;  \n\t int den;  \n\t}rat;\n\n其中，num表示该有理数的分子，den表示该有理数的分母，而整个数据结构rat即可表示为有理数。如果要得到该有理数的分子，可用rat.num表示，而rat.den则表示分母。\n\n那么，如果不用数据结构，完全用过程来表示这样的数据，可行吗？\n\n“一般而言，我们总可以将数据定义为一组适当的选择函数和构造函数，以及为使这些过程成为一套合法表示，它们就必须满足的一组特定条件。”————–SICP\n\n我们定义这样三个过程，\n\n* cons————–将两个对象粘接到一起\n* car—————-取出第一个对象\n* cdr—————-取出第二个对象\n\n其中，cons为构造函数，car和cdr为选择函数，而这些操作满足的条件就是：对任何对象x和y，如果z是(cons x y)，则(car z)为x，(cdr z)为y。\n\n这样，我们确实能够完全不用任何数据结构，只使用过程就可以实现序对。如下：\n\n\t(define (cons x y)  \n\t     (define (dispatch m)  \n\t            (cond ((= m 0) x)  \n\t                  ((= m 1) y)  \n\t                  (else (error \"Argument not 0 or 1 ---------CONS\" m))))  \n\t     dispatch)  \n\t \n\t(define (car z) (z 0))  \n\t(define (cdr z) (z 1))\n\n上面是采用Lisp实现的，但是用C呢？\n\n\t#include \"stdio.h\"  \n\t \n\ttypedef int (*pFunToDispatch)(int);  \n\t \n\tpFunToDispatch pairConstructor(int x, int y)  \n\t{  \n\t    int dispatch(int m)  \n\t    {  \n\t        return (m == 0) ? x : y;  \n\t    }  \n\t \n\t    return dispatch;  \n\t}  \n\t \n\tint firstOfPair(pFunToDispatch pair)  \n\t{  \n\t    return (*pair)(0);  \n\t}  \n\t \n\tint secondOfPair(pFunToDispatch pair)  \n\t{  \n\t    return (*pair)(1);  \n\t}  \n\t \n\tint main(int argc, char** argv)  \n\t{  \n\t    pFunToDispatch pair = pairConstructor(11, 12);  \n\t \n\t    int first = (*pair)(0);  \n\t    int second = (*pair)(1);  \n\t \n\t    printf(\"%d, %d\\n\", first, second);  \n\t \n\t    return 0;  \n\t}\n\n注意，由于ANSI C并不支持函数的嵌套定义，所以上述函数只适用在GCC中，而且可能会出问题，见http://tieba.baidu.com/p/1192690362?pn=1。\n\n补充：\n\n序对用过程性表示的另一种方法：\n\n\t(define (cons x y)  \n\t      (lambda (m) (m x y)))  \n\t \n\t(define (car z)  \n\t      (z (lambda (p q) p)))  \n\t \n\t(define (cdr z)  \n\t      (z (lambda (p q) q)))","source":"_posts/2011-12-15-0.md","raw":"---\ndate: 2011-12-15\nlayout: post\ntitle: 序对的一种过程性表示\npermalink: '/2011/12-15-0.html'\ncategories:\n- lisp\ntags:\n- 设计\n---\n\n\n考虑这样一个问题，设计一个数据结构，使其表示有理数。\n\nSo easy!\n\n\ttypedef struct rat{  \n\t int num;  \n\t int den;  \n\t}rat;\n\n其中，num表示该有理数的分子，den表示该有理数的分母，而整个数据结构rat即可表示为有理数。如果要得到该有理数的分子，可用rat.num表示，而rat.den则表示分母。\n\n那么，如果不用数据结构，完全用过程来表示这样的数据，可行吗？\n\n“一般而言，我们总可以将数据定义为一组适当的选择函数和构造函数，以及为使这些过程成为一套合法表示，它们就必须满足的一组特定条件。”————–SICP\n\n我们定义这样三个过程，\n\n* cons————–将两个对象粘接到一起\n* car—————-取出第一个对象\n* cdr—————-取出第二个对象\n\n其中，cons为构造函数，car和cdr为选择函数，而这些操作满足的条件就是：对任何对象x和y，如果z是(cons x y)，则(car z)为x，(cdr z)为y。\n\n这样，我们确实能够完全不用任何数据结构，只使用过程就可以实现序对。如下：\n\n\t(define (cons x y)  \n\t     (define (dispatch m)  \n\t            (cond ((= m 0) x)  \n\t                  ((= m 1) y)  \n\t                  (else (error \"Argument not 0 or 1 ---------CONS\" m))))  \n\t     dispatch)  \n\t \n\t(define (car z) (z 0))  \n\t(define (cdr z) (z 1))\n\n上面是采用Lisp实现的，但是用C呢？\n\n\t#include \"stdio.h\"  \n\t \n\ttypedef int (*pFunToDispatch)(int);  \n\t \n\tpFunToDispatch pairConstructor(int x, int y)  \n\t{  \n\t    int dispatch(int m)  \n\t    {  \n\t        return (m == 0) ? x : y;  \n\t    }  \n\t \n\t    return dispatch;  \n\t}  \n\t \n\tint firstOfPair(pFunToDispatch pair)  \n\t{  \n\t    return (*pair)(0);  \n\t}  \n\t \n\tint secondOfPair(pFunToDispatch pair)  \n\t{  \n\t    return (*pair)(1);  \n\t}  \n\t \n\tint main(int argc, char** argv)  \n\t{  \n\t    pFunToDispatch pair = pairConstructor(11, 12);  \n\t \n\t    int first = (*pair)(0);  \n\t    int second = (*pair)(1);  \n\t \n\t    printf(\"%d, %d\\n\", first, second);  \n\t \n\t    return 0;  \n\t}\n\n注意，由于ANSI C并不支持函数的嵌套定义，所以上述函数只适用在GCC中，而且可能会出问题，见http://tieba.baidu.com/p/1192690362?pn=1。\n\n补充：\n\n序对用过程性表示的另一种方法：\n\n\t(define (cons x y)  \n\t      (lambda (m) (m x y)))  \n\t \n\t(define (car z)  \n\t      (z (lambda (p q) p)))  \n\t \n\t(define (cdr z)  \n\t      (z (lambda (p q) q)))","slug":"/2011/12-15-0.html","published":1,"updated":"2015-06-19T16:09:05.000Z","comments":1,"photos":[],"link":"","_id":"ciiwjp31r0048of6goudm8d67"},{"date":"2011-10-15T16:00:00.000Z","layout":"post","title":"一个N个整数序列取M个数，使其概率相同问题","_content":"\n这是今天上午在同济笔试百度的题目，当时没做出来，那个郁闷，现把思路放在此处纪念已逝的笔试。\n\n原题大概是这样的：一个服务器一天内会收到很多request，但是服务器只能存放m个request，试设计一种算法，使得在时时的reqest中选择m个保存，并保证最后各个request被选中的概率为大致相同。记住，不到最后，不知道request的总数n.\n\n其实，这个题目可以这样解：\n\n前m个request依次放入服务器中，当第m+1个来临时，以m/(m+1)的概率选中，并在已保存的m个request中等概率选择一个替换之。当第m+2个来临时，以\n\nm/(m+2)的概率选中，并在已保存的m个request中等概率选择一个替换之。 依次类推，第N个request以m/N的概率被选择，并在已保存的m个request中等概率选择一个替换之。最终每个request被选择的概率为m/n.\n\n证明如下(数学归纳法）：\n\n当n=m+1时，第m+1选中的概率为m/(m+1)，而第一个被选中的概率为：1/(m+1) + m/(m+1) * (m-1)/m = m/(m+1);\n\n假设当n = N时，每个request被选择的概率为m/N;\n\n现证明当n = N+1时，每个request被选择的概率为m / (N+1).\n\n第N+1个被选中的概率当然为m/(N+1)，而第一个request被选择的概率为：m/N * ( (N+1-m)/(N+1) + m/(N+1) * (m-1)/m = m / (N+1)；其余request被选择的概率也一样，得证当n = N+1时，每个request被选择的概率为m / (N+1)。\n\n综上得，第方法可以实现最最终每个request被选择的为m/n.\n","source":"_posts/2011-10-16-0.md","raw":"---\ndate: 2011-10-16\nlayout: post\ntitle: 一个N个整数序列取M个数，使其概率相同问题\npermalink: '/2011/10-16-0.html'\ncategories:\n- 算法\ntags:\n- 面试题\n---\n\n这是今天上午在同济笔试百度的题目，当时没做出来，那个郁闷，现把思路放在此处纪念已逝的笔试。\n\n原题大概是这样的：一个服务器一天内会收到很多request，但是服务器只能存放m个request，试设计一种算法，使得在时时的reqest中选择m个保存，并保证最后各个request被选中的概率为大致相同。记住，不到最后，不知道request的总数n.\n\n其实，这个题目可以这样解：\n\n前m个request依次放入服务器中，当第m+1个来临时，以m/(m+1)的概率选中，并在已保存的m个request中等概率选择一个替换之。当第m+2个来临时，以\n\nm/(m+2)的概率选中，并在已保存的m个request中等概率选择一个替换之。 依次类推，第N个request以m/N的概率被选择，并在已保存的m个request中等概率选择一个替换之。最终每个request被选择的概率为m/n.\n\n证明如下(数学归纳法）：\n\n当n=m+1时，第m+1选中的概率为m/(m+1)，而第一个被选中的概率为：1/(m+1) + m/(m+1) * (m-1)/m = m/(m+1);\n\n假设当n = N时，每个request被选择的概率为m/N;\n\n现证明当n = N+1时，每个request被选择的概率为m / (N+1).\n\n第N+1个被选中的概率当然为m/(N+1)，而第一个request被选择的概率为：m/N * ( (N+1-m)/(N+1) + m/(N+1) * (m-1)/m = m / (N+1)；其余request被选择的概率也一样，得证当n = N+1时，每个request被选择的概率为m / (N+1)。\n\n综上得，第方法可以实现最最终每个request被选择的为m/n.\n","slug":"/2011/10-16-0.html","published":1,"updated":"2015-06-19T16:09:05.000Z","comments":1,"photos":[],"link":"","_id":"ciiwjp31w004cof6gqqnr27a5"},{"date":"2011-10-06T16:00:00.000Z","layout":"post","title":"编写高质量C语言代码 -- API设计","_content":"\n\n首先我们先来看一个程序：\n\n\tchar* strdup(char* str)\n\t{\n\t    char* strNew;\n\t \n\t    strNew = (char*)malloc(strlen(str) + 1);\n\t    strcpy(strNew, str);\n\t    return(strNew);\n\t}\n\n上面这个程序会发生什么情况？如果malloc失败，strNew为NULL，oh, no！这个malloc也太难用了吧，老是忘记要判断返回值是否为NULL。没错，但这不是你的错，是malloc的错。为什么malloc函数返回值既 可能是新分配的地址，又可能是NULL，即表示malloc出错呢？如果malloc函数改成如下：\n\n\tbool malloc(void* ptr, size_t size);\n\nptr为指向新分配内存的指针，size为新分配内存的大小，返回值为malloc成功与否。若是这样的malloc，你会用错吗？\n\n还记得那万恶的getchar函数吗？对，它的原型是：\n\n\tint getchar();\n\n为什么是int，而不是char呢？坑爹呢？有木有！有木有啊！无数次错误的用成：\n\n\tchar c;  \n\t \n\tc = getchar();  \n\tif(c == EOF)  \n\t    ...\n\n要是有更好的函数，鬼才愿意用这个函数！若是这样的原型：\n\n\tbool getchar(char* c);\n\n整个世界和谐了。**Don’t mix error and other special-purpose values into your outputs of interfaces.**\n\n这不是最坑爹的，且看下面的BOSS级函数：\n\n\tvoid* realloc(void* pv, size_t size);\n\n在C library manual中有这样几句话（译）：\n\n1. 如果pv为NULL， size不为0，则此函数相当于malloc(size);\n2. 如果size为0， pv不为NULL， 则此函数相当于free();\n3. 如果pv为NULL，size为0，则未定义。\n\n这怎么回事？这明明是realloc函数啊，怎么又出来malloc和free函数了。如果realloc能完成malloc和free函数的功 能，后面两个函数累赘了吧？还有，如果realloc失败，realloc返回的将是NULL。这又在坑爹啊，我多么想这么用啊：\n\n\tptr = realloc(ptr, newSize)\n\n发现ptr为NULL，不是吧，内存泄露了（ptr如果是ptr所指内存的唯一取的方法，那么您将永远失去您对那块内存的控制）。\n\n如果realloc不是这样的万能，我们的生活会不会更和谐？**Don’t write multipurpose functions. Remember K.I.S.S..**\n\n当然，作为一般性的考试题，总会有附加题的，请看题：\n\n\tfseek(fpDocument, offset, 1);\n\n这不是将fpDocument文件指针定位嘛，有问题？请问，定位在哪？等等，我得去看下fseek函数的说明。。。。N分钟过后。。。。\n\n靠，如果是这样：\n\n\tfseek(fpDocument, offset, SEEK_CUR);\n\n有需要去查fseek函数的说明吗？万恶的bool型参数请参见[博文](http://blog.csdn.net/jay1002008/article/details/6761575)。Don’t use magic numbers and boolean arguments.\n\n小结：良好的API设计将是您编写bug_free代码的福音，请投入她的怀抱，感受她带来的好处吧~","source":"_posts/2011-10-07-0.md","raw":"---\ndate: 2011-10-07\nlayout: post\ntitle: 编写高质量C语言代码 -- API设计\npermalink: '/2011/10-07-0.html'\ncategories:\n- c/c++\ntags:\n- 设计\n- 代码质量\n---\n\n\n首先我们先来看一个程序：\n\n\tchar* strdup(char* str)\n\t{\n\t    char* strNew;\n\t \n\t    strNew = (char*)malloc(strlen(str) + 1);\n\t    strcpy(strNew, str);\n\t    return(strNew);\n\t}\n\n上面这个程序会发生什么情况？如果malloc失败，strNew为NULL，oh, no！这个malloc也太难用了吧，老是忘记要判断返回值是否为NULL。没错，但这不是你的错，是malloc的错。为什么malloc函数返回值既 可能是新分配的地址，又可能是NULL，即表示malloc出错呢？如果malloc函数改成如下：\n\n\tbool malloc(void* ptr, size_t size);\n\nptr为指向新分配内存的指针，size为新分配内存的大小，返回值为malloc成功与否。若是这样的malloc，你会用错吗？\n\n还记得那万恶的getchar函数吗？对，它的原型是：\n\n\tint getchar();\n\n为什么是int，而不是char呢？坑爹呢？有木有！有木有啊！无数次错误的用成：\n\n\tchar c;  \n\t \n\tc = getchar();  \n\tif(c == EOF)  \n\t    ...\n\n要是有更好的函数，鬼才愿意用这个函数！若是这样的原型：\n\n\tbool getchar(char* c);\n\n整个世界和谐了。**Don’t mix error and other special-purpose values into your outputs of interfaces.**\n\n这不是最坑爹的，且看下面的BOSS级函数：\n\n\tvoid* realloc(void* pv, size_t size);\n\n在C library manual中有这样几句话（译）：\n\n1. 如果pv为NULL， size不为0，则此函数相当于malloc(size);\n2. 如果size为0， pv不为NULL， 则此函数相当于free();\n3. 如果pv为NULL，size为0，则未定义。\n\n这怎么回事？这明明是realloc函数啊，怎么又出来malloc和free函数了。如果realloc能完成malloc和free函数的功 能，后面两个函数累赘了吧？还有，如果realloc失败，realloc返回的将是NULL。这又在坑爹啊，我多么想这么用啊：\n\n\tptr = realloc(ptr, newSize)\n\n发现ptr为NULL，不是吧，内存泄露了（ptr如果是ptr所指内存的唯一取的方法，那么您将永远失去您对那块内存的控制）。\n\n如果realloc不是这样的万能，我们的生活会不会更和谐？**Don’t write multipurpose functions. Remember K.I.S.S..**\n\n当然，作为一般性的考试题，总会有附加题的，请看题：\n\n\tfseek(fpDocument, offset, 1);\n\n这不是将fpDocument文件指针定位嘛，有问题？请问，定位在哪？等等，我得去看下fseek函数的说明。。。。N分钟过后。。。。\n\n靠，如果是这样：\n\n\tfseek(fpDocument, offset, SEEK_CUR);\n\n有需要去查fseek函数的说明吗？万恶的bool型参数请参见[博文](http://blog.csdn.net/jay1002008/article/details/6761575)。Don’t use magic numbers and boolean arguments.\n\n小结：良好的API设计将是您编写bug_free代码的福音，请投入她的怀抱，感受她带来的好处吧~","slug":"/2011/10-07-0.html","published":1,"updated":"2015-06-19T16:09:05.000Z","comments":1,"photos":[],"link":"","_id":"ciiwjp31x004fof6gyhcxgh1u"},{"date":"2011-10-15T16:00:00.000Z","layout":"post","title":"编写高质量C语言代码 -- Assert Yourself","_content":"\n\nC语言中assert功能强大，人称“断言”，如语句assert ( expression )，即断言expression始终为true, 若为false，则程序运行失败。\n\n但是，assert ( expression ) 看似function，但它其实是macro, 而且只是一个debug-only的宏，即只有在定义DEBUG宏的情况下才有用。但是它却是一个强大的高度工具，而且也是编码bug-free的code的有力助手。\n\n举个例子，有以下这样一个function:\n\nexample 1:\n\n\t/* memcpy -- copy a nonoverlapping memory block */\n\tvoid* memcpy(void* pvTo, void* pvFrom, size_t size)\n\t{\n\t    byte* pbTo = (byte*)pvTo;\n\t    byte* pbFrom = (byte*)pvFrom;\n\t \n\t    while(size-- > 0)\n\t        *pbTo = *pvFrom;\n\t \n\t    return(pvTo);\n\t}\n\n有经验的programmer一看就知道这是一个有bug的function。如果如此应用：\n\n1.\n\n\tmemcpy(NULL, pvFrom, size);\n\n2.\n\n\tmemcpy(pvTo, NULL, size);\n\n就会出现问题。NULL是0，而对0地址解引用会出现什么事？SO BAD！\n\n那么怎么办呢？在对pbTo与pvFrom解引用之前进行指针检查，进行如下改变：\n\nexample 2 :\n\n\t/* memcpy -- copy a nonoverlapping memory block */\n\tvoid* memcpy(void* pvTo, void* pvFrom, size_t size)\n\t{\n\t    byte* pbTo = (byte*)pvTo;\n\t    byte* pbFrom = (byte*)pvFrom;\n\t \n\t    if(pvTo == NULL || pvFrom == NULL){\n\t        fprintf(stderr, \"Bad args in memcpy\\n\");\n\t        abort();\n\t    }\n\t \n\t    while(size-- > 0)\n\t        *pbTo++ = *pvFrom++;\n\t \n\t    return(pvTo);\n\t}\n\nOK， Perfect ！但是身为一个持有完美主义的coder，似乎这样的代码不是那么一回事。有人教导我们，编写代码的时候要有两个版本：Debug Version and Ship Version。我们新加的语句好像是Debug Version里的吧，怎么能让它出现在Ship Version里呢？于是乎：\n\nexample 3:\n\n\t/* memcpy -- copy a nonoverlapping memory block */\n\tvoid* memcpy(void* pvTo, void* pvFrom, size_t size)\n\t{\n\t    byte* pbTo = (byte*)pvTo;\n\t    byte* pbFrom = (byte*)pvFrom;\n\t \n\t#ifdef DEBUG\n\t    if(pvTo == NULL || pvFrom == NULL){\n\t         fprintf(stderr, \"Bad args in memcpy\\n\");\n\t         abort();\n\t    }\n\t#endif\n\t \n\t    while(size-- > 0)\n\t        *pbTo++ = *pvFrom++;\n\t \n\t    return(pvTo);\n\t}\n\n这下没问题了吧？嗯，我们的主角assert呢？怎么没有？别急，马上就来，有句话不是说：英雄总是最后登场的嘛。注意我们加的Debug语句不就是在测试pvTo与pvFrom不为NULL吗？这不就是assert的功能！So:\n\nexample 4:\n\n\t/* memcpy -- copy a nonoverlapping memory block */\n\tvoid* memcpy(void* pvTo, void* pvFrom, size_t size)\n\t{\n\t    byte* pbTo = (byte*)pvTo;\n\t    byte* pbFrom = (byte*)pvFrom;\n\t \n\t    assert(pvTo != NULL && pvFrom != NULL);\n\t \n\t    while(size-- > 0)\n\t        *pbTo++ = *pvFrom++;\n\t    return(pvTo);\n\t}\n\n嗯，好像可以了。但是~，如果pvTo与pvFrom指向的内存块是overlapped的呢？oh, no！所以还等断言pvTo与pvFrom是没有overlapped的。最终版登场：\n\nexample5:\n\n\t/* memcpy -- copy a nonoverlapping memory block */\n\tvoid* memcpy(void* pvTo, void* pvFrom, size_t size)\n\t{\n\t    byte* pbTo = (byte*)pvTo;\n\t    byte* pbFrom = (byte*)pvFrom;\n\t \n\t    assert(pvTo != NULL && pvFrom != NULL);\n\t    assert(pvTo >= pvFrom + size || pvFrom >= pbTo + size);\n\t \n\t    while(size-- > 0)\n\t        *pbTo++ = *pvFrom++;\n\t    return(pvTo);\n\t}\n\t\n小结：请使用assert 来code您的程序！","source":"_posts/2011-10-06-0.md","raw":"---\ndate: 2011-10-16\nlayout: post\ntitle: 编写高质量C语言代码 -- Assert Yourself\npermalink: '/2011/10-16-0.html'\ncategories:\n- c/c++\ntags:\n- 设计\n- 代码质量\n---\n\n\nC语言中assert功能强大，人称“断言”，如语句assert ( expression )，即断言expression始终为true, 若为false，则程序运行失败。\n\n但是，assert ( expression ) 看似function，但它其实是macro, 而且只是一个debug-only的宏，即只有在定义DEBUG宏的情况下才有用。但是它却是一个强大的高度工具，而且也是编码bug-free的code的有力助手。\n\n举个例子，有以下这样一个function:\n\nexample 1:\n\n\t/* memcpy -- copy a nonoverlapping memory block */\n\tvoid* memcpy(void* pvTo, void* pvFrom, size_t size)\n\t{\n\t    byte* pbTo = (byte*)pvTo;\n\t    byte* pbFrom = (byte*)pvFrom;\n\t \n\t    while(size-- > 0)\n\t        *pbTo = *pvFrom;\n\t \n\t    return(pvTo);\n\t}\n\n有经验的programmer一看就知道这是一个有bug的function。如果如此应用：\n\n1.\n\n\tmemcpy(NULL, pvFrom, size);\n\n2.\n\n\tmemcpy(pvTo, NULL, size);\n\n就会出现问题。NULL是0，而对0地址解引用会出现什么事？SO BAD！\n\n那么怎么办呢？在对pbTo与pvFrom解引用之前进行指针检查，进行如下改变：\n\nexample 2 :\n\n\t/* memcpy -- copy a nonoverlapping memory block */\n\tvoid* memcpy(void* pvTo, void* pvFrom, size_t size)\n\t{\n\t    byte* pbTo = (byte*)pvTo;\n\t    byte* pbFrom = (byte*)pvFrom;\n\t \n\t    if(pvTo == NULL || pvFrom == NULL){\n\t        fprintf(stderr, \"Bad args in memcpy\\n\");\n\t        abort();\n\t    }\n\t \n\t    while(size-- > 0)\n\t        *pbTo++ = *pvFrom++;\n\t \n\t    return(pvTo);\n\t}\n\nOK， Perfect ！但是身为一个持有完美主义的coder，似乎这样的代码不是那么一回事。有人教导我们，编写代码的时候要有两个版本：Debug Version and Ship Version。我们新加的语句好像是Debug Version里的吧，怎么能让它出现在Ship Version里呢？于是乎：\n\nexample 3:\n\n\t/* memcpy -- copy a nonoverlapping memory block */\n\tvoid* memcpy(void* pvTo, void* pvFrom, size_t size)\n\t{\n\t    byte* pbTo = (byte*)pvTo;\n\t    byte* pbFrom = (byte*)pvFrom;\n\t \n\t#ifdef DEBUG\n\t    if(pvTo == NULL || pvFrom == NULL){\n\t         fprintf(stderr, \"Bad args in memcpy\\n\");\n\t         abort();\n\t    }\n\t#endif\n\t \n\t    while(size-- > 0)\n\t        *pbTo++ = *pvFrom++;\n\t \n\t    return(pvTo);\n\t}\n\n这下没问题了吧？嗯，我们的主角assert呢？怎么没有？别急，马上就来，有句话不是说：英雄总是最后登场的嘛。注意我们加的Debug语句不就是在测试pvTo与pvFrom不为NULL吗？这不就是assert的功能！So:\n\nexample 4:\n\n\t/* memcpy -- copy a nonoverlapping memory block */\n\tvoid* memcpy(void* pvTo, void* pvFrom, size_t size)\n\t{\n\t    byte* pbTo = (byte*)pvTo;\n\t    byte* pbFrom = (byte*)pvFrom;\n\t \n\t    assert(pvTo != NULL && pvFrom != NULL);\n\t \n\t    while(size-- > 0)\n\t        *pbTo++ = *pvFrom++;\n\t    return(pvTo);\n\t}\n\n嗯，好像可以了。但是~，如果pvTo与pvFrom指向的内存块是overlapped的呢？oh, no！所以还等断言pvTo与pvFrom是没有overlapped的。最终版登场：\n\nexample5:\n\n\t/* memcpy -- copy a nonoverlapping memory block */\n\tvoid* memcpy(void* pvTo, void* pvFrom, size_t size)\n\t{\n\t    byte* pbTo = (byte*)pvTo;\n\t    byte* pbFrom = (byte*)pvFrom;\n\t \n\t    assert(pvTo != NULL && pvFrom != NULL);\n\t    assert(pvTo >= pvFrom + size || pvFrom >= pbTo + size);\n\t \n\t    while(size-- > 0)\n\t        *pbTo++ = *pvFrom++;\n\t    return(pvTo);\n\t}\n\t\n小结：请使用assert 来code您的程序！","slug":"/2011/10-16-0.html","published":1,"updated":"2015-06-19T16:09:05.000Z","comments":1,"photos":[],"link":"","_id":"ciiwjp31z004jof6gwifzj1kl"},{"date":"2011-06-03T16:00:00.000Z","layout":"post","title":"用代理类实现二组数组","_content":"\n C++语言在数组的支持方面不强其他语言强劲，如FORTRAN、BASIC、甚至在COBOL中可以产生二维数组、三维数组，乃至于n维数组，但你能 C++中这么做吗？有同学不同意了，C++中可以产生维数组啊，int data[2][3]不是吗？但是，如果这样：\n\n\tvoid processInput(int dim1, int dim2)  \n\t{  \n\t     int data[dim1][dim2];  \n\t     ........  \n\t}\n\n还行吗？C++不允许！\n\n那么怎么办呢？《more effective c++》中Item 30有详细的介绍，但没有给出具体代码。本人实现了下:\n\n\t#include   \n\tusing namespace std;  \n\ttemplate  \n\tclass Array2D{  \n\tpublic:  \n\t    Array2D(int realDim1, int realDim2);  \n\t    ~Array2D();  \n\t    class Array1D{  \n\t    public:  \n\t        Array1D(){};  \n\t        Array1D(int realDim2);  \n\t        Array1D& operator=(const Array1D& lhs);  \n\t        ~Array1D();  \n\t        T& operator[](int index);  \n\t        const T& operator[](int index)const;  \n\t    private:  \n\t        T* dim2Data;  \n\t        int dim2;  \n\t    };  \n\t    Array1D& operator[](int index);  \n\t    const Array1D& operator[](int index)const;  \n\tprivate:  \n\t    int dim1;  \n\t    Array1D* dim1Data;  \n\t};  \n\ttemplate \n\ttypename Array2D::Array1D& Array2D::Array1D::operator=(const Array1D& lhs)  \n\t{  \n\t    dim2 = lhs.dim2;  \n\t    dim2Data = new T[dim2];  \n\t    if(dim2Data == NULL)  \n\t        cout << \"There is no memory!\" << endl;  \n\t    for(int i = 0; i < dim2; ++i)  \n\t        dim2Data[i] = lhs.dim2Data[i];  \n\t    return *this;  \n\t}  \n\ttemplate \n\tArray2D::Array1D::Array1D(int realDim2)  \n\t:dim2(realDim2)  \n\t{  \n\t    dim2Data = new T[dim2];  \n\t    if(dim2Data == NULL)  \n\t        cout << \"There is no memory!\" << endl;  \n\t}  \n\ttemplate \n\tArray2D::Array2D(int realDim1, int realDim2)  \n\t:dim1(realDim1)  \n\t{  \n\t    typedef typename Array2D::Array1D myType;  \n\t    dim1Data = new myType[dim1];  \n\t    if(dim1Data == NULL)  \n\t        cout << \"There is no memory!\" << endl;  \n\t    for(int i = 0; i < dim1; ++i)  \n\t        dim1Data[i] = myType(realDim2); // using operator=!  \n\t}  \n\ttemplate \n\tArray2D::Array1D::~Array1D()  \n\t{  \n\t    delete []dim2Data;  \n\t}  \n\ttemplate \n\tArray2D::~Array2D()  \n\t{  \n\t    delete []dim1Data;  \n\t}  \n\ttemplate \n\tT& Array2D::Array1D::operator [](int index)  \n\t{  \n\t    return dim2Data[index];  \n\t}  \n\ttemplate \n\tconst T& Array2D::Array1D::operator [](int index)const \n\t{  \n\t    return dim2Data[index];  \n\t}  \n\ttemplate \n\ttypename Array2D::Array1D& Array2D::operator [](int index)  \n\t{  \n\t    return dim1Data[index];  \n\t}  \n\ttemplate \n\tconst typename Array2D::Array1D& Array2D::operator[](int index)const \n\t{  \n\t    return dim1Data[index];  \n\t}  \n\tint main()  \n\t{  \n\t    Array2D data(2, 3);  \n\t    for(int i = 0; i < 2; ++i)  \n\t        for(int j = 0; j < 3; ++j)  \n\t            data[i][j] = j;  \n\t    for(int i = 0; i < 2; ++i)  \n\t        for(int j = 0; j < 3; ++j)  \n\t            cout << data[i][j] << endl;  \n\t    return 0;  \n\t}\n\n当然，其中也遇到了一些困难，现整理如下：\n\n**FIRST**，代码第27行中，typename Array2D<T>::Array1D&，关键字typename有什么作用？\n\ntypename有双重意义，具体参见《effective c++》 Item 42。这里只由于其第二重意义。观察Array2D<T>::Array1D，其类型取决于template参数T。template内出现 的名称如果相依于某个template参数，称之为从属名称。如果从属名称在class内呈嵌套状，则称之为嵌套从属名称。而嵌套从属名称有可能导致解析 困难，所以必须在其前加上关键字typename表示其是一个类型。\n\n**SECOND**,代码50~55读者是否感到有些奇怪。为什么不写成dim1Data = new myType\\[dim1\\](realDim2);呢？事实上，该语句是不能通过编译的。因为这不符合C++的语法。那么只能用点小聪明代替了。这里还要注 意就是代码行62调用的是类赋值函数，刚开始笔者也在此处吃了亏。\n\n总之，学习C++之路还是很漫长啊。\n","source":"_posts/2011-06-04-0.md","raw":"---\ndate: 2011-06-04\nlayout: post\ntitle: 用代理类实现二组数组\npermalink: '/2011/06-04-0.html'\ncategories:\n- c/c++\ntags:\n- 设计\n- 面向对象\n---\n\n C++语言在数组的支持方面不强其他语言强劲，如FORTRAN、BASIC、甚至在COBOL中可以产生二维数组、三维数组，乃至于n维数组，但你能 C++中这么做吗？有同学不同意了，C++中可以产生维数组啊，int data[2][3]不是吗？但是，如果这样：\n\n\tvoid processInput(int dim1, int dim2)  \n\t{  \n\t     int data[dim1][dim2];  \n\t     ........  \n\t}\n\n还行吗？C++不允许！\n\n那么怎么办呢？《more effective c++》中Item 30有详细的介绍，但没有给出具体代码。本人实现了下:\n\n\t#include   \n\tusing namespace std;  \n\ttemplate  \n\tclass Array2D{  \n\tpublic:  \n\t    Array2D(int realDim1, int realDim2);  \n\t    ~Array2D();  \n\t    class Array1D{  \n\t    public:  \n\t        Array1D(){};  \n\t        Array1D(int realDim2);  \n\t        Array1D& operator=(const Array1D& lhs);  \n\t        ~Array1D();  \n\t        T& operator[](int index);  \n\t        const T& operator[](int index)const;  \n\t    private:  \n\t        T* dim2Data;  \n\t        int dim2;  \n\t    };  \n\t    Array1D& operator[](int index);  \n\t    const Array1D& operator[](int index)const;  \n\tprivate:  \n\t    int dim1;  \n\t    Array1D* dim1Data;  \n\t};  \n\ttemplate \n\ttypename Array2D::Array1D& Array2D::Array1D::operator=(const Array1D& lhs)  \n\t{  \n\t    dim2 = lhs.dim2;  \n\t    dim2Data = new T[dim2];  \n\t    if(dim2Data == NULL)  \n\t        cout << \"There is no memory!\" << endl;  \n\t    for(int i = 0; i < dim2; ++i)  \n\t        dim2Data[i] = lhs.dim2Data[i];  \n\t    return *this;  \n\t}  \n\ttemplate \n\tArray2D::Array1D::Array1D(int realDim2)  \n\t:dim2(realDim2)  \n\t{  \n\t    dim2Data = new T[dim2];  \n\t    if(dim2Data == NULL)  \n\t        cout << \"There is no memory!\" << endl;  \n\t}  \n\ttemplate \n\tArray2D::Array2D(int realDim1, int realDim2)  \n\t:dim1(realDim1)  \n\t{  \n\t    typedef typename Array2D::Array1D myType;  \n\t    dim1Data = new myType[dim1];  \n\t    if(dim1Data == NULL)  \n\t        cout << \"There is no memory!\" << endl;  \n\t    for(int i = 0; i < dim1; ++i)  \n\t        dim1Data[i] = myType(realDim2); // using operator=!  \n\t}  \n\ttemplate \n\tArray2D::Array1D::~Array1D()  \n\t{  \n\t    delete []dim2Data;  \n\t}  \n\ttemplate \n\tArray2D::~Array2D()  \n\t{  \n\t    delete []dim1Data;  \n\t}  \n\ttemplate \n\tT& Array2D::Array1D::operator [](int index)  \n\t{  \n\t    return dim2Data[index];  \n\t}  \n\ttemplate \n\tconst T& Array2D::Array1D::operator [](int index)const \n\t{  \n\t    return dim2Data[index];  \n\t}  \n\ttemplate \n\ttypename Array2D::Array1D& Array2D::operator [](int index)  \n\t{  \n\t    return dim1Data[index];  \n\t}  \n\ttemplate \n\tconst typename Array2D::Array1D& Array2D::operator[](int index)const \n\t{  \n\t    return dim1Data[index];  \n\t}  \n\tint main()  \n\t{  \n\t    Array2D data(2, 3);  \n\t    for(int i = 0; i < 2; ++i)  \n\t        for(int j = 0; j < 3; ++j)  \n\t            data[i][j] = j;  \n\t    for(int i = 0; i < 2; ++i)  \n\t        for(int j = 0; j < 3; ++j)  \n\t            cout << data[i][j] << endl;  \n\t    return 0;  \n\t}\n\n当然，其中也遇到了一些困难，现整理如下：\n\n**FIRST**，代码第27行中，typename Array2D<T>::Array1D&，关键字typename有什么作用？\n\ntypename有双重意义，具体参见《effective c++》 Item 42。这里只由于其第二重意义。观察Array2D<T>::Array1D，其类型取决于template参数T。template内出现 的名称如果相依于某个template参数，称之为从属名称。如果从属名称在class内呈嵌套状，则称之为嵌套从属名称。而嵌套从属名称有可能导致解析 困难，所以必须在其前加上关键字typename表示其是一个类型。\n\n**SECOND**,代码50~55读者是否感到有些奇怪。为什么不写成dim1Data = new myType\\[dim1\\](realDim2);呢？事实上，该语句是不能通过编译的。因为这不符合C++的语法。那么只能用点小聪明代替了。这里还要注 意就是代码行62调用的是类赋值函数，刚开始笔者也在此处吃了亏。\n\n总之，学习C++之路还是很漫长啊。\n","slug":"/2011/06-04-0.html","published":1,"updated":"2015-06-19T16:09:05.000Z","comments":1,"photos":[],"link":"","_id":"ciiwjp320004nof6gxyfnjv84"},{"date":"2011-05-28T16:00:00.000Z","layout":"post","title":"重新审视这个世界","_content":"\n\n断断续续读完了《推理的迷宫》一书，这是一本难得的好书。看到书的副标题，“悖论，谜题，及知识的脆弱性”，这本书就完全吸引了我。\n\n第一章就让我这个基本是“悖论盲”的人为之一惊。“缸中之脑”，对，我可能真的是不存在的，只是实验室里的一颗大脑。我这颗大脑不停的接收各种实验师给我 的电信号刺激，让我觉得我活在现在这个世界上，早晨起床，中午吃饭……。当然，这个世界也有可能存在的，我并不只是一颗大脑。从小就接受神奇国度的应试教 育，基本没有接触过这样的知识熏陶，我感到很兴奋。\n\n当享受到“亨普尔的乌鸦”这章时，我突然觉得我所掌握的各种知识的脆弱性了。一直认为乌鸦嘛，当然是黑色的嘛，有不是黑色的乌鸦吗？但是，我们获得知识只 有两种方法，一种是归纳，一种是演绎。而“所有乌鸦都是黑色的”这个命题就是由归纳得来的。而归纳这个方法值得信任吗？谁能保证下一次发现的乌鸦不是红色 的呢？又或者不是蓝色的呢？以前接受教育都是老师说什么就是什么，“两点确定一条直线”就是“两点确定一条直线”，不许怀疑，这是公理。什么是公理，公理 就是大家公认的定理，不需要证明的。但是，为什么不怀疑“两点不能确定一条直线”呢？也许在我们这个世界是这样子的，但是谁能保证在宇宙的另外一个星球上 是“三点确定一条直线”呢？\n\n随着阅读的深入，我在享受这本书给我的快乐的同时，也越来越怀疑这个世界的存在性与我掌握的知识的正确性。我看到的“绿色”是真的绿色吗？还是我看到的其 实是“黑色”，而我把它称为“绿色”，你看到的其实是“白色”，而你把它也称为“绿色”。为什么要这么做呢？我们从小就被长辈教育这是“绿色”，而不是其 它颜色，于是这就是“绿色”。没有能保证我们看到的“绿色”都是相同的颜色。\n\n这个世界真的存在吗？可信吗？\n","source":"_posts/2011-05-29-0.md","raw":"---\ndate: 2011-05-29\nlayout: post\ntitle: 重新审视这个世界\npermalink: '/2011/05-29-0.html'\ncategories:\n- 杂感\ntags:\n---\n\n\n断断续续读完了《推理的迷宫》一书，这是一本难得的好书。看到书的副标题，“悖论，谜题，及知识的脆弱性”，这本书就完全吸引了我。\n\n第一章就让我这个基本是“悖论盲”的人为之一惊。“缸中之脑”，对，我可能真的是不存在的，只是实验室里的一颗大脑。我这颗大脑不停的接收各种实验师给我 的电信号刺激，让我觉得我活在现在这个世界上，早晨起床，中午吃饭……。当然，这个世界也有可能存在的，我并不只是一颗大脑。从小就接受神奇国度的应试教 育，基本没有接触过这样的知识熏陶，我感到很兴奋。\n\n当享受到“亨普尔的乌鸦”这章时，我突然觉得我所掌握的各种知识的脆弱性了。一直认为乌鸦嘛，当然是黑色的嘛，有不是黑色的乌鸦吗？但是，我们获得知识只 有两种方法，一种是归纳，一种是演绎。而“所有乌鸦都是黑色的”这个命题就是由归纳得来的。而归纳这个方法值得信任吗？谁能保证下一次发现的乌鸦不是红色 的呢？又或者不是蓝色的呢？以前接受教育都是老师说什么就是什么，“两点确定一条直线”就是“两点确定一条直线”，不许怀疑，这是公理。什么是公理，公理 就是大家公认的定理，不需要证明的。但是，为什么不怀疑“两点不能确定一条直线”呢？也许在我们这个世界是这样子的，但是谁能保证在宇宙的另外一个星球上 是“三点确定一条直线”呢？\n\n随着阅读的深入，我在享受这本书给我的快乐的同时，也越来越怀疑这个世界的存在性与我掌握的知识的正确性。我看到的“绿色”是真的绿色吗？还是我看到的其 实是“黑色”，而我把它称为“绿色”，你看到的其实是“白色”，而你把它也称为“绿色”。为什么要这么做呢？我们从小就被长辈教育这是“绿色”，而不是其 它颜色，于是这就是“绿色”。没有能保证我们看到的“绿色”都是相同的颜色。\n\n这个世界真的存在吗？可信吗？\n","slug":"/2011/05-29-0.html","published":1,"updated":"2015-06-19T16:09:05.000Z","comments":1,"photos":[],"link":"","_id":"ciiwjp324004rof6gf96p9u1y"},{"date":"2010-09-02T16:00:00.000Z","layout":"post","title":"关于幸福","_content":"\n\n幸福是什么？网上流行这样一句话：幸福就是猫吃鱼，狗吃肉，奥特曼打小怪兽。这虽是一句俏皮话，但是，为什么不是猫吃肉，奥特曼吃鱼，让狗去打小怪兽呢？ 当然，这么办的话，猫不会觉得幸福，狗也过得不自在，奥特曼更是不知道幸福为何物了。所以，幸福的定义只能是主观的，每个人的幸福并不相同。比如，我们的 朝鲜同胞们有一辆自行车就觉得很幸福，而我们有辆普桑为什么就没觉得有多少幸福。\n\n那么，怎么才能幸福呢？是拥有大量的财产，还是手握巨大的权力？这个问题，答案只有自己知道。这里，我们只能告诉你一点点幸福的秘诀。\n\n**尽量获取不容易情感适应的，且会带来快乐的外部刺激；尽量规避不容易情感适应的，且会带来不快的外部刺激。** 什么是情感适应呢？我们都会有这样的经历，当手伸入零度的冰水中时，会觉得异常冰冷与不 适应，但是随着时间的推移，我们渐渐觉得没有先前这么不适应了。这就是情感适应的因故。当然，有童鞋会说这不是生理上的适应嘛。事实上，导致情感适应的主 要原因包括生理适应，大脑对熟悉信息的模块化记忆，对于外部刺激注意力的转移以及对于事件结果的合理化解释。对于某件产生负向情感的事情，如将手伸入冰水 中，我们逐渐情感适应了，当然也不觉得这么难受了。相反，如果某件产生正向情感的事，比如说中的百万元的彩票，情感适应容易与否直接关系到快乐持续时间的 长短了。所以，对于能产生快乐的外部刺激，我们追求不容易情感适应的，如旅行等，而对于带来不快的外部刺激，我们则尽量避开不容易情感适应的，如失恋。\n\n**尽量花钱在单独消费时就可以感知其品质变化的产品或服务上，而不要花在只有在比较时才能感知相应变化的产品或服务上。** 举个例子，假如你想更换家中书房里的办公椅，因为这把椅子坐着不舒服，有种倾斜的感觉，所以想把它换成高档的办公椅。与此同时，你又想更换自己的数码相机，因为是几年前买的，虽然镜头和其他功能都让人满意，但却只有 800 万相素。而新品虽然在其他方面相差不大，但却有 1200 万相素。办公椅与相机价格相当，但是你只有购买其中一个，你经常在家里办公，也经常外出旅游摄影。你会如何选择呢？幸福学告诉你，应该选择办公椅。为什么呢？因为办公椅解决的是你的肌肉疲劳程度，而这点又是人体比较容易感知的，无须进行比较。相反，照片的相素从 800 万上升到 1200 万，只有在比较的情况下才能感知，一般人肉眼是无法将其分辨。所以，把钱花在容易感知其品质变化的产品或服务上才是正确的选择。\n\n**偶尔吃点苦能提高整体幸福水平，偶尔体验较为高档的享受都降低整体幸福水平，除非这些偶尔的体验被你视为非正常状态。** 如果你每天开车上班，可以每星期有那么一天去挤一次公交。这样的体验，能让你更能感受到开车上班的幸福感。正如有人说：忆苦思甜甜更甜。然而，偶尔体验较为高档的享受就不提倡了。如果你开的车是辆奇锐 QQ ，有个机会让你去免费试开宝马一个星期，你会把握这个机会吗？面对这样的机会，我们还是避而远之比较好。如果你去尝试了，等一个星期结束，你会发现你的奇锐 QQ 制动又差，方向盘又不舒适，总之是这有问题，那也有问题。然后，就会抱怨你的爱车有多么得差劲。其实，你大可不必这样，因为完全可以避免。当然，这里还有一种极端的情况，如果你这一辈子都买不起宝马，那么我建议去尝试吧，就好比刘姥姥游大观园而已。\n\n**学会创造流体验。** 所谓流体验，是指人们在进行某些活动时的忘我状态，此时人们完全被活动吸引，所有注意力 完全投注于活动中，并且觉得没有比活动本身更加重要的东西。我们生活中多多少少，有意无意地都经历过一些流体验。例如阅读一本情节跌宕起伏的小说，你会觉 得整个自己都被这小说吸引了，然后会觉得时间过得很快，不知不觉就几个小时过去了。等阅读完后，会感觉自己仍然沉浸在阅读这本小说的快乐之中。生活中多经 历些流体验，就会觉得更加幸福与快乐。\n\n**不要忽视预测和体验时生理、经济、社会等状况的不同。此时所欲未必是彼时所欲，己所欲未必是他人所欲。** 我们一定遇上过这样的情况，当你饥肠辘辘时点菜时，通常点了一大堆菜。等到你吃得差不多 的时候，就会发现你已经吃不了这么多菜了。这就是你点菜时候的状态并不是你吃菜时候的状态了。另一个例子就是，如果让你的父母来选择你们的配偶，通常是以 贤淑为标准的，他们从来不会把性生活作为标准之一。因为在他们的年龄来看这种事，已经不再重要了。这也就是说自己想要的不一定是他人想要的东西。\n\n总的来说，幸福可以自己去把握的。对于一些网上报道的城市幸福指数排名，我们大可不必理会。幸福从来都是自己的事，正如，猫吃着鱼，狗吃着肉，奥特曼一直喜欢打怪兽。\n\n------------------\n\n--《撬动幸福》   奚恺元","source":"_posts/2010-09-03-0.md","raw":"---\ndate: 2010-09-03\nlayout: post\ntitle: 关于幸福\npermalink: '/2010/09-03-0.html'\ncategories:\n- 杂感\ntags:\n---\n\n\n幸福是什么？网上流行这样一句话：幸福就是猫吃鱼，狗吃肉，奥特曼打小怪兽。这虽是一句俏皮话，但是，为什么不是猫吃肉，奥特曼吃鱼，让狗去打小怪兽呢？ 当然，这么办的话，猫不会觉得幸福，狗也过得不自在，奥特曼更是不知道幸福为何物了。所以，幸福的定义只能是主观的，每个人的幸福并不相同。比如，我们的 朝鲜同胞们有一辆自行车就觉得很幸福，而我们有辆普桑为什么就没觉得有多少幸福。\n\n那么，怎么才能幸福呢？是拥有大量的财产，还是手握巨大的权力？这个问题，答案只有自己知道。这里，我们只能告诉你一点点幸福的秘诀。\n\n**尽量获取不容易情感适应的，且会带来快乐的外部刺激；尽量规避不容易情感适应的，且会带来不快的外部刺激。** 什么是情感适应呢？我们都会有这样的经历，当手伸入零度的冰水中时，会觉得异常冰冷与不 适应，但是随着时间的推移，我们渐渐觉得没有先前这么不适应了。这就是情感适应的因故。当然，有童鞋会说这不是生理上的适应嘛。事实上，导致情感适应的主 要原因包括生理适应，大脑对熟悉信息的模块化记忆，对于外部刺激注意力的转移以及对于事件结果的合理化解释。对于某件产生负向情感的事情，如将手伸入冰水 中，我们逐渐情感适应了，当然也不觉得这么难受了。相反，如果某件产生正向情感的事，比如说中的百万元的彩票，情感适应容易与否直接关系到快乐持续时间的 长短了。所以，对于能产生快乐的外部刺激，我们追求不容易情感适应的，如旅行等，而对于带来不快的外部刺激，我们则尽量避开不容易情感适应的，如失恋。\n\n**尽量花钱在单独消费时就可以感知其品质变化的产品或服务上，而不要花在只有在比较时才能感知相应变化的产品或服务上。** 举个例子，假如你想更换家中书房里的办公椅，因为这把椅子坐着不舒服，有种倾斜的感觉，所以想把它换成高档的办公椅。与此同时，你又想更换自己的数码相机，因为是几年前买的，虽然镜头和其他功能都让人满意，但却只有 800 万相素。而新品虽然在其他方面相差不大，但却有 1200 万相素。办公椅与相机价格相当，但是你只有购买其中一个，你经常在家里办公，也经常外出旅游摄影。你会如何选择呢？幸福学告诉你，应该选择办公椅。为什么呢？因为办公椅解决的是你的肌肉疲劳程度，而这点又是人体比较容易感知的，无须进行比较。相反，照片的相素从 800 万上升到 1200 万，只有在比较的情况下才能感知，一般人肉眼是无法将其分辨。所以，把钱花在容易感知其品质变化的产品或服务上才是正确的选择。\n\n**偶尔吃点苦能提高整体幸福水平，偶尔体验较为高档的享受都降低整体幸福水平，除非这些偶尔的体验被你视为非正常状态。** 如果你每天开车上班，可以每星期有那么一天去挤一次公交。这样的体验，能让你更能感受到开车上班的幸福感。正如有人说：忆苦思甜甜更甜。然而，偶尔体验较为高档的享受就不提倡了。如果你开的车是辆奇锐 QQ ，有个机会让你去免费试开宝马一个星期，你会把握这个机会吗？面对这样的机会，我们还是避而远之比较好。如果你去尝试了，等一个星期结束，你会发现你的奇锐 QQ 制动又差，方向盘又不舒适，总之是这有问题，那也有问题。然后，就会抱怨你的爱车有多么得差劲。其实，你大可不必这样，因为完全可以避免。当然，这里还有一种极端的情况，如果你这一辈子都买不起宝马，那么我建议去尝试吧，就好比刘姥姥游大观园而已。\n\n**学会创造流体验。** 所谓流体验，是指人们在进行某些活动时的忘我状态，此时人们完全被活动吸引，所有注意力 完全投注于活动中，并且觉得没有比活动本身更加重要的东西。我们生活中多多少少，有意无意地都经历过一些流体验。例如阅读一本情节跌宕起伏的小说，你会觉 得整个自己都被这小说吸引了，然后会觉得时间过得很快，不知不觉就几个小时过去了。等阅读完后，会感觉自己仍然沉浸在阅读这本小说的快乐之中。生活中多经 历些流体验，就会觉得更加幸福与快乐。\n\n**不要忽视预测和体验时生理、经济、社会等状况的不同。此时所欲未必是彼时所欲，己所欲未必是他人所欲。** 我们一定遇上过这样的情况，当你饥肠辘辘时点菜时，通常点了一大堆菜。等到你吃得差不多 的时候，就会发现你已经吃不了这么多菜了。这就是你点菜时候的状态并不是你吃菜时候的状态了。另一个例子就是，如果让你的父母来选择你们的配偶，通常是以 贤淑为标准的，他们从来不会把性生活作为标准之一。因为在他们的年龄来看这种事，已经不再重要了。这也就是说自己想要的不一定是他人想要的东西。\n\n总的来说，幸福可以自己去把握的。对于一些网上报道的城市幸福指数排名，我们大可不必理会。幸福从来都是自己的事，正如，猫吃着鱼，狗吃着肉，奥特曼一直喜欢打怪兽。\n\n------------------\n\n--《撬动幸福》   奚恺元","slug":"/2010/09-03-0.html","published":1,"updated":"2015-06-19T16:09:05.000Z","comments":1,"photos":[],"link":"","_id":"ciiwjp327004tof6glmi8n5oi"},{"date":"2010-08-01T16:00:00.000Z","layout":"post","title":"《高效能人士的七个习惯》读后","_content":"\n\n偶然在[刘未鹏](http://mindhacks.cn/)大牛的博客里看到[《高效能人士的七个习惯》](http://book.douban.com/subject/1048007/) 一书，便有兴趣一读。遂去图书馆借书一册，每晚睡觉前阅读几页，断断续续将其读完，颇有心得，与大家其享之。\n\n《高效能人士的七个习惯》，英文原名《The habits of highly effective people》。effective一词，可以认为是[getting the right things done](http://en.wikipedia.org/wiki/Effectiveness)。 但是，我觉得理解为getting the right things done rightly ，也就是说**正确地做正确的事** 。书中列举了effective人士的七个习惯，从**依赖到独立，再从独立到互赖**，完成到一个effective people的完全蜕变。\n\n习惯一：**积极主动(be proactive)** 。关于积极主动，可以算是老生长谈了。但凡是教人如何做事的书籍均会提到这样的词。确实，我们做做事情，如果缺乏积极主动，那么将一事无成。有句老话叫“天上不会掉馅饼”，没有积极主动，想想守株待兔的结局吧。\n\n习惯二：**以终为始(begin with the end in mind)**。任何事情的完成，都会经历两个阶段，一个为在你大脑里构思完成，另一个便是真正事实上完成。所以，我们必须一直抱着要完成的心态去做每一件事，切忌只将事情停留在你的大脑里。抛弃“我想……”，用“我要……”来代替，然后以完成它作为目标，直至事情的圆满结束。\n\n习惯三：**要事第一(put first things first)**。[笑来老师](http://www.lixiaolai.com/) 在他的博客里提到过，他辅导过一个女孩，见面时问她今天有什么事要处理。那女孩说给我两分钟时间，然后从包里拿出一本记事本，今天要处理的事全部都记在上 面。笑来老师认为这个女孩不错，会是个人才，因为她做事很有条理，而不是一团糟。后来，那女孩被耶鲁大学录取了。这里，我觉得这个女孩把要处理的事都记载 下来（尽管很多人会不屑），当然我并不觉得她的记忆力不好，是为了把事情按重要程度区别开来，以至于要事永远放在第一。\n\n习惯四：**双赢思维(think win/win)**。很多人认为双方竞争只有两个结果，已胜彼败，或者是已败彼胜。殊不知，还有[双嬴](http://en.wikipedia.org/wiki/Win_%26_Win)的可能。同一个团队，为了个人的竞争，勾心斗角不断，整个团队的效率就会停滞不前。很多公司的招聘，都会加上一个条件，要求有“团队合作精神”。先不论这样的招聘要求有没有实际的意义，但是企业的出发点还是好的，就是双嬴思维，双嬴才是目标。\n\n习惯五：**知彼解已(seek first to understand, then to be understood)**。想要别人了解你，那么首先要了解别人。我们看这个世界，都是带着有色眼镜观察。看别人的事，总会多少带一点个人色彩。同样一个小沈阳，你把他捧成星，我 却认为他是俗。更熟悉的说法就是，一千个读者就有一千个哈姆雷特。所以，评价别人的时候，摘掉我们的眼镜，用心真正去聆听别人，真正设身处地去了解别人， 这样，才能嬴得别人。\n\n习惯六：**统合综效(synergize)**。我们时常会听说1+1>2的事，这就是统合综效的成果。如果我们没有做到统合综效，那整个团队无异于一盘散沙，你要往东走，我却要向西行，无论如何也达不到1+1>2，反而1+1<2；\n\n习惯七：**不断更新(sharpen the saw)**。我们处在一个高速发展的时代，如果不更新自己，很快就会被社会淘汰。中国有句老话，“活到老，学到老”。我们伟大的毛主席也说，“流水不腐，户枢不蠹”。只有经常更新自己，才能跟上时代的步伐，也才能迈向新的成长之路。\n\n这七个习惯都不是我们罕见的道理，但是谨记**知易行难**，如果真正做到了，那就恭喜了，你成为effecive people的一员了。","source":"_posts/2010-08-02-0.md","raw":"---\ndate: 2010-08-02\nlayout: post\ntitle: 《高效能人士的七个习惯》读后\npermalink: '/2010/08-02-0.html'\ncategories:\n- 杂感\ntags:\n---\n\n\n偶然在[刘未鹏](http://mindhacks.cn/)大牛的博客里看到[《高效能人士的七个习惯》](http://book.douban.com/subject/1048007/) 一书，便有兴趣一读。遂去图书馆借书一册，每晚睡觉前阅读几页，断断续续将其读完，颇有心得，与大家其享之。\n\n《高效能人士的七个习惯》，英文原名《The habits of highly effective people》。effective一词，可以认为是[getting the right things done](http://en.wikipedia.org/wiki/Effectiveness)。 但是，我觉得理解为getting the right things done rightly ，也就是说**正确地做正确的事** 。书中列举了effective人士的七个习惯，从**依赖到独立，再从独立到互赖**，完成到一个effective people的完全蜕变。\n\n习惯一：**积极主动(be proactive)** 。关于积极主动，可以算是老生长谈了。但凡是教人如何做事的书籍均会提到这样的词。确实，我们做做事情，如果缺乏积极主动，那么将一事无成。有句老话叫“天上不会掉馅饼”，没有积极主动，想想守株待兔的结局吧。\n\n习惯二：**以终为始(begin with the end in mind)**。任何事情的完成，都会经历两个阶段，一个为在你大脑里构思完成，另一个便是真正事实上完成。所以，我们必须一直抱着要完成的心态去做每一件事，切忌只将事情停留在你的大脑里。抛弃“我想……”，用“我要……”来代替，然后以完成它作为目标，直至事情的圆满结束。\n\n习惯三：**要事第一(put first things first)**。[笑来老师](http://www.lixiaolai.com/) 在他的博客里提到过，他辅导过一个女孩，见面时问她今天有什么事要处理。那女孩说给我两分钟时间，然后从包里拿出一本记事本，今天要处理的事全部都记在上 面。笑来老师认为这个女孩不错，会是个人才，因为她做事很有条理，而不是一团糟。后来，那女孩被耶鲁大学录取了。这里，我觉得这个女孩把要处理的事都记载 下来（尽管很多人会不屑），当然我并不觉得她的记忆力不好，是为了把事情按重要程度区别开来，以至于要事永远放在第一。\n\n习惯四：**双赢思维(think win/win)**。很多人认为双方竞争只有两个结果，已胜彼败，或者是已败彼胜。殊不知，还有[双嬴](http://en.wikipedia.org/wiki/Win_%26_Win)的可能。同一个团队，为了个人的竞争，勾心斗角不断，整个团队的效率就会停滞不前。很多公司的招聘，都会加上一个条件，要求有“团队合作精神”。先不论这样的招聘要求有没有实际的意义，但是企业的出发点还是好的，就是双嬴思维，双嬴才是目标。\n\n习惯五：**知彼解已(seek first to understand, then to be understood)**。想要别人了解你，那么首先要了解别人。我们看这个世界，都是带着有色眼镜观察。看别人的事，总会多少带一点个人色彩。同样一个小沈阳，你把他捧成星，我 却认为他是俗。更熟悉的说法就是，一千个读者就有一千个哈姆雷特。所以，评价别人的时候，摘掉我们的眼镜，用心真正去聆听别人，真正设身处地去了解别人， 这样，才能嬴得别人。\n\n习惯六：**统合综效(synergize)**。我们时常会听说1+1>2的事，这就是统合综效的成果。如果我们没有做到统合综效，那整个团队无异于一盘散沙，你要往东走，我却要向西行，无论如何也达不到1+1>2，反而1+1<2；\n\n习惯七：**不断更新(sharpen the saw)**。我们处在一个高速发展的时代，如果不更新自己，很快就会被社会淘汰。中国有句老话，“活到老，学到老”。我们伟大的毛主席也说，“流水不腐，户枢不蠹”。只有经常更新自己，才能跟上时代的步伐，也才能迈向新的成长之路。\n\n这七个习惯都不是我们罕见的道理，但是谨记**知易行难**，如果真正做到了，那就恭喜了，你成为effecive people的一员了。","slug":"/2010/08-02-0.html","published":1,"updated":"2015-06-19T16:09:05.000Z","comments":1,"photos":[],"link":"","_id":"ciiwjp32a004vof6glm752b2a"}],"PostAsset":[],"PostCategory":[{"post_id":"ciiwjp2xz0000of6ghe2ih6yq","category_id":"ciiwjp2y40001of6g1j0xtk6a","_id":"ciiwjp2y70004of6gsuz04e83"},{"post_id":"ciiwjp2yu000cof6gi7tep7pm","category_id":"ciiwjp2yv000dof6gfnf95ypv","_id":"ciiwjp2yv000gof6glxltyx58"},{"post_id":"ciiwjp2yx000hof6ga461t7z0","category_id":"ciiwjp2yy000iof6ge41e7ll0","_id":"ciiwjp2yy000lof6ggz3qezz8"},{"post_id":"ciiwjp2z0000mof6gf056mr5i","category_id":"ciiwjp2z1000nof6gk2xv516u","_id":"ciiwjp2z1000qof6ggkkxandw"},{"post_id":"ciiwjp2z2000rof6gopjc4xke","category_id":"ciiwjp2z3000sof6gr0zjg7xx","_id":"ciiwjp2z4000uof6gebeq19xt"},{"post_id":"ciiwjp2z5000vof6gth1a0w8c","category_id":"ciiwjp2z3000sof6gr0zjg7xx","_id":"ciiwjp2z6000wof6gfkaxx8er"},{"post_id":"ciiwjp2z8000yof6gaf0lf9y1","category_id":"ciiwjp2z3000sof6gr0zjg7xx","_id":"ciiwjp2z9000zof6gw5ktcnbw"},{"post_id":"ciiwjp2zb0012of6gz8qepc5y","category_id":"ciiwjp2z3000sof6gr0zjg7xx","_id":"ciiwjp2zb0013of6gavcy4bw4"},{"post_id":"ciiwjp2zd0015of6geqmjlgcl","category_id":"ciiwjp2z3000sof6gr0zjg7xx","_id":"ciiwjp2ze0016of6guwod6ujf"},{"post_id":"ciiwjp2zf0018of6g4za5lknw","category_id":"ciiwjp2z1000nof6gk2xv516u","_id":"ciiwjp2zg0019of6gke91m8ti"},{"post_id":"ciiwjp2zi001cof6gmt6bdhx1","category_id":"ciiwjp2z1000nof6gk2xv516u","_id":"ciiwjp2zj001dof6g5o76yl7x"},{"post_id":"ciiwjp2zk001fof6g1o8hgpj7","category_id":"ciiwjp2z1000nof6gk2xv516u","_id":"ciiwjp2zm001gof6g9yv8y1us"},{"post_id":"ciiwjp2zo001iof6gv8helixr","category_id":"ciiwjp2z1000nof6gk2xv516u","_id":"ciiwjp2zp001jof6g8ehs212b"},{"post_id":"ciiwjp2zq001lof6g8jjh099b","category_id":"ciiwjp2z1000nof6gk2xv516u","_id":"ciiwjp2zr001mof6gk080rlnb"},{"post_id":"ciiwjp2zt001oof6grbezs3i6","category_id":"ciiwjp2z1000nof6gk2xv516u","_id":"ciiwjp2zu001pof6grtjpj3gw"},{"post_id":"ciiwjp2zw001rof6gkc2hz1lb","category_id":"ciiwjp2z1000nof6gk2xv516u","_id":"ciiwjp2zx001sof6g05601lm3"},{"post_id":"ciiwjp2zy001uof6geudkk1if","category_id":"ciiwjp2z1000nof6gk2xv516u","_id":"ciiwjp2zz001vof6g046xzj8l"},{"post_id":"ciiwjp300001yof6gdjrc0rwh","category_id":"ciiwjp2z1000nof6gk2xv516u","_id":"ciiwjp301001zof6g8vk7iqql"},{"post_id":"ciiwjp3020021of6g8sy0xhq9","category_id":"ciiwjp2z1000nof6gk2xv516u","_id":"ciiwjp3030022of6g8jjc8yvm"},{"post_id":"ciiwjp3040024of6g8sthtsii","category_id":"ciiwjp2z1000nof6gk2xv516u","_id":"ciiwjp3050025of6gsu1x9343"},{"post_id":"ciiwjp3060027of6gr8i4ds8t","category_id":"ciiwjp3070028of6g0lmx51jb","_id":"ciiwjp308002bof6gfenjg7ow"},{"post_id":"ciiwjp309002dof6gimnfu2uq","category_id":"ciiwjp2z1000nof6gk2xv516u","_id":"ciiwjp30a002eof6gp9r88u4r"},{"post_id":"ciiwjp30c002hof6gvftwcuww","category_id":"ciiwjp2z1000nof6gk2xv516u","_id":"ciiwjp30d002iof6gya4bdpo8"},{"post_id":"ciiwjp30e002kof6g4hzf3wdl","category_id":"ciiwjp3070028of6g0lmx51jb","_id":"ciiwjp30f002lof6g4k0xlffh"},{"post_id":"ciiwjp30h002oof6gmfa99n4w","category_id":"ciiwjp30i002pof6gd9xgesb3","_id":"ciiwjp30j002sof6ghpfxoyih"},{"post_id":"ciiwjp30k002vof6gmoliiwak","category_id":"ciiwjp30l002wof6gztk38zpp","_id":"ciiwjp30l002zof6g2hm4iiee"},{"post_id":"ciiwjp30m0030of6gtpskodso","category_id":"ciiwjp2z3000sof6gr0zjg7xx","_id":"ciiwjp30n0031of6gnvnuxuy5"},{"post_id":"ciiwjp30o0034of6gds9i8tha","category_id":"ciiwjp30p0035of6gcezpbnpf","_id":"ciiwjp30p0036of6gkoxa3tdj"},{"post_id":"ciiwjp30q0037of6gvchi421i","category_id":"ciiwjp30r0038of6gcul9a1kg","_id":"ciiwjp30r003bof6gs6bee88m"},{"post_id":"ciiwjp30t003cof6gbahic1i5","category_id":"ciiwjp30r0038of6gcul9a1kg","_id":"ciiwjp30u003dof6g6nx8s8dz"},{"post_id":"ciiwjp30v003fof6g3j7xwp2x","category_id":"ciiwjp30r0038of6gcul9a1kg","_id":"ciiwjp30w003gof6g6i7jd3wq"},{"post_id":"ciiwjp30y003iof6ga3yqhix7","category_id":"ciiwjp30p0035of6gcezpbnpf","_id":"ciiwjp310003jof6goa53zihv"},{"post_id":"ciiwjp311003kof6g5ejxcdza","category_id":"ciiwjp30r0038of6gcul9a1kg","_id":"ciiwjp312003lof6g2saj0f68"},{"post_id":"ciiwjp31b003nof6gckgwne0c","category_id":"ciiwjp30i002pof6gd9xgesb3","_id":"ciiwjp31c003oof6guxoypcg2"},{"post_id":"ciiwjp31d003pof6g6742vxkt","category_id":"ciiwjp30i002pof6gd9xgesb3","_id":"ciiwjp31e003qof6gcv5aavbg"},{"post_id":"ciiwjp31g003tof6glknjiodk","category_id":"ciiwjp2z1000nof6gk2xv516u","_id":"ciiwjp31g003uof6g6esp0on2"},{"post_id":"ciiwjp31j003xof6gbh99uje7","category_id":"ciiwjp2y40001of6g1j0xtk6a","_id":"ciiwjp31k003yof6g0spr371q"},{"post_id":"ciiwjp31m0041of6gvzobzhdp","category_id":"ciiwjp31m0042of6glg0ia1ue","_id":"ciiwjp31n0044of6gy26akgjj"},{"post_id":"ciiwjp31p0045of6g23ekbapx","category_id":"ciiwjp31m0042of6glg0ia1ue","_id":"ciiwjp31q0046of6gb2mec8i8"},{"post_id":"ciiwjp31r0048of6goudm8d67","category_id":"ciiwjp31s0049of6gefjc1nwo","_id":"ciiwjp31t004bof6g6sy1p5r6"},{"post_id":"ciiwjp31w004cof6gqqnr27a5","category_id":"ciiwjp2z1000nof6gk2xv516u","_id":"ciiwjp31w004dof6g0fgs22a1"},{"post_id":"ciiwjp31x004fof6gyhcxgh1u","category_id":"ciiwjp2y40001of6g1j0xtk6a","_id":"ciiwjp31y004gof6gwyl5e879"},{"post_id":"ciiwjp31z004jof6gwifzj1kl","category_id":"ciiwjp2y40001of6g1j0xtk6a","_id":"ciiwjp320004kof6g8kugjfbt"},{"post_id":"ciiwjp320004nof6gxyfnjv84","category_id":"ciiwjp2y40001of6g1j0xtk6a","_id":"ciiwjp321004oof6ghgwub5t5"},{"post_id":"ciiwjp324004rof6gf96p9u1y","category_id":"ciiwjp30p0035of6gcezpbnpf","_id":"ciiwjp326004sof6gwggonuct"},{"post_id":"ciiwjp327004tof6glmi8n5oi","category_id":"ciiwjp30p0035of6gcezpbnpf","_id":"ciiwjp329004uof6gjlui8lww"},{"post_id":"ciiwjp32a004vof6glm752b2a","category_id":"ciiwjp30p0035of6gcezpbnpf","_id":"ciiwjp32a004wof6g86z3ycz3"}],"PostTag":[{"post_id":"ciiwjp2xz0000of6ghe2ih6yq","tag_id":"ciiwjp2y50002of6gcyayw8fg","_id":"ciiwjp2y70006of6g53z11omo"},{"post_id":"ciiwjp2xz0000of6ghe2ih6yq","tag_id":"ciiwjp2y60003of6ghf94zg27","_id":"ciiwjp2y70007of6gmukiovry"},{"post_id":"ciiwjp2xz0000of6ghe2ih6yq","tag_id":"ciiwjp2y70005of6g3crkj647","_id":"ciiwjp2y80008of6g272oxhws"},{"post_id":"ciiwjp2yu000cof6gi7tep7pm","tag_id":"ciiwjp2yv000eof6gb82p955r","_id":"ciiwjp2yv000fof6gtx5tbs32"},{"post_id":"ciiwjp2yx000hof6ga461t7z0","tag_id":"ciiwjp2yy000jof6gcwlegu1c","_id":"ciiwjp2yy000kof6gxoq0q2ph"},{"post_id":"ciiwjp2z0000mof6gf056mr5i","tag_id":"ciiwjp2z1000oof6gqmme0wpc","_id":"ciiwjp2z1000pof6g3oa625hx"},{"post_id":"ciiwjp2z2000rof6gopjc4xke","tag_id":"ciiwjp2y70005of6g3crkj647","_id":"ciiwjp2z3000tof6gbirr6dju"},{"post_id":"ciiwjp2z5000vof6gth1a0w8c","tag_id":"ciiwjp2y70005of6g3crkj647","_id":"ciiwjp2z6000xof6gonhxbb98"},{"post_id":"ciiwjp2z8000yof6gaf0lf9y1","tag_id":"ciiwjp2z90010of6g6226er2f","_id":"ciiwjp2za0011of6gkz4aq2m0"},{"post_id":"ciiwjp2zb0012of6gz8qepc5y","tag_id":"ciiwjp2y70005of6g3crkj647","_id":"ciiwjp2zc0014of6g1w7vp3c7"},{"post_id":"ciiwjp2zd0015of6geqmjlgcl","tag_id":"ciiwjp2y70005of6g3crkj647","_id":"ciiwjp2ze0017of6g22k47vsm"},{"post_id":"ciiwjp2zf0018of6g4za5lknw","tag_id":"ciiwjp2zg001aof6g4obr8prl","_id":"ciiwjp2zh001bof6gusogross"},{"post_id":"ciiwjp2zi001cof6gmt6bdhx1","tag_id":"ciiwjp2zg001aof6g4obr8prl","_id":"ciiwjp2zj001eof6g0vg1lisd"},{"post_id":"ciiwjp2zk001fof6g1o8hgpj7","tag_id":"ciiwjp2zg001aof6g4obr8prl","_id":"ciiwjp2zm001hof6gt5zkezcw"},{"post_id":"ciiwjp2zo001iof6gv8helixr","tag_id":"ciiwjp2zg001aof6g4obr8prl","_id":"ciiwjp2zp001kof6g1gck28xz"},{"post_id":"ciiwjp2zq001lof6g8jjh099b","tag_id":"ciiwjp2zg001aof6g4obr8prl","_id":"ciiwjp2zr001nof6gxryoj94h"},{"post_id":"ciiwjp2zt001oof6grbezs3i6","tag_id":"ciiwjp2zg001aof6g4obr8prl","_id":"ciiwjp2zu001qof6gyvwuoya1"},{"post_id":"ciiwjp2zw001rof6gkc2hz1lb","tag_id":"ciiwjp2zg001aof6g4obr8prl","_id":"ciiwjp2zx001tof6g7qnkn22f"},{"post_id":"ciiwjp2zy001uof6geudkk1if","tag_id":"ciiwjp2zz001wof6gk3i5bosq","_id":"ciiwjp2zz001xof6gywlse7dm"},{"post_id":"ciiwjp300001yof6gdjrc0rwh","tag_id":"ciiwjp2zz001wof6gk3i5bosq","_id":"ciiwjp3010020of6gje11sgq0"},{"post_id":"ciiwjp3020021of6g8sy0xhq9","tag_id":"ciiwjp2zz001wof6gk3i5bosq","_id":"ciiwjp3030023of6gf8hd8ypv"},{"post_id":"ciiwjp3040024of6g8sthtsii","tag_id":"ciiwjp2zz001wof6gk3i5bosq","_id":"ciiwjp3050026of6g8yaj299k"},{"post_id":"ciiwjp3060027of6gr8i4ds8t","tag_id":"ciiwjp2y70005of6g3crkj647","_id":"ciiwjp308002aof6gnis2zv7p"},{"post_id":"ciiwjp3060027of6gr8i4ds8t","tag_id":"ciiwjp3080029of6gbu4b4vig","_id":"ciiwjp308002cof6gvtvaam6b"},{"post_id":"ciiwjp309002dof6gimnfu2uq","tag_id":"ciiwjp30a002fof6gmv0t5qr7","_id":"ciiwjp30b002gof6ga3gajqb2"},{"post_id":"ciiwjp30c002hof6gvftwcuww","tag_id":"ciiwjp30a002fof6gmv0t5qr7","_id":"ciiwjp30d002jof6gto4hxuf1"},{"post_id":"ciiwjp30e002kof6g4hzf3wdl","tag_id":"ciiwjp30f002mof6goaq8dqce","_id":"ciiwjp30g002nof6gy4nwfk9w"},{"post_id":"ciiwjp30h002oof6gmfa99n4w","tag_id":"ciiwjp30j002qof6g7czc2pm2","_id":"ciiwjp30j002tof6ghyjy2672"},{"post_id":"ciiwjp30h002oof6gmfa99n4w","tag_id":"ciiwjp30j002rof6gbxolb05j","_id":"ciiwjp30j002uof6glwrs6nrl"},{"post_id":"ciiwjp30k002vof6gmoliiwak","tag_id":"ciiwjp30l002xof6gcf83o5pc","_id":"ciiwjp30l002yof6ghnlkl33z"},{"post_id":"ciiwjp30m0030of6gtpskodso","tag_id":"ciiwjp30n0032of6glwh98xi0","_id":"ciiwjp30n0033of6g0bo2kpj5"},{"post_id":"ciiwjp30q0037of6gvchi421i","tag_id":"ciiwjp30r0039of6gu3h2k2yb","_id":"ciiwjp30r003aof6gh498v4ar"},{"post_id":"ciiwjp30t003cof6gbahic1i5","tag_id":"ciiwjp30r0039of6gu3h2k2yb","_id":"ciiwjp30u003eof6ghd40u9h7"},{"post_id":"ciiwjp30v003fof6g3j7xwp2x","tag_id":"ciiwjp30r0039of6gu3h2k2yb","_id":"ciiwjp30w003hof6gmgoc1mqp"},{"post_id":"ciiwjp311003kof6g5ejxcdza","tag_id":"ciiwjp30r0039of6gu3h2k2yb","_id":"ciiwjp312003mof6gvntaknfp"},{"post_id":"ciiwjp31d003pof6g6742vxkt","tag_id":"ciiwjp31e003rof6ggrztx7ah","_id":"ciiwjp31e003sof6g2vqxytck"},{"post_id":"ciiwjp31g003tof6glknjiodk","tag_id":"ciiwjp30a002fof6gmv0t5qr7","_id":"ciiwjp31g003vof6ggpkktrni"},{"post_id":"ciiwjp31g003tof6glknjiodk","tag_id":"ciiwjp2zg001aof6g4obr8prl","_id":"ciiwjp31g003wof6gvf63ydku"},{"post_id":"ciiwjp31j003xof6gbh99uje7","tag_id":"ciiwjp31k003zof6gxa7dympc","_id":"ciiwjp31l0040of6g5ea5fm50"},{"post_id":"ciiwjp31m0041of6gvzobzhdp","tag_id":"ciiwjp2y50002of6gcyayw8fg","_id":"ciiwjp31n0043of6gt0qicb71"},{"post_id":"ciiwjp31p0045of6g23ekbapx","tag_id":"ciiwjp2y50002of6gcyayw8fg","_id":"ciiwjp31q0047of6gvxncip6c"},{"post_id":"ciiwjp31r0048of6goudm8d67","tag_id":"ciiwjp2y50002of6gcyayw8fg","_id":"ciiwjp31s004aof6go3b5o3jx"},{"post_id":"ciiwjp31w004cof6gqqnr27a5","tag_id":"ciiwjp30a002fof6gmv0t5qr7","_id":"ciiwjp31w004eof6g9kdrgd3r"},{"post_id":"ciiwjp31x004fof6gyhcxgh1u","tag_id":"ciiwjp2y50002of6gcyayw8fg","_id":"ciiwjp31y004hof6gsjtmp8mo"},{"post_id":"ciiwjp31x004fof6gyhcxgh1u","tag_id":"ciiwjp2y60003of6ghf94zg27","_id":"ciiwjp31y004iof6gc9ie7szs"},{"post_id":"ciiwjp31z004jof6gwifzj1kl","tag_id":"ciiwjp2y50002of6gcyayw8fg","_id":"ciiwjp320004lof6g446jdlcs"},{"post_id":"ciiwjp31z004jof6gwifzj1kl","tag_id":"ciiwjp2y60003of6ghf94zg27","_id":"ciiwjp320004mof6gj0fg75nr"},{"post_id":"ciiwjp320004nof6gxyfnjv84","tag_id":"ciiwjp2y50002of6gcyayw8fg","_id":"ciiwjp322004pof6ga0qp41lq"},{"post_id":"ciiwjp320004nof6gxyfnjv84","tag_id":"ciiwjp30l002xof6gcf83o5pc","_id":"ciiwjp322004qof6gs1cr786m"}],"Tag":[{"name":"设计","_id":"ciiwjp2y50002of6gcyayw8fg"},{"name":"代码质量","_id":"ciiwjp2y60003of6ghf94zg27"},{"name":"性能","_id":"ciiwjp2y70005of6g3crkj647"},{"name":"计划","_id":"ciiwjp2yv000eof6gb82p955r"},{"name":"iOS入门","_id":"ciiwjp2yy000jof6gcwlegu1c"},{"name":"查找","_id":"ciiwjp2z1000oof6gqmme0wpc"},{"name":"架构","_id":"ciiwjp2z90010of6g6226er2f"},{"name":"排序","_id":"ciiwjp2zg001aof6g4obr8prl"},{"name":"union-find","_id":"ciiwjp2zz001wof6gk3i5bosq"},{"name":"pprof","_id":"ciiwjp3080029of6gbu4b4vig"},{"name":"面试题","_id":"ciiwjp30a002fof6gmv0t5qr7"},{"name":"小技巧","_id":"ciiwjp30f002mof6goaq8dqce"},{"name":"元编程","_id":"ciiwjp30j002qof6g7czc2pm2"},{"name":"内存管理","_id":"ciiwjp30j002rof6gbxolb05j"},{"name":"面向对象","_id":"ciiwjp30l002xof6gcf83o5pc"},{"name":"网络I/O","_id":"ciiwjp30n0032of6glwh98xi0"},{"name":"openGL","_id":"ciiwjp30r0039of6gu3h2k2yb"},{"name":"高阶函数","_id":"ciiwjp31e003rof6ggrztx7ah"},{"name":"基础","_id":"ciiwjp31k003zof6gxa7dympc"}]}}